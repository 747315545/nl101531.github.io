<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Mybatis源码分析(四)--TypeHandler的解析]]></title>
    <url>%2F2017%2F12%2F15%2Fmybatis%2FMybatis%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(%E5%9B%9B)--Typehandler%E7%9A%84%E6%9C%AC%E8%B4%A8%2F</url>
    <content type="text"><![CDATA[学习前的疑问 TypeHandler的主要功能是什么? TypeHandler如何配置? Mybatis是如何使用TypeHandler?(参数设置,结果映射) TypeHandler的主要功能是什么?TypeHandler是一个接口,那么其所拥有什么功能最简单的方法是看接口方法与注释(这里mybatis注释相当少),那么看下列方法.1.void setParameter(PreparedStatement ps, int i, T parameter, JdbcType jdbcType) throws SQLException;该方法为设置参数使用的转换方法,所需要的参数基本都给你传过来了,因此很好理解.2.T getResult(ResultSet rs, String columnName) throws SQLException;该方法是拿到结果集后根据列名称处理结果3.T getResult(ResultSet rs, int columnIndex) throws SQLException该方法是拿到结果集后根据列序号处理结果4.T getResult(CallableStatement cs, int columnIndex) throws SQLException;该方法是针对存储过程转换结果. 那么TypeHandler的作用就可以简单的理解为: 转换参数到sql中 转换查询结果到Java类中 TypeHandler如何配置?1.系统默认转换器TypeHandler有一个注册工厂为TypeHandlerRegistry类,该类中默认初始化了常用的转换器,其成员变量中有如下两个Map,可以看到JDBC_TYPE_HANDLER_MAP该map是针对jdbc转换到Java类的转换,为一对一结构,TYPE_HANDLER_MAP该map是针对Java类到JDBC类型的转换,为一对多结构.12private final Map&lt;JdbcType, TypeHandler&lt;?&gt;&gt; JDBC_TYPE_HANDLER_MAP = new EnumMap&lt;JdbcType, TypeHandler&lt;?&gt;&gt;(JdbcType.class); private final Map&lt;Type, Map&lt;JdbcType, TypeHandler&lt;?&gt;&gt;&gt; TYPE_HANDLER_MAP = new ConcurrentHashMap&lt;Type, Map&lt;JdbcType, TypeHandler&lt;?&gt;&gt;&gt;(); 以String类的转换器注册为例分析下123456789101112131415register(String.class, new StringTypeHandler());register(String.class, JdbcType.CHAR, new StringTypeHandler());register(String.class, JdbcType.CLOB, new ClobTypeHandler());register(String.class, JdbcType.VARCHAR, new StringTypeHandler());register(String.class, JdbcType.LONGVARCHAR, new ClobTypeHandler());register(String.class, JdbcType.NVARCHAR, new NStringTypeHandler());register(String.class, JdbcType.NCHAR, new NStringTypeHandler());register(String.class, JdbcType.NCLOB, new NClobTypeHandler());register(JdbcType.CHAR, new StringTypeHandler());register(JdbcType.VARCHAR, new StringTypeHandler());register(JdbcType.CLOB, new ClobTypeHandler());register(JdbcType.LONGVARCHAR, new ClobTypeHandler());register(JdbcType.NVARCHAR, new NStringTypeHandler());register(JdbcType.NCHAR, new NStringTypeHandler());register(JdbcType.NCLOB, new NClobTypeHandler()); 那么对应的JDBC_TYPE_HANDLER_MAP内存里面为TYPE_HANDLER_MAP内存里面接口如下图,注意在其TypeHandler中有一个key为null的转换器,其对应的注册方法自然为register(String.class, new StringTypeHandler());,那么也就是说当没指定jdbc类型时对于String.class类的转换均使用该转换器作为默认的TypeHandler. 2.mybatis.type-handlers-package转换器该指令是配置一个转换器所在的包,然后扫描该包下的TypeHandler的实现类,自动注册为转换器,详情可以看org.apache.ibatis.type.TypeHandlerRegistry#register(java.lang.String)方法由于Java存在泛型擦除机制,那么该Handler针对的JavaType该方法从TypeHandler实现类是拿不到的,因此其需要配合MappedTypes注解,看如下实现方法,针对TypeHandler去主动获取其上的MappedTypes注解,使用注解中的JavaType作为该TypeHandler的转换主体,如果获取不到则使用null,因此需要额外注意.12345678910111213public void register(Class&lt;?&gt; typeHandlerClass) &#123; boolean mappedTypeFound = false; MappedTypes mappedTypes = typeHandlerClass.getAnnotation(MappedTypes.class); if (mappedTypes != null) &#123; for (Class&lt;?&gt; javaTypeClass : mappedTypes.value()) &#123; register(javaTypeClass, typeHandlerClass); mappedTypeFound = true; &#125; &#125; if (!mappedTypeFound) &#123; register(getInstance(null, typeHandlerClass)); &#125; &#125; 3.Mapper中定义的TypeHandler首先我定义一个自定义的TypeHandler,该Handler只针对我所定义的枚举类处理,当然只能处理UserIdentifyType枚举类型,后面会实现一个通用的枚举转换器.123456789101112131415161718public class UserIdentifyTypeHandler extends BaseTypeHandler&lt;UserIdentifyType&gt; &#123; @Override public void setNonNullParameter(PreparedStatement ps, int i, UserIdentifyType parameter, JdbcType jdbcType) throws SQLException &#123; ps.setInt(i, parameter.getValue()); &#125; @Override public UserIdentifyType getNullableResult(ResultSet rs, String columnName) throws SQLException &#123; return UserIdentifyType.of(rs.getInt(columnName)); &#125; @Override public UserIdentifyType getNullableResult(ResultSet rs, int columnIndex) throws SQLException &#123; return UserIdentifyType.of(rs.getInt(columnIndex)); &#125; @Override public UserIdentifyType getNullableResult(CallableStatement cs, int columnIndex) throws SQLException &#123; return UserIdentifyType.of(cs.getInt(columnIndex)); &#125;&#125; 然后在mapper.xml文件中也是可以定义TypeHandler的,如下形式12345&lt;select id="findByOpenIdAnyType" resultType="com.itoolshub.user.repository.domain.UserAuth"&gt; SELECT &lt;include refid="RM-USERAUTH-ALLCOLS"/&gt; FROM user_auth WHERE status = 1 AND openid = #&#123;openId&#125; AND identity_type = #&#123;type,typeHandler=com.itoolshub.user.convert.UserIdentifyTypeHandler&#125; &lt;/select&gt; 那么这个TypeHandler是什么时候初始化的呢?这里涉及到ParameterMapping这个类,该类是Mybatis存储参数映射的地方,其内部有方法org.apache.ibatis.builder.BaseBuilder#resolveTypeHandler(java.lang.Class&lt;?&gt;, java.lang.Class&lt;? extends org.apache.ibatis.type.TypeHandler&lt;?&gt;&gt;),该方法会获取到对应的TypeHandler,然后从typeHandlerRegistry中获取,获取不到则使用反射生成一个.生成后并没有加入到typeHandlerRegistry中,也就是该TypeHandler并非单例,多少个sqlStament中如果使用了该转换器那么就会实例化几个该转换器,因此正确的使用方法是把该TypeHandler注册到typeHandlerRegistry中,然后在xml中使用.那么针对上述sql的ParameterMapping如下.另外由于我没有在xml中指定JavaType,那么其默认为Object,也就是参数设置是不能动态获取参数类型的. 参数如何使用TypeHandler设置到sql中?上面说到对于每一个sqlSatment都会解析为一个ParameterMapping的Map集合,在该ParameterMapping中TypeHandler已经确定好了,那么设置参数就只需要简单的调用下typeHandler.setParameter(ps, i + 1, value, jdbcType);方法,具体可以参考org.apache.ibatis.scripting.defaults.DefaultParameterHandler#setParameters方法中对其的做法.这里有一个很重要的点就是这里的TypeHandler的选择没有和我传入的参数类型绑定,举个例子我把上述参数去掉typehandler变成identity_type = #{type},那么得到的则是一个UnknownTypeHandler. UnknownTypeHandler并不UnknowUnknownTypeHandler的实现中能获取到具体输入参数的类型,然后调用org.apache.ibatis.type.UnknownTypeHandler#resolveTypeHandler(java.lang.Object, org.apache.ibatis.type.JdbcType)方法从TypeHandlerRegistry中获取到真正的转换器,这里的获取是根据输入参数的具体类型的class名称.获取不到则使用ObjectTypeHandler作为转换器. 结果如何使用TypeHandler设置到结果集中?相比参数设置结果的取出转换要复杂很多,方法org.apache.ibatis.executor.resultset.ResultSetWrapper#getTypeHandler中定义了一系列的获取TypeHandler的策略,总结如下顺序 根据返回参数类型+jdbc类型 根据返回参数类型 根据jdbc类型具体就不展开讨论了. 制作通用的枚举类处理器依照上述分析,如果想让枚举类的处理和基本类型一样的不需要显示的在mapper.xml上指定一些属性,几乎是不可能的一键事情,不过可以大大简化其使用方式,首先分析下对于枚举类两处的处理. 参数设置时,mapper.xml中的sql字段什么都不指定直接#{value},那么最终会使用该value的class名称去获取到对应的typeHandler. 结果映射时,由上述优先级顺序可以得知对于枚举类会使用方式2根据返回参数类型,也就是class名称获取对应的typeHandler. 那么通用转换器的实现思路很简单了,首先定义一个枚举类所使用的接口,然后编写通用处理,这里能实现还一个原因就是Class对象有type.getEnumConstants()方法可以获取到其所有枚举对象,也就是可以把数字映射为指定结果了,需要注意的是这里把每个枚举类都注入到TypeHandlerRegistry使用的是@MappedTypes注解,该注解生效是需要配置mybatis.type-handlers-package以包的形式扫,否则不生效. 下面的代码是copy自github,本文算是对其原理分析了一遍.https://github.com/mybatis/mybatis-3/issues/42EnumHasValue123public interface EnumHasValue &#123; int getValue();&#125; EnumValueTypeHandler12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@MappedTypes(&#123;UserIdentifyType.class, UserRoleType.class&#125;)public class EnumValueTypeHandler&lt;E extends Enum&lt;E&gt; &amp; EnumHasValue&gt; extends BaseTypeHandler&lt;E&gt;&#123; private Class&lt;E&gt; type; private final E[] enums; public EnumValueTypeHandler(Class&lt;E&gt; type) &#123; if (type == null) &#123; throw new IllegalArgumentException("Type argument cannot be null"); &#125; this.type = type; this.enums = type.getEnumConstants(); if (this.enums == null) &#123; throw new IllegalArgumentException(type.getSimpleName() + " does not represent an enum type."); &#125; &#125; @Override public void setNonNullParameter(PreparedStatement ps, int i, E parameter, JdbcType jdbcType) throws SQLException &#123; ps.setInt(i,parameter.getValue()); &#125; @Override public E getNullableResult(ResultSet rs, String columnName) throws SQLException &#123; int value = rs.getInt(columnName); if (rs.wasNull()) &#123; return null; &#125; for (E enm : enums) &#123; if (value == enm.getValue()) &#123; return enm; &#125; &#125; throw new IllegalArgumentException("Cannot convert " + value + " to " + type.getSimpleName()); &#125; @Override public E getNullableResult(ResultSet rs, int columnIndex) throws SQLException &#123; int value = rs.getInt(columnIndex); if (rs.wasNull()) &#123; return null; &#125; for (E enm : enums) &#123; if (value == enm.getValue()) &#123; return enm; &#125; &#125; throw new IllegalArgumentException("Cannot convert " + value + " to " + type.getSimpleName()); &#125; @Override public E getNullableResult(CallableStatement cs, int columnIndex) throws SQLException &#123; int value = cs.getInt(columnIndex); if (cs.wasNull()) &#123; return null; &#125; for (E enm : enums) &#123; if (value == enm.getValue()) &#123; return enm; &#125; &#125; throw new IllegalArgumentException("Cannot convert " + value + " to " + type.getSimpleName()); &#125;&#125; 备注以上内容基于 mybatis-spring-boot-starter:1.3.0,其mybatis版本3.4.4 参考文章: http://www.mybatis.org/mybatis-3/zh/configuration.html#typeHandlers]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[由需求而产生的一款db导出excel的工具]]></title>
    <url>%2F2017%2F12%2F02%2F%E5%B7%A5%E5%85%B7%2F%E7%94%B1%E9%9C%80%E6%B1%82%E8%80%8C%E4%BA%A7%E7%94%9F%E7%9A%84%E4%B8%80%E6%AC%BEdb%E5%AF%BC%E5%87%BAexcel%E7%9A%84%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[程序员最大的毛病可能就是懒,因为懒所以做出了许许多多提高自己工作效率的工具.起因于我是商业开发,既然是商业项目避免不了各种数据统计,虽然公司有专门的数据平台,但是应对一些临时性需求还是免不了开发人员去导出一些数据.每一次有需求来我都是写一个复杂的sql,然后放到DataGrip中执行,利用其功能导出cvs,然而越来越多的需求该功能无法满足,比如导出组合表,也就是一个excel中有多个sheet表.那么应该这个需求我写了一个为自己的工具. 我理想中的工具 1.简单模式使用sql查询直接导出2.复杂模式可以定义一些复杂的bean,然后通过组合代码中自定义实现导出逻辑3.可以自己定义表头,以及对应的数据处理,比如把时间戳转换为yyy-MM-dd hh:MM:ss这样的形式4.支持一个excel中含有多个sheet5.不需要很复杂的配置,因为自用,所以能约定俗成的地方就约定俗成. 语言的选择这个很随意了,我是选择自己最熟悉的语言,也就是Java.同事听说我用Java写这种工具,强烈推荐我用py,但天生动态语言无感,可以说是反感,所以放弃. 实现DB连接: DBUtilsExcel: POI具体过程很简单,代码逻辑也很清晰,这里只说下主要流程,详细的可以参考源码Github地址,另外由于个人使用,所以没有太多的校验和异常考虑. easy-excel https://github.com/mrdear/easy-excel) 另外分享一个IDEA从数据库表生成对应Bean的脚本,使用方法自定义自己的extensions script即可.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121import com.google.common.collect.Setsimport com.intellij.database.model.DasTableimport com.intellij.database.model.ObjectKindimport com.intellij.database.util.Caseimport com.intellij.database.util.DasUtilimport org.apache.commons.lang3.StringUtils/* * Available context bindings: * SELECTION Iterable&lt;DasObject&gt; * PROJECT project * FILES files helper */typeMapping = [ (~/(?i)tinyint/) : "Integer", (~/(?i)int/) : "Long", (~/(?i)float|double|decimal|real/): "Double", (~/(?i)date|datetime|timestamp/) : "java.util.Date", (~/(?i)time/) : "java.sql.Time", (~/(?i)/) : "String"]colTypeMapping = [ (~/(?i)tinyint/) : "TINYINT", (~/(?i)int/) : "BIGINT", (~/(?i)float|double|decimal|real/): "DECIMAL", (~/(?i)datetime|timestamp/) : "TIMESTAMP", (~/(?i)date/) : "TIMESTAMP", (~/(?i)time/) : "TIMESTAMP", (~/(?i)text/) : "LONGVARCHAR", (~/(?i)/) : "VARCHAR"]FILES.chooseDirectoryAndSave("Choose directory", "Choose where to store generated files") &#123; dir -&gt; SELECTION.filter &#123; it instanceof DasTable &amp;&amp; it.getKind() == ObjectKind.TABLE &#125;.each &#123; generate(it, dir) &#125;&#125;def generate(table, dir) &#123; def packageName = getPackageName(dir) def className = javaName(table.getName(), true) def fields = calcFields(table) //创建相关目录 repository目录下的 def path = dir.toString() //创建pojo与xml new File(path + File.separator + className + ".java").withPrintWriter &#123; out -&gt; generatePojo(out, packageName, className, fields) &#125;&#125;/** * 生成POJO * @param out * @param packageName * @param className * @param fields * @return */def generatePojo(out, packageName, className, fields) &#123; out.println "package $&#123;packageName&#125;;" out.println "" out.println "@Data" out.println "public class $&#123;className&#125; &#123;" out.println "" fields.each() &#123; // 输出注释 if (StringUtils.isNoneEmpty(it.comment)) &#123; out.println " /**" out.println " * $&#123;it.comment&#125;" out.println " */" &#125; if (it.annos != "") out.println " $&#123;it.annos&#125;" out.println " private $&#123;it.type&#125; $&#123;it.name&#125;;" &#125; out.println "" out.println "&#125;"&#125;// ------------方法 ---------------/** * 拿到所有的字段 * @param table 数据库表 * @return 字段Object */def calcFields(table) &#123; DasUtil.getColumns(table).reduce([]) &#123; fields, col -&gt; def spec = Case.LOWER.apply(col.getDataType().getSpecification()) def typeStr = typeMapping.find &#123; p, t -&gt; p.matcher(spec).find() &#125;.value def colTypeStr = colTypeMapping.find &#123; p, t -&gt; p.matcher(spec).find() &#125;.value fields += [[ colName: col.getName(), name : javaName(col.getName(), false), type : typeStr, colType: colTypeStr, comment: col.getComment(), annos : ""]] &#125;&#125;/** * 获取字段对应的Java类名称 */def javaName(str, capitalize) &#123; def s = str.split(/(?&lt;=[^\p&#123;IsLetter&#125;])/).collect &#123; Case.LOWER.apply(it).capitalize() &#125; .join("").replaceAll("_", "") capitalize || s.length() == 1 ? s : Case.LOWER.apply(s[0]) + s[1..-1]&#125;/** * 获取包名称 * @param dir 实体类所在目录 * @return */def getPackageName(dir) &#123; def target = dir.toString().replaceAll("/", ".").replaceAll("^.*src(\\.main\\.java\\.)?", "") return target.charAt(0) == '.' ? target.substring(1) : target&#125; 总结本文的主要目的是表达迷茫的时候不知道自己该做什么,那么就从自己身边的需求开始,分析自己所遇到的痛点,然后用你喜欢的方式去解决这个痛点,那么这个过程就是你的进步.]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>excel</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git的回滚操作]]></title>
    <url>%2F2017%2F11%2F20%2F%E5%B7%A5%E5%85%B7%2Fgit%E7%9A%84%E5%9B%9E%E6%BB%9A%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[一直在使用git作为版本管理器,但是有一次线上出问题,但是又有未通过完整测试的代码在mater分支上,那么所需要的操作就是 回滚代码到上一个已通过测试的master版本 -&gt; 修复bug -&gt; 发布 -&gt; 还原master -&gt; 合并修改了bug的分支 -&gt; 重新上预发布,那么下面开始演练. 为了简单描述,我们把定义几个分支.init-master //最初的masteruntest-master //未完全通过测试的master,其是远程仓库上最新的masterbugfix/fix_some_bug //修改的bug分支 操作拉取untest-master首先是切换并更新master,注意此时的master是untest-master,也就是我们要对其进行回滚操作12git checkout mastergit pull origin master 回滚到init-master回滚操作首先需要定义到要回滚到的提交记录,然后强制回滚到该记录上,注意这里的操作只是对本地分支的操作并不会影响到远程分支123//使用git log查看其提交记录,确定要回滚到的`commit id`git log g reset --hard [commit id] 回滚远程master回滚操作是把你当前的分支强制提交到master上也就是加-f参数指明强制覆盖,该命令需要你有相应的master权限.这样的话master上就是之前的版本了.那么接下来就是一般的修改bug了.1git push -u origin master -f 修复bug,并发布bug的修复是在当前init-master分支的基础上,切出一个新的分支,然后像平常一样修改提交,最后合到init-master上.123git checkout -b bugfix/fix_some_bug// 修复bug// 发布 取消回滚取消回滚则是重新强制恢复到修改过的版本,然后就可以强制回滚到任意版本了12git reflog 查看该分支的变动,可以确定其commit idgit reset --hard [commit id] 合并修改了bug的分支这次回滚后你处在untest-master分支上,该分支上是没有bugfix/fix_some_bug修复bug的代码的,那么把他合并过来.然后推送上去,那么master就是当前最新的版本了12git merge bugfix/fix_some_buggit push origin master 总结以上是操作是必须需要有master权限的,否则无法回滚,另外如果担心代码丢失那么在untest-master分支上再次checkout一个分支,这样即使master再怎么变,这个分支仍然是untest-master的副本.最后git是一款强大的版本工具,其可能有更加简单的方法,欢迎分享.]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[委派模型与类加载器]]></title>
    <url>%2F2017%2F11%2F13%2Fjava%2F%E5%A7%94%E6%B4%BE%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%2F</url>
    <content type="text"><![CDATA[最近在读许令波的深入分析Java Web技术内幕一书,对于学习Java以来一直有的几个疑惑得到了解答,遂记录下来. 我的疑问 双亲委派模型(实际上是一个翻译错误,英文为parent delegation,只是一个父委托模型)是什么?如何实现?为什么这样实现? 热加载的技术原理是什么? ClassLoader如何实现动态加载jar,实现插件模式系统?下面跟着教程来寻找这些答案. ClassLoader与委派模型ClassLoader顾名思义是类加载器,负责将Class加载到JVM中,其所使用的加载策略叫做双亲委派模型.JVM平台提供三个ClassLoader: Bootstrap ClassLoader,由C++实现的类加载器,其主要负责加载JVM自身工作所需要的类,该Loader由JVM自身控制,别人是无法访问的,其也不再双亲委派模型中承担角色. ExtClassLoader,该类加载器主要加载System.getProperty(&quot;java.ext.dirs&quot;)所对应的目录下class文件.一般为JVM平台扩展工具. AppClassLoader,该类加载器主要加载 System.getProperty(&quot;java.class.path&quot;)所对应的目录下的class文件,其委托父类为ExtClassLoader(后面会解释) 对于ExtClassLoader和AppClassLoader有着一个统一的父类ClassLoader,该类的结构如下,其拥有一个委托父类对象,同样的设计在Mybatis的Exector中也有体现,感兴趣的同学可以看我之前关于Mybatis分析的文章.12345public abstract class ClassLoader &#123; private final ClassLoader parent; protected Class&lt;?&gt; loadClass(String name, boolean resolve); ......&#125; 接下来重点看loadClass()方法,该方法为加载class二进制文件的核心方法.12345678910111213141516171819202122232425262728293031323334353637protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; //当父加载器不存在的时候会尝试使用BootStrapClassLoader作为父类 if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; //c为null则证明父加载器没有加载到,进而使用子类本身的加载策略`findClass()`方法 if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 那么开始回答问题1. 双亲委派模型是什么?上述加载流程是 使用parent加载器加载类 -&gt; parent不存在使用BootStrapClassLoader加载 -&gt; 加载不到则使用子类的加载策略,这里要注意BootStrapClassLoader是由C++实现的JVM内部的加载工具,其没有对应的Java对象,因此不在这个委派体系中,只是相当于名义上的加载器父类. 那么所谓的双亲我认为是parent委托对象与BootStrapClassLoader最顶端的加载器,两者都是属于被委托的对象,那么这就是所谓的双亲委派模型. 那么双亲是什么? 看ClassLoader的注释就能发现这只是个翻译错误,害得我脑补半天,明明是单亲委派,更通俗来说就是一个委托模式,当parent为null的时候,其parent为名义上的BootStrapClassLoader1Each instance of &lt;tt&gt;ClassLoader&lt;/tt&gt; has an associated parent class loader 2. 委派模型如何实现?实现如上述代码所示,其类本身有private final ClassLoader parent;这一委托父对象,另外其还有虚拟机实现的BootStrapClassLoader这个名义上的父加载器,在方法上优先执行委托类的策略.3. 为什么使用委派模型?回答这个问题要先了解Java中是如何判定两个类是同一个类状况,如下段官方所说,也就是类名(包括包名)相同并且他们的类加载器相同,那么两个对象才是等价的.123At run time, several reference types with the same binary name may be loaded simultaneously by different class loaders. These types may or may not represent the same type declaration. Even if two such types do represent the same type declaration, they are considered distinct. 对于Object类因为父加载器先加载所以能保证对于所有Object的子类其所对应的Object都是由同一个ClassLoader所加载,也就保证了对象相等. 简单来说委托类优先模式保证了加载器的优先级问题,让优先级高的ClassLoader先加载,然后轮到优先级低的. 热加载的技术原理热部署对于开发阶段的实用性极高,利用Jrebel等工具可以极大的节省应用调试时间.关于热加载技术可以参考文章http://www.hollischuang.com/archives/606,对于一个被ClassLoader加载到内存的类来说,再次加载的时候就会被findLoadedClass()方法所拦截,其判断该类已加载,则不会再次加载,那么热加载的技术本质是要替换到已加载的类. 对于Spring Boot devtools的restart技术,其是使用了两个ClassLoader,对于开发者所写的类使用自定义的ClassLoader,对于第三方包则使用默认加载器,那么每当代码有改动需要热加载时,丢弃自定义的ClassLoader所加载的类,然后重新使用其加载,如此做到了热部署. 对于Jrebel使用的貌似是修改类的字节码方式,具体不是很懂也就不讨论了. 对于Tomcat,其热部署技术是每次清理之前的引用,然后创建一个新的ClassLoaderWebClassLoader来重新加载应用,这个加载使得永久代中对象增多,那么清理要求是full GC,这个是不可控的,所以也就导致了Tomcat热部署频繁会触发java.lang.OutOfMemoryErrorPermGen space这个bug. ClassLoader如何实现动态加载jar,实现插件模式系统?ClassLoader的委派模型使得很容易扩展自定义的类加载器,那么基本步骤 定义自己的类加载器 -&gt; 加载指定jar -&gt; 创建所需要的应用实例,大概代码如下.12345678910String jarPath = "/Users/niuli/workspace/quding-git/quding-study/helloworld/target/hello-world-1.0-SNAPSHOT.jar"; URL jarUrl = new File(jarPath).toURI().toURL(); //加载该jar URLClassLoader loader = new URLClassLoader(new URL[]&#123;jarUrl&#125;,Thread.currentThread().getContextClassLoader()); //获取插件Class对象 Class helloClass = loader.loadClass("com.itoolshub.hello.HelloWorld"); //创建该对象 IHelloWorldService helloWorldService = (IHelloWorldService) helloClass.newInstance(); //调用方法 helloWorldService.sayHello(); 另外插件模式的话一般还会有一些配置文件plugin.xml,告诉系统主要对外提供服务的类是什么以及一些默认配置等.不过大概思路都是大同小异. 另外既然有装载也就有卸载,卸载的必要条件是以下三个外,另外类是装载在永久代,那么卸载的触发也就是full GC才会去清理永久代中没有被强引用指向的类. 该类所有的实例都已经被GC。 加载该类的ClassLoader实例已经被GC。 该类的java.lang.Class对象没有在任何地方被引用。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的四种引用]]></title>
    <url>%2F2017%2F10%2F30%2Fjava%2FJava%E4%B8%AD%E7%9A%84%E5%9B%9B%E7%A7%8D%E5%BC%95%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Java中存在四种引用,StrongReference(强引用) 、SoftReferenc(软引用) 、WeakReferenc(弱引用)、PhantomReference(虚引用).虽然不常用,但是对于理解Java的回收等级还是很有帮助的,一句话来说这些引用只是不同回收等级的一种表现形式. StrongReference(强引用)强引用是最经常使用的一种引用,如new操作创建的对象就属于强引用.如下代码,对于强引用要记住无论如何JVM都不会去回收其内存.1Object obj = new Object(); SoftReferenc(软引用)软引用是由java.lang.ref.SoftReference所提供的功能,被其所关联的对象不存在强引用并且此时JVM内存不足才会去回收该对象.个人不知道其用处,做缓存的话,现在的企业项目基本不是单体架构所以用处不大,倒是可以做内存警告,当对象被回收时则说明系统所需要的内存不足,那么就可以发邮件通知相关人员. WeakReferenc(弱引用)弱引用是java.lang.ref包下的WeakReferenc类所提供的包装功能,对于弱引用JVM会回收仅被弱引用所关联的对象.也就是说弱引用对象会在一次gc之后被回收,如下代码,其中obj1没被回收,因为其的引用是强引用,但是weakObj1与其关联是弱引用,因此不属于被收回对象.weakObj2所关联的new Object()只有一个弱引用关联,因此会被回收.12345678Object obj1 = new Object();WeakReference&lt;Object&gt; weakObj1 = new WeakReference&lt;Object&gt;(obj1);WeakReference&lt;Object&gt; weakObj2 = new WeakReference&lt;Object&gt;(new Object());//主动回收System.gc();System.out.println(weakObj1.get()); // 非nullSystem.out.println(weakObj2.get()); // null Java中提供了一个很棒的工具类WeakHashMap,按照注释所说,该类是一个键为弱引用类型的Map,与传统Map不同的是其键会自动删除释放掉,因为gc()时会自动释放,因此很适合做缓存这一类的需求,下面代码是Tomcat所实现的LRU(最少使用策略)缓存算法的实现,关键点在注释中给出.123456789101112131415161718192021222324252627282930313233343536373839404142import java.util.Map;import java.util.WeakHashMap;import java.util.concurrent.ConcurrentHashMap;public final class ConcurrentCache&lt;K,V&gt; &#123; //LRU所允许的最大缓存量 private final int size; private final Map&lt;K,V&gt; eden; private final Map&lt;K,V&gt; longterm; public ConcurrentCache(int size) &#123; this.size = size; //eden是主要缓存 this.eden = new ConcurrentHashMap&lt;&gt;(size); //longterm是实现LRU算法的关键点. this.longterm = new WeakHashMap&lt;&gt;(size); &#125; //get是先从eden中取出缓存,当不存在时则去longterm中获取缓存,并且此时获取到的缓存说明还在使用,因此会put到eden中(LRU算法) public V get(K k) &#123; V v = this.eden.get(k); if (v == null) &#123; synchronized (longterm) &#123; v = this.longterm.get(k); &#125; if (v != null) &#123; this.eden.put(k, v); &#125; &#125; return v; &#125; //put操作当size大于LRU最大容量时,则把缓存都放入到longterm,当this.eden.clear()后使其成为弱引用,那么LRU的实现则在get方法中体现了出来. public void put(K k, V v) &#123; if (this.eden.size() &gt;= size) &#123; synchronized (longterm) &#123; this.longterm.putAll(this.eden); &#125; this.eden.clear(); &#125; this.eden.put(k, v); &#125;&#125; 此方法如果操作时刚好遇到了一次gc,那么longterm的引用就会丢失,那么缓存就gg了. PhantomReference(虚引用)虚引用是由java.lang.ref.PhantomReference所提供的关联功能,虚引用对其原对象的生命周期毫无影响,其可以算是一种标记,当其所引用对象被回收时其会自动加入到引用队列中.也就是说你可以通过虚引用得到哪些对象已被回收.具体用法可以分析common.io中的org.apache.commons.io.FileCleaningTracker该类中有一内部类class Tracker extends PhantomReference&lt;Object&gt;,也就是其包裹着虚引用对象,分析其构造函数,marker参数是该具体的虚引用,当marker被回收时,该对应的Track会被加入到引用队列queue中.123456Tracker(String path, FileDeleteStrategy deleteStrategy, Object marker, ReferenceQueue&lt;? super Object&gt; queue) &#123; //marker是具体的虚引用对象 super(marker, queue); this.path = path; this.deleteStrategy = deleteStrategy == null ? FileDeleteStrategy.NORMAL : deleteStrategy;&#125; 文件删除则是该类维护的一个线程来进行的操作,既然对象回收后会加入到引用队列queue,那么该线程要做的功能自然是从引用队列中获取到对应的Track,然后执行其删除策略.在这个流程中虚引用起到的是跟踪所包裹对象作用,当包裹的的对象被回收时,这边会得到一个通知(将其加入到引用队列).1234567891011121314151617@Override public void run() &#123; // thread exits when exitWhenFinished is true and there are no more tracked objects while (exitWhenFinished == false || trackers.size() &gt; 0) &#123; try &#123; // Wait for a tracker to remove. Tracker tracker = (Tracker) q.remove(); // cannot return null trackers.remove(tracker); if (!tracker.delete()) &#123; deleteFailures.add(tracker.getPath()); &#125; tracker.clear(); &#125; catch (InterruptedException e) &#123; continue; &#125; &#125; &#125; 参考文章理解Java中的弱引用]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网站升级HTTPS与HTTP2记录]]></title>
    <url>%2F2017%2F10%2F18%2F%E8%BF%90%E7%BB%B4%2F%E7%BD%91%E7%AB%99%E5%8D%87%E7%BA%A7HTTPS%E4%B8%8EHTTP2%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[最近看到两篇文章对于HTTPS与HTTP2两者讲解的很详细,分享并实践一下,正好近期捣鼓了一个工具类站点https://www.itoolshub.com/,可以用来实验.文章地址为什么要把网站升级到HTTPS怎样把网站升级到http/2 升级HTTPS升级的好处如文章所说,另外这里主要是按照文章中的教程来处理,不过我的服务器是Centos7,大体步骤相同,选择操作系统与服务器后会到该页面https://certbot.eff.org/#centosrhel7-nginx.要注意sudo certbot --nginx命令,该命令默认会去usr/bin/nginx与/etc/nginx下寻找nginx启动文件与配置文件,因此如果你的nginx位置不对就会报not install错误,导致无法进行,解决方案为使用软链接形式创建链接.12ln -s /usr/local/nginx/sbin/nginx /usr/bin/nginxln -s /usr/local/nginx/conf/ /etc/nginx 命令都执行完后,nginx的server节点下会多出如下配置,第一部分为监听443端口.即https默认端口,使用该证书.第二部分是对非https请求重定向到https.这样也就学到了nginx是怎么配置https请求.123456789 listen 443 ssl; # managed by Certbotssl_certificate /etc/letsencrypt/live/itoolshub.com/fullchain.pem; # managed by Certbotssl_certificate_key /etc/letsencrypt/live/itoolshub.com/privkey.pem; # managed by Certbot include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot if ($scheme != &quot;https&quot;) &#123; return 301 https://$host$request_uri; &#125; # managed by Certbot 升级HTTP2正如原作者所说HTTP2具有太多的优势,比如多路复用，对同一个域的服务器只建立一次TCP连接，加载多个资源，使用二进制帧传输，同时会对http头部进行压缩,大大提高了传输的效率.要注意的是Nginx启用http2则需要安装http_v2_module模块,并且需要openssl版本大于1.0.2,由于Chrome改变了验证http2的方式,详情可以参考此文章https://news.cnblogs.com/n/545972/. 推荐做法nginx的模块是支持静态编译的,因此自己下载所需要的软件版本,然后编译时指定配置相应的版本是最佳解决方案.如下脚本,我配置了http_v2_module和/opt/openssl-OpenSSL_1_0_2k的版本,这样nginx编译时则不会去使用系统自带的openssl.注意不要make install,该命令是会执行安装操作,也就是会把你之前安装的nginx覆盖掉.123456789101112131415161718./configure \ --prefix=/usr/local/nginx \ --conf-path=/etc/nginx/nginx.conf \ --pid-path=/var/local/nginx/nginx.pid \ --lock-path=/var/lock/nginx/nginx.lock \ --error-log-path=/quding/logs/nginx/error.log \ --http-log-path=/quding/logs/nginx/access.log \ --with-http_gzip_static_module \ --http-client-body-temp-path=/var/temp/nginx/client \ --http-proxy-temp-path=/var/temp/nginx/proxy \ --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \ --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \ --with-http_ssl_module \ --http-scgi-temp-path=/var/temp/nginx/scgi \ --with-http_v2_module \ --with-openssl=/opt/openssl-OpenSSL_1_0_2kecho 'make start...'make 脚本执行完毕后,手动copy nginx替换原nginx,使用nginx -V查看所使用的openssl版本信息,如下所示则不会有大问题. 最后在https监听那里加上http2,nginx reload下即可.1listen 443 ssl http2; 对于chrome最可信的调试方式是访问chrome://net-internals/#http2,如果显示你的网站使用的协议为h2,那么恭喜你开启了http2 目前https://www.itoolshub.com/已经开启了HTTPS与HTTP2.但是图片是放在七牛云的,七牛的HTTPS收费,所以目前没解决,由于图片并不是很多后期迁到自己的服务器上,或者使用base64形式.]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>https</tag>
        <tag>http2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Angular中引入第三方JS库]]></title>
    <url>%2F2017%2F10%2F09%2Fweb%2FAngular%E4%B8%AD%E5%BC%95%E5%85%A5%E7%AC%AC%E4%B8%89%E6%96%B9Js%E5%BA%93%2F</url>
    <content type="text"><![CDATA[最近写http://www.itoolshub.com/的时候用到了日期时间选择器,Angular本身material2只有日期选择器,也不知道为什么官方不提供日期时间选择器,也可能是Angular2以及如今的4有些年轻,很多库都不是很成熟,于是乎搜索到的解决方案就是借助第三方的库来使用一些优秀的组件.本文以https://github.com/sentsin/laydate组件为例. 引入js与csshttps://github.com/sentsin/laydate是采用原生js实现的组件,因此不需要考虑相关依赖,直接入手.1.使用npm下载该组件npm install layui-laydate -save2.在.angular-cli.json文件中配置1234567"styles": [ "styles.scss", "../node_modules/layui-laydate/dist/theme/default/laydate.css" ], "scripts": [ "../node_modules/layui-laydate/dist/laydate.js" ], Angular在编译的时候会把上述的js引用都打包到scripts.bundle.js文件中 ts编译识别laydate第一步完成后如果在TS中使用laydate变量,编译器是会直接报错的,因为其找不到这个变量,因此这一步要做的就是让ts识别该变量.做法很简单,在typings.d.ts中加入声明1234567/* SystemJS module definition */declare var module: NodeModule;interface NodeModule &#123; id: string;&#125;// laydate声明declare var laydate: any; 使用laydate功能laydate是需要更改Dom节点的,因此该步骤必须放到Angular对视图渲染之后,也就是生命周期中的AfterViewInit函数中执行.另外该渲染会使得双向绑定失效,需要处理结果则可以在laydate的回调函数中处理.另外使用的时候就可以按照ts的语法来使用了,最终都会解析成原生js.比如下方的箭头函数.12345678910111213ngAfterViewInit(): void &#123; let done = (value, date, endDate) =&gt;&#123; let selectTime = new Date(value); this.timeStampOut = selectTime.getTime() / 1000; this.timeStampWeek = TimestampComponent.WEEKS[selectTime.getDay()] == null ? "Invalid Week": TimestampComponent.WEEKS[selectTime.getDay()] &#125;; laydate.render(&#123; elem: '#layerdate', type: 'datetime', change: done, done: done &#125;);&#125; 备注很多库都是直接对DOM进行操作,这对于Angular这种虚拟Dom操作会导致绑定失效等各种异常问题,一般情况下不建议混编,尤其是大项目,到后期会出现各种折磨人的小问题. 更多Angular实战代码可以参考我的开源项目: github: https://github.com/nl101531/IToolsHub]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>angular</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客的好搭档七牛云]]></title>
    <url>%2F2017%2F09%2F24%2F%E8%BF%90%E7%BB%B4%2F%E5%8D%9A%E5%AE%A2%E7%9A%84%E5%A5%BD%E6%90%AD%E6%A1%A3%E4%B8%83%E7%89%9B%E4%BA%91%2F</url>
    <content type="text"><![CDATA[博客也搭建有一段时间了,期间一些同学来询问如何搭建博客,找了几篇文章让其搭建好了后我却发现大量图片也没他上传到github了,图片本身大,再加上github国内访问并不是很流畅,那么结果就是博客速度的下降,所以分享七牛云就是解决这个问题. 是什么?七牛云是一个云存储平台,对于个人博客而言他就是一个图床,我们可以把图片等静态资源放在上面,甚至可以把整个博客都放在上面.比如http://oobu4m7ko.bkt.clouddn.com/1506220469.png这张图片就是我上传到七牛云上的,嵌入到markdown中的话展示效果如下: 七牛云允许你对链接加参数来对图片进行一些处理,比如下面这些操作http://oobu4m7ko.bkt.clouddn.com/1506220469.png?imageMogr2/thumbnail/!70p,这参数以为等比缩放为70%,对于mac等高分辨屏来说很实用.当然还有缩略,转换,裁剪等功能.详细的可以参考该文档七牛图片处理基本文档 七牛给免费用户提供了每月10GB的流量,足够个人网站的使用了. 怎么用?七牛虽好,但是上传是个麻烦的事情,写作的时候不能还开个浏览器窗口专门上传图片,这个肯定不合理.这样的不合理肯定有好的解决方案,我理想中的方案时复制图片到剪贴板,软件从剪贴板读取,上传,返回指定形式链接到粘贴板.下面推荐一些比较好的开源方案. 注册账号首先注册七牛账号,不介意的话可以走我的邀请链接. 注册七牛云 mac对于mac下图床的客户端选择是非常多的,这里首推alfred的workflow,简洁实用.https://github.com/kaito-kidd/markdown-image-alfred 支持复制本地图片获取图片链接支持截图获取图片图片链接支持gif格式操作结果会在通知栏显示 windowswindows下首推mpic这款软件,操作简单,文档清晰,下载后配置下即可使用.http://mpic.lzhaofu.cn/ 如果你有更好的方案,欢迎分享.]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>七牛</tag>
        <tag>图片存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8学习记录(三)-强大的collect操作]]></title>
    <url>%2F2017%2F09%2F20%2Fjava%2FJava8%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%B8%89)-%E5%BC%BA%E5%A4%A7%E7%9A%84collect%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[collect应该说是Stream中最强大的终端操作了,使用其几乎能得到你想要的任意数据的聚合,下面好好分析该工具的用法. 在Stream接口中有如下两个方法12345 &lt;R&gt; R collect(Supplier&lt;R&gt; supplier, BiConsumer&lt;R, ? super T&gt; accumulator, BiConsumer&lt;R, R&gt; combiner); &lt;R, A&gt; R collect(Collector&lt;? super T, A, R&gt; collector); 很明显第一种相当于简易实现版本,第二种为高级用法.更多更复杂的操作都封装到Collector接口中,并提供一些静态方法供使用者调用.下面逐一分析. 简易调用形式简易调用形式就是第一种接口,接口如下123&lt;R&gt; R collect(Supplier&lt;R&gt; supplier, BiConsumer&lt;R, ? super T&gt; accumulator, BiConsumer&lt;R, R&gt; combiner); 调用方式如下,很明显第一个参数supplier为结果存放容器,第二个参数accumulator为结果如何添加到容器的操作,第三个参数combiner则为多个容器的聚合策略.123String concat = stringStream.collect(StringBuilder::new, StringBuilder::append,StringBuilder::append).toString();//等价于上面,这样看起来应该更加清晰String concat = stringStream.collect(() -&gt; new StringBuilder(),(l, x) -&gt; l.append(x), (r1, r2) -&gt; r1.append(r2)).toString(); 那么换一种,我想对一个List收集结果总和,按照Collect的要求,首先需要容器sum,然后添加操作 sum+x,聚合操作,sum1+sum2,那么就很容易写出来了,看完下面代码后好好体会下,然后再看高级用法.当然用sum方法收集是最佳解决方案,这里只是提供一种示例应用.1234// 由于基本类型都是不可变类型,所以这里用数组当做容器final Integer[] integers = Lists.newArrayList(1, 2, 3, 4, 5) .stream() .collect(() -&gt; new Integer[]&#123;0&#125;, (a, x) -&gt; a[0] += x, (a1, a2) -&gt; a1[0] += a2[0]); 那么再换一种,有一个Person类,其拥有type与name两个属性,那么使用collect把他收集到Map集合中,其中键为type,值为person的集合.如下代码所示,看明白了相信就掌握了该方法.123456789Lists.&lt;Person&gt;newArrayList().stream() .collect(() -&gt; new HashMap&lt;Integer,List&lt;Person&gt;&gt;(), (h, x) -&gt; &#123; List&lt;Person&gt; value = h.getOrDefault(x.getType(), Lists.newArrayList()); value.add(x); h.put(x.getType(), value); &#125;, HashMap::putAll ); Collector高级调用Collector接口是使得collect操作强大的终极武器,对于绝大部分操作可以分解为旗下主要步骤,提供初始容器-&gt;加入元素到容器-&gt;并发下多容器聚合-&gt;对聚合后结果进行操作,同时Collector接口又提供了of静态方法帮助你最大化的定制自己的操作,官方也提供了Collectors这个类封装了大部分的常用收集操作.另外CollectorImpl为Collector的实现类,因为接口不可实例化,这里主要完成实例化操作.12345678910//初始容器 Supplier&lt;A&gt; supplier();//加入到容器操作BiConsumer&lt;A, T&gt; accumulator();//多容器聚合操作BinaryOperator&lt;A&gt; combiner();//聚合后的结果操作Function&lt;A, R&gt; finisher();//操作中便于优化的状态字段Set&lt;Characteristics&gt; characteristics(); Collectors的方法封装Collectors作为官方提供的收集工具类,那么其很多操作都具有参考性质,能帮助我们更加理解Collector接口,万变不离其宗,最终只是上面五个函数接口的混合操作,下面来分析下官方是如何使用这几个接口的. toList()容器: ArrayList::new加入容器操作: List::add多容器合并: left.addAll(right); return left;聚合后的结果操作: 这里直接返回,因此无该操作,默认为castingIdentity()优化操作状态字段: CH_ID这样看起来很简单,那么对于Map,Set等操作都是类似的实现.123456public static &lt;T&gt; Collector&lt;T, ?, List&lt;T&gt;&gt; toList() &#123; return new CollectorImpl&lt;&gt;((Supplier&lt;List&lt;T&gt;&gt;) ArrayList::new, List::add, (left, right) -&gt; &#123; left.addAll(right); return left; &#125;, CH_ID); &#125; joining()容器: StringBuilder::new加入容器操作: StringBuilder::append多容器合并: r1.append(r2); return r1;聚合后的结果操作: StringBuilder::toString优化操作状态字段: CH_NOID123456public static Collector&lt;CharSequence, ?, String&gt; joining() &#123; return new CollectorImpl&lt;CharSequence, StringBuilder, String&gt;( StringBuilder::new, StringBuilder::append, (r1, r2) -&gt; &#123; r1.append(r2); return r1; &#125;, StringBuilder::toString, CH_NOID);&#125; 下面来个复杂的 groupingBy()groupingBy是toMap的一种高级方式,弥补了toMap对值无法提供多元化的收集操作,比如对于返回Map&lt;T,List&lt;E&gt;&gt;这样的形式toMap就不是那么顺手,那么groupingBy的重点就是对Key和Value值的处理封装.分析如下代码,其中classifier是对key值的处理,mapFactory则是指定Map的容器具体类型,downstream为对Value的收集操作,具体代码这里不做分析,无非是把值一个一个的put进指定容器.123456public static &lt;T, K, D, A, M extends Map&lt;K, D&gt;&gt; Collector&lt;T, ?, M&gt; groupingBy(Function&lt;? super T, ? extends K&gt; classifier, Supplier&lt;M&gt; mapFactory, Collector&lt;? super T, A, D&gt; downstream) &#123; ....... &#125; 对于之前用原生collect方法做的收集操作那么就可以很容易改写为groupBy形式12345678910111213141516//原生形式 Lists.&lt;Person&gt;newArrayList().stream() .collect(() -&gt; new HashMap&lt;Integer,List&lt;Person&gt;&gt;(), (h, x) -&gt; &#123; List&lt;Person&gt; value = h.getOrDefault(x.getType(), Lists.newArrayList()); value.add(x); h.put(x.getType(), value); &#125;, HashMap::putAll );//groupBy形式Lists.&lt;Person&gt;newArrayList().stream() .collect(Collectors.groupingBy(Person::getType, HashMap::new, Collectors.toList()));//因为对值有了操作,因此我可以更加灵活的对值进行转换Lists.&lt;Person&gt;newArrayList().stream() .collect(Collectors.groupingBy(Person::getType, HashMap::new, Collectors.mapping(Person::getName,Collectors.toSet()))); reducing()reducing是针对单个值的收集,其返回结果不是集合家族的类型,而是单一的实体类T容器: boxSupplier(identity),这里包裹用的是一个长度为1的Object[]数组,至于原因自然是不可变类型的锅加入容器操作: a[0] = op.apply(a[0], t)多容器合并: a[0] = op.apply(a[0], b[0]); return a;聚合后的结果操作: 结果自然是Object[0]所包裹的数据a -&gt; a[0]优化操作状态字段: CH_NOID那么看到这里困惑是不是有一种恍然大悟的感觉,反正我是有的.123456789public static &lt;T&gt; Collector&lt;T, ?, T&gt; reducing(T identity, BinaryOperator&lt;T&gt; op) &#123; return new CollectorImpl&lt;&gt;( boxSupplier(identity), (a, t) -&gt; &#123; a[0] = op.apply(a[0], t); &#125;, (a, b) -&gt; &#123; a[0] = op.apply(a[0], b[0]); return a; &#125;, a -&gt; a[0], CH_NOID); &#125; 那么接下来就是对之前Collect的一些操作的改造1234567891011//原生操作final Integer[] integers = Lists.newArrayList(1, 2, 3, 4, 5) .stream() .collect(() -&gt; new Integer[]&#123;0&#125;, (a, x) -&gt; a[0] += x, (a1, a2) -&gt; a1[0] += a2[0]);//reducing操作final Integer collect = Lists.newArrayList(1, 2, 3, 4, 5) .stream() .collect(Collectors.reducing(0, Integer::sum)); //当然Stream也提供了reduce操作final Integer collect = Lists.newArrayList(1, 2, 3, 4, 5) .stream().reduce(0, Integer::sum) 可能遇到的问题记录下生产中使用该工具遇到的一些小错误 toMap所产生的异常toMap的操作主要如下代码,异常来自两个方面 操作调用的是map.merge方法,该方法遇到value为null的情况会报npe,即使你使用的是hashMap可以接受null值,也照样报.搞不懂这里为什么这样设计. 未指定冲突合并策略,也就是第三个参数BinaryOperator&lt;U&gt; mergeFunction时遇到重复的key会直接抛IllegalStateException,因此需要注意. 总结到此对于collect的操作应该就很清晰了,希望通过这些例子能掌握核心,也就是Collector接口中那几个函数的作用,希望对你有帮助. 个人博客 mrdear.cn ,欢迎交流]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis源码分析(三)--动态Sql中的参数解析]]></title>
    <url>%2F2017%2F09%2F10%2Fmybatis%2FMybatis%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(%E4%B8%89)--%E5%8F%82%E6%95%B0%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Mybatis中参数解析对于开发人员来说是至关重要的,不然很容易出小问题,举个例子,假设现在方法为,当然这个是很糟糕的写法,这里只是想要搞清楚参数如何解析,项目中万万不可这样写. 参数输入解析12345678 //方法 User findUser(@Param("name") String name,int age,String email) //对应xml&lt;select id="findUser" resultType="cn.mrdear.users.dao.User"&gt; SELECT * FROM user WHERE username = #&#123;name&#125; AND age = #&#123;age&#125; AND email = #&#123;email&#125; &lt;/select&gt;//调用参数 final User user = userMapper.findUser("quding", 18, "qq@mail.com"); 那么这里Mybatis会怎么解析参数呢?这个xml会构造失败不?首先是MapperMethod中使用ParamNameResolver对输入参数解析,针对上述输入参数会得到下面的结果.1234567891011121314151617181920212223242526272829303132333435public ParamNameResolver(Configuration config, Method method) &#123; final Class&lt;?&gt;[] paramTypes = method.getParameterTypes();//获取参数类型,对于上述例子则是String,int,String final Annotation[][] paramAnnotations = method.getParameterAnnotations();//这里获取到的则是@Param,getParameterAnnotations方法也用到了动态代理. final SortedMap&lt;Integer, String&gt; map = new TreeMap&lt;Integer, String&gt;(); int paramCount = paramAnnotations.length; // get names from @Param annotations for (int paramIndex = 0; paramIndex &lt; paramCount; paramIndex++) &#123; if (isSpecialParameter(paramTypes[paramIndex])) &#123; //过滤其内部一些特殊类型 // skip special parameters continue; &#125; String name = null; for (Annotation annotation : paramAnnotations[paramIndex]) &#123; if (annotation instanceof Param) &#123; hasParamAnnotation = true; name = ((Param) annotation).value();//获取到'name'值 break; &#125; &#125; if (name == null) &#123; // @Param was not specified. if (config.isUseActualParamName()) &#123;//默认为true,因此编译后参数都是args0,args1之类,因此这里获取的也是args0... name = getActualParamName(method, paramIndex); &#125; //当上面配置为false的时候这里才会使用0,1代替,因此如果未开启则会报错 if (name == null) &#123; // use the parameter index as the name ("0", "1", ...) // gcode issue #71 name = String.valueOf(map.size());//上述都没的话则世界使用map的index. &#125; &#125; map.put(paramIndex, name); &#125; names = Collections.unmodifiableSortedMap(map); &#125; 那么执行完毕后对于上述例子,names里面如下图所示,由于config.isUseActualParamName()为true,所以#{0}这种写法这里并不支持,而且也不建议这种写法,无可读性.接下来执行method.convertArgsToSqlCommandParam(args)获取到实际输入的参数,对于上面例子我获取到的是个Map集合,如下图所示,对于单一实体例如User那么获取到的就是该实体.再看我所用的sql写法,那么这里只能获取到name的值,sql处理时就会报错.1SELECT * FROM user WHERE username = #&#123;name&#125; AND age = #&#123;age&#125; AND email = #&#123;email&#125; 由此可见针对多参数的输入,最佳解决方案是用@Param注解,其次为使用Map集合包裹参数,这样的话method.convertArgsToSqlCommandParam(args)得到的则是该Map集合. 动态sql渲染解析上述流程能得到所有的输入参数,那么接下来就是对sql的解析,下面把我们的sql变得复杂一些.(不要讨论sql的意义…这里只是分析参数如何解析)12345678910//mapper接口 User findUser(@Param("name") String name, @Param("user") User user,@Param("ids") List&lt;Long&gt; ids);//xml &lt;select id="findUser" resultType="cn.mrdear.users.dao.User"&gt; SELECT * FROM user WHERE username = #&#123;name&#125; AND age = #&#123;user.age&#125; AND email = #&#123;user.email&#125; OR id in &lt;foreach collection="ids" item="item" open="(" close=")" separator=","&gt; #&#123;item&#125; &lt;/foreach&gt; &lt;/select&gt; 按照上述流程Mybatis解析出来的输入参数如下图 接下进入DefaultSqlSession的处理中,在其中有如下方法会多参数进一步判断,可以看出对于单一参数为Collection或者Array时Mybatis都会给默认命名方案.(这里是在3.3.0之前的版本只会处理List)123456789101112131415private Object wrapCollection(final Object object) &#123; if (object instanceof Collection) &#123; StrictMap&lt;Object&gt; map = new StrictMap&lt;Object&gt;(); map.put("collection", object); if (object instanceof List) &#123; map.put("list", object); &#125; return map; &#125; else if (object != null &amp;&amp; object.getClass().isArray()) &#123; StrictMap&lt;Object&gt; map = new StrictMap&lt;Object&gt;(); map.put("array", object); return map; &#125; return object;&#125; 到了接下来转到执行器,使用DynamicContext构造动态sql所需要的上下文,对其构造函数分析执行到这里的话参数只有三种情况 null,无任何参数传入 Map类型，对于多参数,或者参数本身就是map再或者输入单一参数集合类型,数组类型都会转换为map 单一POJO类型.Mybatis这里要做的就是把参数的各种形式尽可能都放在ContextMap中,该ContextMap是绑定了Ognl的,方便Ognl直接从其中获取到值.123456789101112public DynamicContext(Configuration configuration, Object parameterObject) &#123; if (parameterObject != null &amp;&amp; !(parameterObject instanceof Map)) &#123; MetaObject metaObject = configuration.newMetaObject(parameterObject); //对于单个输入数据直接保存在ContentMap中 bindings = new ContextMap(metaObject); &#125; else &#123; bindings = new ContextMap(null); &#125; //输入参数形式为 _parameter : parameterObject bindings.put(PARAMETER_OBJECT_KEY, parameterObject); bindings.put(DATABASE_ID_KEY, configuration.getDatabaseId());&#125; SqlNodeSqlNode是动态Sql解析和完善ContextMap的地方,对于我上述sql会转换为其三个子类,相关解析方法都在其内部.解析后的sql如下图12SELECT * FROM user WHERE username = ? AND age = ? AND email = ? OR id in ( ?, ?, ?) 此时ContextMap如下,其中有_frch_item_2这种形式的参数,这是Mybatis对foreach解析后所生成的键,便于填充数据,具体可以看ForeachSqlNode那么接下来要做的事情就是一一设置进去这些值. ParameterHandler顾名思义,其提供void setParameters(PreparedStatement ps)对于sql参数设置的处理.分析下DefaultParameterHandler1234567891011121314151617181920212223242526272829303132333435363738394041@Override public void setParameters(PreparedStatement ps) &#123; ErrorContext.instance().activity("setting parameters").object(mappedStatement.getParameterMap().getId()); List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings(); if (parameterMappings != null) &#123; //parameterMappings存储着要设置进去的值类型等信息 for (int i = 0; i &lt; parameterMappings.size(); i++) &#123; ParameterMapping parameterMapping = parameterMappings.get(i); if (parameterMapping.getMode() != ParameterMode.OUT) &#123; Object value; String propertyName = parameterMapping.getProperty(); //AdditionalParameter是从ContextMap中copy到的,其没有的话说明是_parameter里面的值. if (boundSql.hasAdditionalParameter(propertyName)) &#123; // issue #448 ask first for additional params value = boundSql.getAdditionalParameter(propertyName); &#125; else if (parameterObject == null) &#123; value = null; &#125; else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) &#123; value = parameterObject; &#125; else &#123; //获取_parameter里面的值. MetaObject metaObject = configuration.newMetaObject(parameterObject); //其内部是一个递归实现获取. value = metaObject.getValue(propertyName); &#125; //typeHandle的处理 TypeHandler typeHandler = parameterMapping.getTypeHandler(); JdbcType jdbcType = parameterMapping.getJdbcType(); if (value == null &amp;&amp; jdbcType == null) &#123; jdbcType = configuration.getJdbcTypeForNull(); &#125; try &#123; typeHandler.setParameter(ps, i + 1, value, jdbcType); &#125; catch (TypeException e) &#123; throw new TypeException("Could not set parameters for mapping: " + parameterMapping + ". Cause: " + e, e); &#125; catch (SQLException e) &#123; throw new TypeException("Could not set parameters for mapping: " + parameterMapping + ". Cause: " + e, e); &#125; &#125; &#125; &#125; &#125; 那么看MetaObject的递归获取,递归是针对参数为user.username这样的话会先从_parameter中找到user,然后再调用user 的getUsername()方法获取到结果.123456789101112131415public Object getValue(String name) &#123; PropertyTokenizer prop = new PropertyTokenizer(name); //hasNext判断user.username这种类型 if (prop.hasNext()) &#123; MetaObject metaValue = metaObjectForProperty(prop.getIndexedName()); if (metaValue == SystemMetaObject.NULL_META_OBJECT) &#123; return null; &#125; else &#123; //递归获取 return metaValue.getValue(prop.getChildren()); &#125; &#125; else &#123; return objectWrapper.get(prop); &#125;&#125; 那么针对上面的例子,这里先是去boundSql中的addtionParameters中获取参数,该参数一般是sql解析时动态生成的,比如foreach生成的_frch_xx,获取不到的话再去原始的ParamsObject中获取,该处的解析为递归形式了. 总结Mybatis的SQL解析总体流程如下: 构造ParamtersMap,保存输入参数. 构造ContextMap,为OGNL解析提供数据. 读取xml.使用SqlSource与SqlNode解析xml中的sql,设置参数值到boundSql的addtionParameters中,其为ContextMap的一个副本. 根据boundSql.parameterMappings获取到参数,从addtionParameters与ParamtersMap中读取参数设置到PreparedStatement中 执行sql本文只分析了总体流程,其中有很多细节都忽略了,如遇到问题再看也不迟.]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis源码分析(二)--Sqlsession的执行流程]]></title>
    <url>%2F2017%2F09%2F09%2Fmybatis%2FMybatis%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(%E4%BA%8C)--Sqlsession%E7%9A%84%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[上一篇Mapper动态代理中发现Mybatis会对Mapper接口的方法转向mapperMethod.execute(sqlSession, args),那么该篇就学习Mybatis对于sql的执行总体流程,文章不会涉及很多细节点,重点学习其设计以及这样做的理由. SqlCommandSqlCommand是MapperMethod的一个内部类,其封装着要执行sql的id(xml的namespace+方法名)与类型(select,insert等),这些都是从MappedStatement中获取到,MappedStatement是mybatis初始化读取xml时所构造的对象,具体可以参考之前的文章.对于一个确定的Mapper接口中方法来说这个是确定的值.还有这里有些人认为是命令模式,我认为不是,这里只是该方法对应sql的唯一标识的体现,从下面代码Mybatis对其的使用来看,也不是命令模式具有的行为,而对于命令的执行实际上是sqlSession来执行的,而命令模式的要求是命令中封装委托对象,调用其excute()把任务交给委托执行的对象.Mybatis对sqlCommand的使用1234567891011121314public Object execute(SqlSession sqlSession, Object[] args) &#123; Object result; switch (command.getType()) &#123; case INSERT: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.insert(command.getName(), param)); break; &#125; case UPDATE: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.update(command.getName(), param)); break; &#125; ............... MethodSignature与ParamNameResolverMethodSignature也是MapperMethod中的一个内部类对象,其封装着该方法的详细信息,比如返回值类型,参数值类型等,分析该类可以得到Mybatis支持的返回类型有集合,Map,游标等各式各样,还支持自定义结果映射器.ParamNameResolver是用于方法参数名称解析并重命名的一个类,在Mybatis的xml中使用#{0},#{id}或者注解@Param()等写法都是合法的,为什么合法这个类就是解释,具体的分析过程因为跨度比较长,后面专用一篇文章来分析. INSERT,UPDATE,DELETE的结果处理对于这三种方法的执行,Mybatis会用rowCountResult()方法包裹结果,从源码中可以很清楚的看出来Mybatis只支持返回void,Integer,Long,Boolean类型的值,默认是int类型,这里建议数量查询使用int.123456789101112131415private Object rowCountResult(int rowCount) &#123; final Object result; if (method.returnsVoid()) &#123; result = null; &#125; else if (Integer.class.equals(method.getReturnType()) || Integer.TYPE.equals(method.getReturnType())) &#123; result = rowCount; &#125; else if (Long.class.equals(method.getReturnType()) || Long.TYPE.equals(method.getReturnType())) &#123; result = (long)rowCount; &#125; else if (Boolean.class.equals(method.getReturnType()) || Boolean.TYPE.equals(method.getReturnType())) &#123; result = rowCount &gt; 0; &#125; else &#123; throw new BindingException("Mapper method '" + command.getName() + "' has an unsupported return type: " + method.getReturnType()); &#125; return result;&#125; Select的处理Select是最复杂的处理,其拥有多样的返回值类型,从源码中可以发现Mybatis支持自定义结果映射器,集合返回,Map返回,游标返回以及单条返回.具体该方法是属于哪一种类型在MethodSignature中都有定义,这里不多叙述.123456789101112131415case SELECT: if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) &#123; executeWithResultHandler(sqlSession, args); result = null; &#125; else if (method.returnsMany()) &#123; result = executeForMany(sqlSession, args); &#125; else if (method.returnsMap()) &#123; result = executeForMap(sqlSession, args); &#125; else if (method.returnsCursor()) &#123; result = executeForCursor(sqlSession, args); &#125; else &#123; Object param = method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(command.getName(), param); &#125; break; SqlSession上述流程之后,SQL的执行就转交给SqlSession,这里会设置参数,去数据库查询,映射结果,可谓是Mybatis的核心.SqlSession下有如下四大对象. ParameterHandler: 处理参数设置问题 ResultHandler: 结果处理 StatementHandler: 负责连接数据库,执行sql Executor: 对上述过程的调度组织. Executor的桥接设计模式Exexutor是一种一对多的模式,所谓的一是对于调用方Client,其任务就是调度执行sql,获取结果返回,所谓的多是其实现可以有多种,比如Mybatis的SimpleExecutor,ReuseExecutor,BatchExecutor其实现这个功能的方式都有些差异,Mybatis在这里的实现就是采用了桥接设计模式,具体结构如下图.关于桥接模式或者其他设计模式可以参考此链接design_patterns因为对于调用方来说只关心接口,因此这里提供Exexutor接口,对于内部多种实现把公共的部分比如缓存处理提取出来作为抽象类BaseExecutor,抽象类具有抽象方法与具体方法,那么最适合作为执行模板.其不同的内容定义为抽象方法,由其子类SimpleExecutor,ReuseExecutor等来实现.这一分支可以视作模板设计模式.另外是一个CachingExecutor,Mybatis会在xml中根据配置cacheEnabled来初始化该类,默认为true,那么该类的作用也就是二级缓存.作为桥接类,其对其他的Executor进行调度,并缓存其结果,解耦接口与实现类之间的联系. 那么问题就来了 桥接模式是怎么体现的? 桥接模式主要是针对接口与实现类的桥接,按理说接口与实现类是属于强耦合的关系,那么使用桥接模式的话就可以去除这种耦合,桥接类中随时可以更换该接口的实现类,比如这里的CacheingExecutor其本身目的是二级缓存,但是二级缓存是针对Executor下的多个实现类,那么这里做下桥接则是一种很优雅的解决方式. 二级缓存为什么不用插件形式来实现,反而用桥接模式来实现呢? 这个问题估计需要我分析完插件设计后才能回答,也可能是其本身设计的问题.占坑. BaseExecutor是一种怎样的设计? 这里是很明显的模板设计,那么这里就要谈对抽象类以及接口的理解,个人认为抽象类与接口的不同之处在于接口定义的是协议,一般对外使用,抽象类定义的是过程,也就是模板,这也是抽象类中非抽象方法与抽象方法共存的优势. 除去上述问题,接下来的执行流程是很清晰的 BaseExecutor1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; BoundSql boundSql = ms.getBoundSql(parameter);//获取sql,此时还都是?占位符状态的sql CacheKey key = createCacheKey(ms, parameter, rowBounds, boundSql); //获取缓存key,根据id,sql,分页参数计算 return query(ms, parameter, rowBounds, resultHandler, key, boundSql);//跳到下面方法执行 &#125; @SuppressWarnings("unchecked") @Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; ErrorContext.instance().resource(ms.getResource()).activity("executing a query").object(ms.getId()); if (closed) &#123; throw new ExecutorException("Executor was closed."); &#125; //queryStack用于延时加载,暂时未研究,若配置不用缓存,则每次查询前清空一级缓存. if (queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) &#123; clearLocalCache(); &#125; List&lt;E&gt; list; try &#123; queryStack++; //缓存中取出数据,具体会在缓存详解中分析,这里只需要了解具体执行过程 list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null; if (list != null) &#123; //针对存储过程更新参数缓存 handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); &#125; else &#123; //缓存未中则去查数据库 list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; &#125; finally &#123; queryStack--; &#125; //这边是延迟加载的实现,不在本次分析内容中 if (queryStack == 0) &#123; for (DeferredLoad deferredLoad : deferredLoads) &#123; deferredLoad.load(); &#125; // issue #601 deferredLoads.clear(); if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) &#123; // issue #482 clearLocalCache(); &#125; &#125; return list; &#125; 接下来是DB的查询,DB的查询主要由其子类来实现.123456789101112131415161718private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; List&lt;E&gt; list; //这里先放入缓存中占位符,一级缓存的实现 localCache.putObject(key, EXECUTION_PLACEHOLDER); try &#123; //调用子类的方法处理,模板方法的体现 list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql); &#125; finally &#123; localCache.removeObject(key); &#125; //放入查询结果缓存,一级缓存的实现 localCache.putObject(key, list); //存储过程还需要缓存参数 if (ms.getStatementType() == StatementType.CALLABLE) &#123; localOutputParameterCache.putObject(key, parameter); &#125; return list;&#125; SimpleExecutor按照上述模板的执行,SimpleExecutor是真正从数据库查询的地方,这里也能看出来模板设计模式的好处,将缓存处理与实际数据查询分离解耦,各司其职.查询是要经过StatementHandler组织ParameterHandler,ResultHandler的处理过程,那么StatementHandler承担了什么样的角色?123456789101112131415@Overridepublic &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); //创建statement StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); //获取连接,设置参数等预处理 stmt = prepareStatement(handler, ms.getStatementLog()); //执行查询并映射结果 return handler.&lt;E&gt;query(stmt, resultHandler); &#125; finally &#123; closeStatement(stmt); &#125;&#125; …篇幅已经过长了,剩下的StatementHandler等也是类似的设计,不打算再继续分析了,有兴趣的同学可以自己研究一下.接下来会对一些关键点的实现分析,比如sql的解析,延迟加载的实现等.]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis源码分析(一)--Mapper的动态代理]]></title>
    <url>%2F2017%2F09%2F07%2Fmybatis%2FMybatis%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(%E4%B8%80)--Mapper%E7%9A%84%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[工作中用的最多的就是Mybatis这款半自动ORM框架,用的久却对其了解不是很深,因此打算开一系列文章对其进行解析,顺便对知识进行查漏补缺.本篇是对Mapper动态代理原理的详解. 代理模式定义为另一个对象提供一个替身或者占位符以控制对这个对象的访问.也就是说目的是控制对象形式其职责.当然也可以增强其职责,比如Spring AOP. 代理模式类图由下图分析,代理模式所需要的角色为: 对外的行为接口Subject,对于调用方Client可见 RealSubject真实的Subject,其包含具体的接口行为,对于Client不可见 代理类Proxy,其是RealSubject的替身,也可以当成对RealSubject的一层包装,对于Client不可见. JDK动态代理Example案例采取Java的动态代理形式开发,按照上述类图定义角色Subject12345678public interface Subject &#123; /** * 反转输入的input字符串 * @param input 要反转的串 * @return 反转后的串 */ String reversalInput(String input);&#125; RealSubject1234567public class RealSubject implements Subject &#123; public String reversalInput(String input) &#123; System.out.println("我是RealSubject: "+input); return new StringBuilder(input).reverse().toString(); &#125;&#125; SubjectProxy该类实现了InvocationHandler,实际上是对调用的拦截,拦截后转向真实对象的调用,从而拿到正确的结果.是不是很像装饰者模式?其实也可以这样理解,设计模式之前本身就有很多关联性,不需要认定某一个行为就是单一的某个模式,从产生效果来看这里的SubjectProxy实际上就是对RealSubject的装饰,只不过这个装饰并没有添加新功能. 12345678910111213141516public class SubjectProxy implements InvocationHandler &#123; private Object target; public SubjectProxy(Object target) &#123; this.target = target; &#125; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println("proxy subject is "+proxy.getClass()); System.out.println("real subject : "+ToStringBuilder.reflectionToString(target)); System.out.println("method: "+method); System.out.println("args: "+ ToStringBuilder.reflectionToString(args)); return method.invoke(target, args); &#125;&#125; Client12345678910111213public class Client &#123; public static void main(String[] args) &#123; RealSubject subject = new RealSubject(); Subject proxyInstance = (Subject) Proxy.newProxyInstance( Subject.class.getClassLoader(), new Class[]&#123;Subject.class&#125;, new SubjectProxy(subject)); System.out.println(proxyInstance.reversalInput("hello world")); &#125;&#125; 输出123456proxy is class com.sun.proxy.$Proxy0target proxy: cn.mrdear.proxy.RealSubject@51016012[]method: public abstract java.lang.String cn.mrdear.proxy.Subject.reversalInput(java.lang.String)args: [Ljava.lang.Object;@29444d75[&#123;hello world&#125;]我是RealSubject: hello worlddlrow olleh 分析1.动态代理哪里体现了动态? 对于常规Java类变量创建要求有.java文件,然后编译成.class文件,然后虚拟机加载该.class文件,最后才能生成对象.但是对于Subject proxyInstance该代理类其是不存在.java文件的,也就是该对象的.class文件是动态生成的,然后虚拟机加载该class文件,创建对象.在Proxy.java中有如下代码动态生成class文件,感兴趣的话可以研究研究,这里不多深入.1234/* * Generate the specified proxy class. */byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces, accessFlags); 2.JDK动态代理的要求 JDK动态代理只能针对接口,如果要针对普通类则可以考虑CGLib的实现,这里不多分析.其次动态代理的要求有接口类Subject,InvocationHandler代理方法类存在,才能创建出代理对象,代理对象的执行方法都被InvocationHandler接口所拦截,转向真实类的执行或者你想要的操作. Mybatis的动态Mapper由上面内容可以看出JDK动态代理需要接口,真实实现类,Clinet调用方,在常规的Mybatis的Mapper代理中接口就是Mapper,Client是service,那么真实的实现类是什么?显而易见这里就是Mapper代理的关键点. MapperProxyFactory顾名思义该类是产生Mapper接口的工厂类,其内部有如下方法,由此可以看出MapperProxy是方法拦截的地方,那么到此动态代理所需要的必须角色都以凑齐,那么接下来分析最重要的MapperProxy方法拦截.123protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy); &#125; MapperProxy该类是Mapper接口的Proxy角色,继承了InvocationHandler,所以具有方法拦截功能,看代码注释.123456789101112131415@Overridepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; if (Object.class.equals(method.getDeclaringClass())) &#123; ////判断是否为object,因为其不是接口 return method.invoke(this, args); &#125; else if (isDefaultMethod(method)) &#123; //判断是否为接口总的默认方法,jdk8允许接口中声明默认方法. return invokeDefaultMethod(proxy, method, args); &#125; &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; //对正常Mapper请求的处理 final MapperMethod mapperMethod = cachedMapperMethod(method); return mapperMethod.execute(sqlSession, args);&#125; 对于正常的Mapper接口中的方法调用,mybatis都会转向到MapperMethod的execute方法中执行,拿到结果返回给调用方Client,整个代理过程结束.对于正常调用是有缓存的,并且该代理类是项目启动时就生成好的,对于性能影响并不是很大实用性还是很高的. 这里要注意下对于默认接口方法的处理invokeDefaultMethod(proxy, method, args),该方法中每次都直接生成代理类,对性能是一种损耗应该不小,所以不建议在Mapper接口中写默认方法.123456789101112131415@UsesJava7private Object invokeDefaultMethod(Object proxy, Method method, Object[] args) throws Throwable &#123; final Constructor&lt;MethodHandles.Lookup&gt; constructor = MethodHandles.Lookup.class .getDeclaredConstructor(Class.class, int.class); if (!constructor.isAccessible()) &#123; constructor.setAccessible(true); &#125; final Class&lt;?&gt; declaringClass = method.getDeclaringClass(); return constructor .newInstance(declaringClass, MethodHandles.Lookup.PRIVATE | MethodHandles.Lookup.PROTECTED | MethodHandles.Lookup.PACKAGE | MethodHandles.Lookup.PUBLIC) .unreflectSpecial(method, declaringClass).bindTo(proxy).invokeWithArguments(args);&#125; 总结从上面来看动态代理的最大的好处就是接口(不单指Java的interface,也包括CGLib的动态代理实现)与其实现类的解耦,原本接口和动态类之间是强关联状态,接口不能实例化,实现类必须实现接口的所有方法,有了动态代理之后,接口与实现类的关系并不是很大,甚至不需要实现类就可以完成调用,比如Mybatis这种形式,其并没有创建该接口的实现类,而是用一个方法拦截器转向到自己的通用处理逻辑.另外就是Spring AOP的动态代理,解耦后自然可以实现对原有方法增强的同时又对其代码的零侵入性.最后Mybatis的Mapper动态代理实现原理还是很清晰的,下一篇具体分析MapperMethod,顺便学习Mybatis的各种设计模式.]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cnpm导致IDEA对于Angular项目提示失效]]></title>
    <url>%2F2017%2F08%2F26%2Fweb%2FCnpm%E5%AF%BC%E8%87%B4IDEA%E5%AF%B9%E4%BA%8EAngular%E9%A1%B9%E7%9B%AE%E6%8F%90%E7%A4%BA%E5%A4%B1%E6%95%88%2F</url>
    <content type="text"><![CDATA[最近写Angular项目的时候,IDEA的提示时而有时而没有,找了好久的原因才发现是cnpm的锅.对于cnpm install,安装的angular依赖时链接方式引入,如下图 对于npm install,安装后的依赖时实在的文件,如下图 解决方案老老实实的用npm命令,觉得慢的话可以使用http代理,mac下的shadowsocks支持直接导出http代理,复制命令后粘贴到终端,即可实现终端翻墙. 如果你不会翻墙,可以参考我之前写的教程 如何搭建属于自己的shadowsocks]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>angular</tag>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动漫推荐]]></title>
    <url>%2F2017%2F08%2F25%2F%E5%8A%A8%E6%BC%AB%2F%E5%8A%A8%E6%BC%AB%E6%8E%A8%E8%8D%90%2F</url>
    <content type="text"><![CDATA[动漫推荐标签（空格分隔）： 动漫 从小就是个动漫爱好者,年轻时追番,现在老了追不动了,只追动漫电影和一些经典动漫剧场版.我也不知道自己是什么风格的动漫迷,只是觉得好看,有共鸣就认为是好作品.人们总是把自己喜爱的东西推荐给``别人,我也不例外,下面推荐我认为很不错的片子.(排名不分先后) 2017-12-24 更新我的英雄学院补番时发现,不同于一般的热血番,我的英雄学院是一部很纯粹的少年追寻成为一名真正的英雄这一梦想的历程,人物个性很鲜明,故事很带感,配上这突变的画风一不小心就看入了神.所谓英雄就是·····能打破逆境的人啊！这是里面的经典台词,男主虽然表面上懦弱,但是其内心相当强大,为了成为英雄,付出超过别人百倍的努力,不断打破逆境的过程是其向着梦想前进的证明. 2017-11-26 更新剑风传奇三部曲剑风传奇三部曲是指其三个剧场版剑风传奇 黄金时代篇1：霸王之卵,剑风传奇 黄金时代篇2：多尔多雷攻略,剑风传奇 黄金时代篇3：降临,三部曲之后是TV版的故事,如果要观看要切记先看未删减的剧场版再看TV版. 剑风传奇是暗黑风格的战争与神话史诗,主角的不屈和坚毅,奋力的对命运进行抗争,坚信自己的道路能让你看的热血沸腾. 你的名字。作为新海诚的粉丝对于其作品无脑推.从星之声中空间的距离到秒速五厘米心灵上的距离再到言叶之庭年龄中的距离,新海诚一直在讲述看似美好但最终无法在一起的爱情.你的名字,讲述了时空上的距离,但是让人感到美好的是有情人终成眷属.另外音乐是真的不错,推荐英文版原声带,网易不给外链我这就只能作罢了. 2017-08-25 更新异邦人 无皇刃谭2017年初来在上海实习时看的,故事很温情,对于刚到一个陌生城市打拼的青年来说很容易引起共鸣,也因此我感触颇深,异邦人都是孤独的存在,内心是挣扎的,想要找到自己的归属,然而哪里才是归属?背景音乐很赞,听起来内心有点温暖,但是又会觉得很伤感,充满了无奈 秒速五厘米大概高一的时候第一次看了这个作品,唯美的画面,伤感的故事,再加上年少懵懂的恋爱经历,从此新海诚一生粉.回想以前是不是很多事情都可以 One more time,One more chance 你看起来很好吃相当有趣的一部动漫,看起来完全没有负重感,从母爱,父爱,独立,自强等方面诠释了一个龙的成长.电影版是温情的结局,萌萌的画面,治愈的故事,给心情带来不一样的体验.记住:哭闹的孩子 不管在哪里都会被霸王龙叼走 萤火之森无法触碰的爱情,只是梦中的憧憬,这样的动漫是提醒你,在你年轻的时候曾经心里也住着一个无法触碰的他/她. fate stay night作为番剧来说最喜欢的一个系列,fate stay night也是最早出来的一部,配乐,战斗,剧情都那么引人入胜,虽然fate zero也非常不错,但是让我来选择的话还是该部更让我难忘. 怪物之子细田守家族系列电影,复杂成长的环境会造成我们内心的空洞,然而填补这些空洞的方式就是父母的爱,即使在你眼中认为一无是处,半吊子的父亲,在最关键的时候也会奋不顾身的化身为剑去填补你内心的黑暗,细细回想小时候学习父亲的一举一动或许是每个人都无法忘记的时刻. 斩·赤红之瞳有点虐的番剧,几乎每个角色都是主角的设定,所以每个人角色的个性都很鲜明,也导致了每一个人物死去所带来的感染力.尤其看到结局,最初的一群角色就剩一个赤瞳了,其帮助革命军成立了新国家,然而其还要背负革命军为了革命所做的恶.该番剧有点杀红了眼,所以看的话就要做好心理准备. 亚人这两周把亚人的电影版和TV版都看了一遍,首先电影版绝对是圈钱的作品,还是直接看TV版本吧,剧情一样.整个看下来感觉亚人一部很理性的动漫,无论是主角的处事风格,还是亚人和搜查官的联合,都是利益组建了一个关系网,截止到第二季来说目前还是这样的理性,不知道后期有没有变化.能把不死这一老套的技能演绎出这么多惊心动魄的故事场景的估计也只有亚人了吧.另外这动漫也透漏出政府只是比较大的土匪头子而已. 犬夜叉剧场版犬夜叉是儿时的回忆,尤其是其四个剧场版,小时候最喜欢看天下霸道之剑这一部,犬夜叉相比火影之类动漫的优点是其有一条纠缠的爱情线,犬夜叉与阿离(我喜欢台版的这个翻译),犬夜叉与桔梗这之间复杂但却互相信任的关系.最喜欢的人物莫过于桔梗,其只是想过上普通的生活,然而命运却让其至死也无法得到想要的生活,悲情人物总能引起观看者的同情.]]></content>
      <categories>
        <category>动漫</category>
      </categories>
      <tags>
        <tag>动漫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenVZ的VPS加速指南]]></title>
    <url>%2F2017%2F08%2F13%2F%E5%B7%A5%E5%85%B7%2FOpenVZ%E7%9A%84VPS%E5%8A%A0%E9%80%9F%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[实现理论OpenVZ架构的VPS加速选择比较少,不然KVM方便,除去双边加速比如FinalSpeed等软件后可用选择并不多,其中比较好的方案是Google BBR加速,为了在OpenVZ架构上使用必须借助UML这一子linux系统. 所谓的UML全称为User Mode Linux,允许用户在Linux中以一个进程的方式再运行一个lInux,那么就很容易实现我们所需要的加速架构,原理是在UML中启动Shadowsocks,然后访问该Shadowsocks实现加速. 安装指南拿来主义原则,给出原博主链接OpenVZ的UML+BBR加速一键包,按照文章描述步骤配置即可,在这里做一些额外的补充. 宿主机请求转发一键脚本配置完毕后其是运行在UML主机里面的程序,其内网相对宿主机ip为10.0.0.2,但我们只能访问到宿主机,需要如下命令转发,其中端口8888改成你的ss配置的端口即可. 12iptables -t nat -A PREROUTING -i venet0 -p tcp --dport 8888 -j DNAT --to-destination 10.0.0.2iptables -t nat -A PREROUTING -i venet0 -p udp --dport 8888 -j DNAT --to-destination 10.0.0.2 接下来像以往一样访问即可.]]></content>
      <categories>
        <category>vps</category>
      </categories>
      <tags>
        <tag>shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何搭建属于自己的shadowsocks]]></title>
    <url>%2F2017%2F08%2F07%2F%E5%B7%A5%E5%85%B7%2F%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E5%B1%9E%E4%BA%8E%E8%87%AA%E5%B7%B1%E7%9A%84shadowsocks%2F</url>
    <content type="text"><![CDATA[shadowsocks是什么?能看到这篇文章的人大概对这个都有些了解,可以理解为一个代理隧道,通过其可以代理到指定的vps服务器,然后服务器去获取到你所访问的内容再返回给你.如果你把服务器当做跳板机的话,那么shadowsocks就是你与跳板机之间的关联. vps服务器的选择vps服务器有很多,这里推荐下搬瓦工KVM架构的机器,推荐理由便宜,可靠,支持支付宝. 不介意可以使用我的邀请链接: https://bandwagonhost.com/aff.php?aff=17639 注册后选择最便宜款的KVM架构,重要的事情说三遍,KVM架构,KVM架构,KVM架构.至于好处是可以使用锐速,能让你的shadowsocks更加快.接下来是选择付款方案,一般选择$19.9的年付,三四个小伙伴一起用,平摊这个费用的话,就相当划算了.买完后会进去类似的管理后台,选择一键安装即可.到这里,vps服务端的shadowsocks就部署完毕了.接下来是客户端连接. shadowsocks客户端在github上有各个平台的客户端https://github.com/shadowsocks,windows一般用shadowsocks-windows,mac用ShadowsocksX-NG,linux则用shadowsocks-qt5,下载对应客户端,配置好vps生成的shadowsocks端口和密码,启用即可,其主要作为一个本地服务器,其他应用软件通过其余vps服务器通信. 如何访问?浏览器安装插件switchyomega,该插件会代理浏览器的请求链接,根据规则列表决定该链接是否要使用shadowsocks代理.首先新建一个代理模式,该模式下所有请求都会走shadowsocks.其次建立一个自动情景切换模式,该模式会根据配置的规则自动选择对应的情景模式来处理.该模式主要分为三部分,第一部分是用户自定义,比如图片中我指定匹配*.github.com的连接走的是ss情景模式.第二部分是规则列表,我配置的为https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt,该文件中是被墙的一些地址,这些地址都走ss情景模式,其余的都是直接连接. 接下来就可以访问google了. 参考连接锐速安装教程: https://github.com/91yun/serverspeederGoogle BBR : https://teddysun.com/489.html]]></content>
      <categories>
        <category>vps</category>
      </categories>
      <tags>
        <tag>shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven仓库清理脚本]]></title>
    <url>%2F2017%2F07%2F29%2F%E5%B7%A5%E5%85%B7%2Fmaven%E4%BB%93%E5%BA%93%E6%B8%85%E7%90%86%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[工作中本地maven仓库随着项目增多会变得越来越大,看着心烦,于是想着清理.没有发现很好的清理策略,只能从文件以及文件夹修改时间上入手,修改时间小于指定时间的文件夹以及文件都给删除,循环清理几次后仓库应该就干净了. 附上清理脚本,实际上就是递归遍历文件夹然后判断文件更新时间,对比后决定是否要删除.首次清理后仓库从1.5G变为650M,清爽了不少.123456789101112131415161718192021222324252627282930313233343536import osimport shutilfrom datetime import datetime# maven仓库地址mvnHome = "/Users/niuli/.m2/repository"# 删除该日期前的文件以及文件夹deleteDateBefore = datetime(2017,4,1,0,0,0)def listPathAndClean(pathContext): pathDir = os.listdir(pathContext) for filename in pathDir: filepath = os.path.join(pathContext, filename) currentTimeFile = datetime.fromtimestamp(os.path.getmtime(filepath)) # 对比时间 if deleteDateBefore &gt; currentTimeFile: print("filePath:"+filepath+"-----updatetime:"+str(currentTimeFile)) print('delete this') if (os.path.isdir(filepath)): shutil.rmtree(filepath) else: os.remove(filepath) continue # 不到期的则深入遍历 if os.path.isdir(filepath): listPathAndClean(filepath)if __name__ == '__main__': print(deleteDateBefore) print('start list should delete path') listPathAndClean(mvnHome)]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven子模块打包后拷贝目标文件到父模块]]></title>
    <url>%2F2017%2F07%2F29%2F%E5%B7%A5%E5%85%B7%2FMaven%E5%AD%90%E6%A8%A1%E5%9D%97%E6%89%93%E5%8C%85%E5%90%8E%E6%8B%B7%E8%B4%9D%E7%9B%AE%E6%A0%87%E6%96%87%E4%BB%B6%E5%88%B0%E7%88%B6%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[看着这个标题一定想怎么会有这么奇怪的需求….嗯,我也认为这个是很奇怪的需求,但实际上确实存在. 问题最近对公司一个大项目进行整改,该项目是写在一个模块下,也就是一个Maven项目,因此打算把其更改为Maven多模块项目.目录结构的变化如下:原目录结构12345buy ---src ---main ---test ---conf 更改后的为,也就是按照业务分为三个部分,其中gateway是打包的入口,不含有业务逻辑,其引用其他两个模块.1234567891011121314buy ---buy-shop ---src ---main ---test ---buy-course ---src ---main ---test ---buy-gateway ---src ---main ---test ---conf 那么自然而然打包后生成的buy.war就到了buy-gateway/target这个目录下,对于master分支的代码是生成在buy/target目录下,这样就倒是线上的自动化打包失效,首先保证master能打包成功就不能更改线上的配置,因此需要把buy-gateway/target/buy.war打包成功后拷贝到buy/target/buy.war,保证线上打包脚本的运行. 解决方案解决方案是maven-dependency-plugin这款插件,该插件有copy功能,可以自由选择target目录下的任意文件拷贝(要注意该插件不同版本配置是有差异的,如果一直不成功就要检查下配置)12345678910111213141516171819202122232425262728&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;artifactItems&gt; &lt;!--把target目录下的war拷贝到buy/target下--&gt; &lt;artifactItem&gt; &lt;groupId&gt;$&#123;project.groupId&#125;&lt;/groupId&gt; &lt;artifactId&gt;$&#123;project.artifactId&#125;&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;type&gt;$&#123;project.packaging&#125;&lt;/type&gt; &lt;overWrite&gt;true&lt;/overWrite&gt; &lt;outputDirectory&gt;$&#123;project.parent.build.directory&#125;&lt;/outputDirectory&gt; &lt;destFileName&gt;buy.war&lt;/destFileName&gt; &lt;/artifactItem&gt; &lt;/artifactItems&gt; &lt;/configuration&gt; &lt;/plugin&gt; 该模块可以用于各种资源的拷贝,因此不要局限于war包 备注:maven中常见的变量 maven常用配置的变量]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[病态的开发模式]]></title>
    <url>%2F2017%2F07%2F28%2F%E9%9A%8F%E8%B0%88%2F%E7%97%85%E6%80%81%E7%9A%84%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[转正后接手越来越多的需求,从表结构设计,到编码实现DO与Dao,Domian与Repository,DTO与Service,VO与API,看起来挺美好的,但是无论对于DO还是Domain还是DTO或着VO来说其只是数据的承载,在各个层次中传输的一种DTO形式.那么这是面向对象吗? 我苦恼于这个问题,不清楚自己做的事情有什么意义,每次需求最重要的部分就是建立表了,然后”重复性”的写各个层次,顶多用点设计模式在service,strategy,factory等之上,这种开发使我产生了厌烦的情绪,我想这个应该不是所谓的面向对象. 查询一些资料,发现疑惑的不止我一个,我得知贫血模型这一关键词,所谓的贫血模型指领域对象里只有get和set方法（POJO），所有的业务逻辑都不包含在内而是放在Business Logic层。也就是目前大多数Java项目使用的结构,这样的结构决定了实现之前必须要先设计表结构.那么这和面向对象就没什么关联了. 与贫血模型相对应,充血模型也就是所谓的面向对象形式,我还没有去用过,不敢枉加主观看法,随着搜索我发现了DDD即领域驱动设计这一充血模型的实现,打算好好看看. 无论怎么样,我认为Java WEB目前的开发形式是有点小问题的 希望后续的学习能够解决我的疑问.]]></content>
      <categories>
        <category>随谈</category>
      </categories>
      <tags>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于老项目替换dubbo的一点经验]]></title>
    <url>%2F2017%2F07%2F23%2Fdubbo%2F%E5%85%B3%E4%BA%8E%E8%80%81%E9%A1%B9%E7%9B%AE%E6%9B%BF%E6%8D%A2dubbo%E7%9A%84%E4%B8%80%E7%82%B9%E7%BB%8F%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[背景公司一直以来使用内部编写的一个rpc框架,简称old_rpc这套RPC框架,由于历史原因,old_rpc存在如下缺点. old_rpc已经很久没人维护了,因此出了错误很难定位到具体的原因. old_rpc本身只是RPC框架,随着项目的增多各个项目之间的依赖关系已经很复杂了,需要一套支持服务治理的解决方案. old_rpc缺乏监控平台,对于动态部署,增加机器或者减少机器都比较麻烦. …这些缺点已经严重影响到线上稳定性,本文就dubbox替换掉old_rpc方案做的一个调研,对工作量,替换后的稳定性做一个评估,以供大家参考. 替换要求 支持平滑上线,也就是说替换后依然支持现有的测试系统,发布系统. 替换必须尽可能小的缩小对业务的影响,代码层面上来看就是业务处理代码中不应该有替换的代码 短期内需要支持dubbox与old_rpc两套方案,并且两套方案可以快速切换,防止替换后线上出现不可预料的问题. 替换思路 saturn作为服务提供者,替换比较简单,只需要在原有基础上,增加dubbo协议的Service. vienna作为消费者,使用dubbo协议引入dubbo的service vienna增加断路器配置,对于repo层引入的service,dubbox作为主service,old_rpc作为备份service,当主service调用失败则自动切换到备份service进行重试,此过程需要有监控. dubbox github: https://github.com/dangdangdotcom/dubboxclone下来后使用mvn package -DskipTests,会打包该项目,生成主要的dubbo.jar,以及管理平台dubbo-admin.war,监控平台dubbo-simple-monitor.tar.gz.我已经把相关jar,deploy到公司的nexus上了.mvn的pom中直接引入如下依赖,这里需要去除Spring依赖,dubbox是基于Spring3开发的,强制引入会与现有项目产生冲突.另外dubbox添加了kryo和FST序列化支持,以及多种新特性,使用的话均需要引入相应的jar,具体参考项目的github.1234567891011&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.8.4&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; zk注册中心dubbo的注册如下所示:实际操作下来,第三层还会有routers,configurators节点,当在dubbo-admin平台操作该service时,比如倍权,该操作会存在在这些节点中. 服务提供者saturnsaturn作为服务提供者,其任务是抛出新的dubbo服务RPC接口.在引入上述pom后,需要做少量的配置. dubbo基本配置因此demo只测试能否实现,每一个配置的详细内容并未研究,详细可以参考官方文档配置.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Configurationpublic class DubboConfig &#123; /** * 注册中心配置 */ @Bean public RegistryConfig registry() &#123; RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setAddress("115.159.185.14:2181"); registryConfig.setProtocol("zookeeper"); return registryConfig; &#125; /** * 当前应用配置 */ @Bean public ApplicationConfig application() &#123; ApplicationConfig applicationConfig = new ApplicationConfig(); applicationConfig.setName("saturn"); return applicationConfig; &#125; /** * 监控配置,监控需要dubbo-monitor */ @Bean public MonitorConfig monitorConfig() &#123; MonitorConfig mc = new MonitorConfig(); mc.setProtocol("registry"); return mc; &#125; /** * 提供者监控服务 */ @Bean public ProviderConfig provider() &#123; ProviderConfig providerConfig = new ProviderConfig(); providerConfig.setMonitor(monitorConfig()); return providerConfig; &#125; /** * 消费者监控 */ @Bean public ReferenceConfig referenceConfig() &#123; ReferenceConfig rc = new ReferenceConfig(); rc.setMonitor(monitorConfig()); return rc; &#125; /** * RPC协议配置 */ @Bean public ProtocolConfig protocol() &#123; ProtocolConfig protocolConfig = new ProtocolConfig(); protocolConfig.setPort(20880); return protocolConfig; &#125; &#125; 提供服务服务的提供利用的是ServiceBean包裹,形成该bean的代理类,可以写一个通用的配置函数123456789101112131415/** * 通用service配置类 * @param saturnService 对应服务 * @return dubbo服务 */private &lt;T&gt; ServiceBean&lt;T&gt; configService(T saturnService) &#123; ServiceBean&lt;T&gt; serviceBean = new ServiceBean&lt;&gt;(); serviceBean.setProxy("javassist"); serviceBean.setVersion("1.0"); serviceBean.setInterface(saturnService.getClass().getInterfaces()[0].getName()); serviceBean.setRef(saturnService); serviceBean.setTimeout(2000); serviceBean.setRetries(3); return serviceBean;&#125; 那么我想要抛出IUserService这个服务,只需要如下几行代码1234@Beanpublic ServiceBean&lt;IUserService&gt; userServiceExport(IUserService userService) &#123; return configService(userService);&#125; 到此提供者配置完毕. 服务消费者vienna(无断路器版本)vienna作为服务消费者与提供者一样也需要基本的dubbo配置,两者配置几乎一模一样. dubbo基本配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@Configuration@EnableAspectJAutoProxypublic class DubboConfig &#123; /** * 注册中心 */ @Bean public RegistryConfig registry() &#123; RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setAddress("115.159.185.14:2181"); registryConfig.setProtocol("zookeeper"); registryConfig.setTimeout(60000);// vienna不知道为什么链接zk很慢 return registryConfig; &#125; /** * 应用信息,计算依赖关系 */ @Bean public ApplicationConfig application() &#123; ApplicationConfig applicationConfig = new ApplicationConfig(); applicationConfig.setName("vienna"); return applicationConfig; &#125; /** * 监控中心地址 */ @Bean public MonitorConfig monitorConfig() &#123; MonitorConfig mc = new MonitorConfig(); mc.setProtocol("registry"); return mc; &#125; /** * 提供者监控服务 */ @Bean public ProviderConfig provider() &#123; ProviderConfig providerConfig = new ProviderConfig(); providerConfig.setMonitor(monitorConfig()); return providerConfig; &#125; /** * 消费者监控 */ @Bean public ReferenceConfig referenceConfig() &#123; ReferenceConfig rc = new ReferenceConfig(); rc.setMonitor(monitorConfig()); return rc; &#125; /** * 协议配置,自身无提供者的话可以不配置 */ @Bean public ProtocolConfig protocol() &#123; ProtocolConfig protocolConfig = new ProtocolConfig(); protocolConfig.setPort(20880); return protocolConfig; &#125;&#125; 配置消费者消费者是用ReferenceBean类来代理的,可以像提供者那样写一个通用的处理方法1234567891011121314/** * 基本配置类 * @param serviceReference 接口 */private &lt;T&gt; ReferenceBean&lt;T&gt; configReference(Class&lt;T&gt; serviceReference) &#123; ReferenceBean&lt;T&gt; ref = new ReferenceBean&lt;&gt;(); ref.setVersion("1.0"); ref.setInterface(serviceReference); ref.setTimeout(2000); ref.setRetries(3); ref.setCheck(false); ref.setLoadbalance("roundrobin"); return ref;&#125; 那么引用服务也就只需要几行代码即可,为了更好的与old_rpc服务区分对于dubbo引入的服务都加上dubbo前缀命名.1234@Bean(name = "dubboUserService")public ReferenceBean&lt;IUserService&gt; userService() &#123; return configReference(IUserService.class);&#125; 替换old_rpc无断路器版本替换就很简单了,找到引用该服务的地方,在Spring注入时为其选择注入dubbo服务即可.问题是一旦该服务出现了问题,那么需要手动切换回old_rpc服务.12@Resource private IUserService dubboUserService; 服务消费者vienna(断路器版本)断路器本身是做服务降级,防止系统因一个服务出问题而产生雪崩效应,对于当前系统的两套RPC方案可以利用这一点把要替换掉的old_rpc作为降级服务,当dubboService出现异常时可以立即去调取old_rpc的服务,从而保证系统的健壮性. 断路器要求 业务代码无侵入,可以使用方法级别的注解控制该方法是否走断路器.稳定后可以直接删除,不留痕迹. 支持自动熔断,自动恢复 有支持集群的监控服务,方便排查出现问题的服务. 断路器依赖对于上述要求,符合条件,又经得起生产考验的大概只有hystrix了,github地址为 https://github.com/Netflix/Hystrix,pom依赖如下,主要是核心服务包,注解包,监控包.12345678910&lt;dependency&gt; &lt;groupId&gt;com.netflix.hystrix&lt;/groupId&gt; &lt;artifactId&gt;hystrix-javanica&lt;/artifactId&gt; &lt;version&gt;1.5.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.netflix.hystrix&lt;/groupId&gt; &lt;artifactId&gt;hystrix-metrics-event-stream&lt;/artifactId&gt; &lt;version&gt;1.5.12&lt;/version&gt; &lt;/dependency&gt; 实现思路实现思路与feign对hystrix的包装很相像,以UserRepo为例,UserRepo中引入了userService服务,那么要自动切换则需要两个UserRepo,一个是引用了dubbox的dubboUserService,一个是引用了old_rpc的old_rpcUserService.断路器是方法级别的监控,使用AOP可以轻松地拦截UserRepo中每一个方法的执行,在执行时使用hystrix包装,执行失败时再使用另一个UserRepo重新执行该方法.上述流程有几个要点: 需要通过引用dubbo服务的UserRepo获取到引入old_rpc的UserRepo 需要获取到UserRepo中全部的public方法,方便二次调用. 可以从UserRepo中得到断路器的配置,比如分组,线程池等信息. 增强Repo功能上述的几个要点需要在UserRepo中附加的功能使用一个接口来抽象.12345678910111213141516171819public interface IDubboRepoProxy extends InitializingBean,ApplicationContextAware &#123; /** * 获取使用dubbo服务调用的Repo */ IDubboRepoProxy getDubboRepo(); /** * 获取当前类所有的public方法 * @return 键与值都是该方法 */ Map&lt;Method, Method&gt; getAllPublicMethods(); /** * 得到断路器的配置 */ HystrixCommand.Setter getHystrixSetter();&#125; 为了让实现类更少的写代码,再为其定义一个抽象类,该抽象类主要负责接口功能的实现,其中initOtherRepo作为抽象方法,需要子类来实现,也就是初始化备份的Repo.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public abstract class DubboRepoProxyImpl&lt;T extends IDubboRepoProxy&gt; implements IDubboRepoProxy&#123; @Getter private ApplicationContext context; @Setter private T otherRepo; private Map&lt;Method, Method&gt; publicMethodMap = Maps.newHashMap(); private HystrixCommand.Setter setter; @Override public IDubboRepoProxy getDubboRepo() &#123; return otherRepo; &#125; @Override public Map&lt;Method, Method&gt; getAllPublicMethods() &#123; return publicMethodMap; &#125; @Override public HystrixCommand.Setter getHystrixSetter() &#123; return setter; &#125; @Override public void afterPropertiesSet() throws Exception &#123; //init repo initOtherRepo(); //init method Class&lt;? extends IDubboRepoProxy&gt; old_rpcClass = this.otherRepo.getClass(); for (Method method : old_rpcClass.getDeclaredMethods()) &#123; publicMethodMap.put(method, method); &#125; //init setter setter = HystrixCommand.Setter .withGroupKey(HystrixCommandGroupKey.Factory.asKey(this.getClass().getName())) .andCommandKey(HystrixCommandKey.Factory.asKey(this.getClass().getSimpleName())); &#125; public abstract void initOtherRepo(); @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.context = applicationContext; &#125;&#125; 使用AOP动态切换上述接口与抽象类会赋予UserRepo我们想要的功能.接下来就是AOP拦截.因为断路器是方法级别的操作,因此该AOP只拦截方法,为了更好的配置增加一个AOP专用注解1234//该注解修饰的方法会被AOP拦截@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface AutoDubboAspect &#123;&#125; 然后写具体的拦截器.该拦截器责任就是按部就班的执行之前的思路.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Component@Aspectpublic class AutoDubboAspectImpl &#123; private static Logger logger = LoggerFactory.getLogger(AutoDubboAspectImpl.class); @Pointcut("@annotation(com.duitang.context.dubbo.AutoDubboAspect)") public void autoDubboAspect() &#123; &#125; //环绕通知 @Around("autoDubboAspect()") public Object autoCheck(ProceedingJoinPoint pjp) throws Throwable &#123; //要执行的主repo IDubboRepoProxy target = (IDubboRepoProxy) pjp.getTarget(); //备用repo IDubboRepoProxy otherRepo = target.getDubboRepo(); //该repo中所有方法 Map&lt;Method, Method&gt; methods = target.getAllPublicMethods(); //断路器执行 HystrixCommand&lt;Object&gt; hystrixCommand = new HystrixCommand&lt;Object&gt;( target.getHystrixSetter()) &#123; @Override protected Object run() throws Exception &#123; try &#123; return pjp.proceed(); &#125; catch (Throwable throwable) &#123; //异常直接抛出 throw new RuntimeException(throwable); &#125; &#125; /** * 备用降级方案 */ @Override protected Object getFallback() &#123; logger.error("start getFallback,this exception is &#123;&#125;", this.getFailedExecutionException()); logger.error("start getFallback", pjp.getSignature().toLongString()); MethodSignature signature = (MethodSignature) pjp.getSignature(); //获取执行方法 Method method = methods.get(signature.getMethod()); if (method == null) &#123; return null; &#125; try &#123; //使用备用repo执行该方法 return method.invoke(otherRepo, pjp.getArgs()); &#125; catch (IllegalAccessException | InvocationTargetException e) &#123; logger.error("getFallback error,&#123;&#125;",e); &#125; return null; &#125; &#125;; return hystrixCommand.execute(); &#125;&#125; 到此准备工作算是结束,下面是真正的替换. 开始替换old_rpc服务因为准备的充分,那么替换就变得相当简单了.首先为UserRepo增强功能,也就是继承抽象类DubboRepoProxyImpl1public class UserRepo extends DubboRepoProxyImpl&lt;UserRepo&gt; 然后实现initOtherRepo方法,该方法主要是从Spring容器中获取到old_rpc的服务,然后再初始化一个UserRepo.12345678910111213141516@Override public void initOtherRepo() &#123; if (null != getContext()) &#123; IUserService userService = getContext().getBean("userService", IUserService.class); IRelationshipService relationshipService = getContext().getBean("relationshipService", IRelationshipService.class); IUserInterestsService userInterestsService = getContext().getBean("userInterestsService", IUserInterestsService.class); IFriendRecomendService friendRecomendService = getContext().getBean("friendRecomendService", IFriendRecomendService.class); //备用old_rpc服务 UserRepo userRepo = new UserRepo(userService, this.appealAccountService, this.datasourceService, relationshipService, this.lifeArtistService, userInterestsService, this.jedisPersist, friendRecomendService); this.setOtherRepo(userRepo); &#125; &#125; 最后为想要实现短路功能的方法加上注解.1234@AutoDubboAspectpublic BaseUser findBasicInfo(long userId) &#123; ...&#125; 注意事项消费者无法从zk中获取提供者信息?这种情况大多数都是因为配置时两方信息不一致导致,可以去dubbo-admin平台检查提供者完整的url,再与日志中消费者引用的url做个比较,定位到问题. zk连接超时zk是我在自己服务器上部署的,在vienna项目中配置了外网地址,在prism环境中启动后总是出现zk连接超时,后来测试要连上zk大概需要20秒左右,索性把超时时间配置为60秒,解决,具体原因未知. saturn中配置zk注册服务后测试案例无法跑通这个问题是我在saturn配置了测试环境的zk,1234567@Beanpublic RegistryConfig registry() &#123; RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setAddress("10.1.4.10:2181"); registryConfig.setProtocol("zookeeper"); return registryConfig;&#125; 但是jenkins打包时,测试案例一直失败,大概要打包10多分钟,问题有点莫名其妙,在测试时避免Spring引入该bean即可解决. 总结整体过程是比较顺利的,下篇再记录dubbo-admin与dubbo-monitor,以及hystrix-dashborad的搭建.]]></content>
      <categories>
        <category>服务治理</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Security学习记录(四) -- JSON Web Token实践(下)]]></title>
    <url>%2F2017%2F06%2F30%2Fspring%2FSpring%20Security%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E5%9B%9B)%20--%20JSON%20Web%20Token%E5%AE%9E%E8%B7%B5(%E4%B8%8B)%2F</url>
    <content type="text"><![CDATA[前提接着上篇的内容,了解了JWT Token后,发现这东西就是一个可信的用户信息存储方式,那么可信的话就可以省去验证这个步骤,只有当需要用户的详细信息时候才会去DB中查询用户的详细信息.那么现在的流程就是用户请求 -&gt; Spring Security通过token把tokenUser设置到上下文中 -&gt; Spring Security Token以及权限验证 -&gt; 具体的业务接口 -&gt; 需要详细信息则根据用户id去DB中获取那么就会有以下几个问题. token在什么时候生成?这个在登录接口中生成,登录后token放入用户id,用户权限等基础信息,以供验证使用. token签名的密钥该使用什么?这个我也不太清楚,写死一个密钥感觉很不安全,我的想法是使用用户的密码的密文作为签名密钥,这样当用户更改密码的时候原token都是失效.这样做有个缺点,用户密码的密文每次获取需要查询DB,势必会造成DB的压力,可以考虑加缓存,但要考虑缓存挂掉的情况下对DB的压力. token该怎么较少被盗后的损失?token既然被系统认为是可信的信息集合,那么就需要有相应的超时机制,超时机制是为了防止token被盗用后的损失也只能在一段时间内,就和session超时机制是一样的用处. 如何解决SSO?SSO需要借助cookie或者localStorge,把token放在顶级域名中,这样的话子系统都能使用到,也就完成的SSO机制.对于多域名,那要解决的问题就是如何跨域设置cookie了 如何解决CSRF?CSRF产生的原因是对方使用了你的Cookie也就是使用了你的认证信息,那么的话获取token这一步就不能依赖token,所以把cookie存在cookie中,然后请求时放入header中,解析时从header中获取token信息. 实践JWT签名与验签首先POM引入依赖包12345&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.7.0&lt;/version&gt;&lt;/dependency&gt; 接着定义一个简单的用户,用作存储在上下文中12345678public class TokenUserDTO &#123; private Long id; private String username; private String email; private String avatar; private List&lt;String&gt; roles; //省略get set&#125; 接着实现jwt123456789101112131415161718192021222324252627282930313233/** * 从用户中创建一个jwt Token * @param userDTO 用户 * @return token */ public String create(TokenUserDTO userDTO) &#123; return Jwts.builder() .setExpiration(new Date(System.currentTimeMillis() + VALIDITY_TIME_MS)) .setSubject(userDTO.getUsername()) .claim("id", userDTO.getId()) .claim("avatar", userDTO.getAvatar()) .claim("email", userDTO.getEmail()) .claim("roles", userDTO.getRoles()) .signWith(SignatureAlgorithm.HS256, secret) .compact(); &#125; /** * 从token中取出用户 */ public TokenUserDTO parse(String token) &#123; Claims claims = Jwts.parser() .setSigningKey(secret) .parseClaimsJws(token) .getBody(); TokenUserDTO userDTO = new TokenUserDTO(); userDTO.setId(NumberUtils.toLong(claims.getId())); userDTO.setAvatar(claims.get("avatar",String.class)); userDTO.setUsername(claims.get("username",String.class)); userDTO.setEmail(claims.get("email",String.class)); userDTO.setRoles((List&lt;String&gt;) claims.get("roles")); return userDTO; &#125; Spring Security过滤上述流程中Spring Security所承担的角色是验证token+保存token解析出来的用户到SecurityContextHolder中,弄清楚角色那么实现就很简单了.看之前的过滤器链,蓝色框内包含跨站攻击检测与用户信息获取校验,因为用的是jwt所以这些都可以省略掉,替换为解析并验证token,然后设置解析后的用户到上下文中. 首先SecurityContextHolder中存储的是Authentication对象,所以需要在TokenUser基础封装一层认证用户.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * Spring Security中存放的认证用户 * @author Niu Li * @since 2017/6/28 */public class TokenUserAuthentication implements Authentication &#123; private static final long serialVersionUID = 3730332217518791533L; private TokenUserDTO userDTO; private Boolean authentication = false; public TokenUserAuthentication(TokenUserDTO userDTO, Boolean authentication) &#123; this.userDTO = userDTO; this.authentication = authentication; &#125; //这里的权限是FilterSecurityInterceptor做权限验证使用 @Override public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() &#123; return userDTO.getRoles().stream() .map(SimpleGrantedAuthority::new).collect(Collectors.toList()); &#125; @Override public Object getCredentials() &#123; return ""; &#125; @Override public Object getDetails() &#123; return userDTO; &#125; @Override public Object getPrincipal() &#123; return userDTO.getUsername(); &#125; @Override public boolean isAuthenticated() &#123; return authentication; &#125; @Override public void setAuthenticated(boolean isAuthenticated) throws IllegalArgumentException &#123; this.authentication = isAuthenticated; &#125; @Override public String getName() &#123; return userDTO.getUsername(); &#125;&#125; 然后实现验签方法,验签是从header中取出相应的token,验签成功后返回一个Authentication的对象.12345678910111213/** * 验签 */public Optional&lt;Authentication&gt; verifyToken(HttpServletRequest request) &#123; final String token = request.getHeader(AUTH_HEADER_NAME); if (token != null &amp;&amp; !token.isEmpty())&#123; final TokenUserDTO user = parse(token.trim()); if (user != null) &#123; return Optional.of(new TokenUserAuthentication(user, true)); &#125; &#125; return Optional.empty();&#125; 最后实现验证Token的过滤器123456789101112131415161718192021222324252627/** * jwt token验证类,验证成功后设置进去SecurityContext中 * @author Niu Li * @since 2017/6/28 */@Slf4jpublic class VerifyTokenFilter extends OncePerRequestFilter &#123; private JwtTokenUtil jwtTokenUtil; public VerifyTokenFilter(JwtTokenUtil jwtTokenUtil) &#123; this.jwtTokenUtil = jwtTokenUtil; &#125; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; try &#123; Optional&lt;Authentication&gt; authentication = jwtTokenUtil.verifyToken(request); log.debug("VerifyTokenFilter result: &#123;&#125;",authentication.orElse(null)); SecurityContextHolder.getContext().setAuthentication(authentication.orElse(null)); filterChain.doFilter(request,response); &#125; catch (JwtException e) &#123; response.setStatus(HttpServletResponse.SC_UNAUTHORIZED); //可以在这里指定重定向还是返回错误接口示例 &#125; &#125;&#125; 配置下Spring Security,主要就是关闭一些不用的过滤器,实现自己的验证过滤器.123456789101112131415161718192021222324252627282930313233343536373839@Configuration@EnableWebSecuritypublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Resource private JwtTokenUtil jwtTokenUtil; /** * 在此配置不过滤的请求 */ @Override public void configure(WebSecurity web) throws Exception &#123; //每一个请求对应一个空的filter链,这里一般不要配置过多, // 因为查找处是一个for循环,过多就导致每个请求都需要循环一遍直到找到 web.ignoring().antMatchers("/","/login","/favicon.ico"); &#125; /** * 在此配置过滤链 */ @Override protected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() //角色定义,Spring Security会在其前面自动加上ROLE_,因此存储权限的时候也要加上ROLE_ADMIN .antMatchers("/detail").access("hasRole('ADMIN')") .anyRequest().permitAll().and() //异常处理,可以再此使用entrypoint来定义错误输出 .exceptionHandling().and() //不需要session来控制,所以这里可以去掉 .securityContext().securityContextRepository(new NullSecurityContextRepository()).and() //开启匿名访问 .anonymous().and() //退出登录自己来控制 .logout().disable() //因为没用到cookies,所以关闭cookies .csrf().disable() //验证token .addFilterBefore(new VerifyTokenFilter(jwtTokenUtil), UsernamePasswordAuthenticationFilter.class); &#125;&#125; 这样做的话,验证就需要在相应的代码中,或者对指定链接使用Spring Security的权限验证.1234567891011/** * 该链接尝试获取登录用户,返回该认证用户的信息,请求该链接需要在header中放入x-authorization: token */@GetMapping("/detail")public TokenUserDTO userDetail() &#123; Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); if (Objects.isNull(authentication)) &#123; return null; &#125; return (TokenUserDTO) authentication.getDetails();&#125; 或者123....antMatchers("/detail").access("hasRole('ADMIN')")... 这样的话就实现了jwt验证,SSO问题也就是token传输的问题,使用cookie就可以了,客户端去请求时从cookie中加载token,然后放入到header中,对这里的代码没影响. github地址: https://github.com/nl101531/JavaWEB]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Security学习记录(三) -- JSON Web Token实践(上)]]></title>
    <url>%2F2017%2F06%2F26%2Fspring%2FSpring%20Security%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%B8%89)%20--%20JSON%20Web%20Token%E5%AE%9E%E8%B7%B5(%E4%B8%8A)%2F</url>
    <content type="text"><![CDATA[JWT实际上与Spring Security没多大关系,本文打算使用Spring Security配合JWT这种方式完成用户的认证和授权. JSON Web Token(JWT),是一个开放安全的行业标准,用于多个系统之间传递安全可靠的信息.关于其解释可以参考博文:JSON Web Token - 在Web应用间安全地传递信息因为原作者写的很详细,这里就只说下个人认为比较重要的问题. JWT是什么样子的结构?JSON Web Token说到底也是一串token,其形式分三段,看下图,红色的为Header,指定token类型与签名类型,紫色的为请求体,存储用户id等关键信息,最后蓝色的为签名,保证整个信息的完整性,可靠性.其中playload中可以 iss: 该JWT的签发者 sub: 该JWT所面向的用户 aud: 接收该JWT的一方 exp(expires): 什么时候过期，这里是一个Unix时间戳 iat(issued at): 在什么时候签发的 nbf: 定义在什么时间之前，该jwt都是不可用的. jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。 JWT是一个怎样的流程? 客户端使用账户密码请求登录接口 登录成功后返回JWT 客户端再次请求其他接口时带上JWT 服务端接收到JWT后验证签名的有效性. JWT解决了什么问题?token被劫持一开始理解很容易陷入一个误区,比如有人会问对于JWT来说,jwt被劫持了的话,那么对方就可以伪造请求,这东西怎么能保证安全呢?这里问题是没理解好JWT,JWT解决的是认证与授权的问题,上述劫持或者类似的中间人攻击是JWT不可避免的,也是其他认证与授权方式不可避免的,想避免可以使用HTTPS,或者签发jwt的时候记录下Client的ip地址,这些就和JWT没关系了. 与Session的区别session实际上是基于cookie来传输的,最重要的session信息是存储在服务器的,所以服务器每次可以通过cookie中的sessionId获取到当前会话的用户,对于单台服务器这样做没问题,但是对于多台就涉及到共享session的问题了,而且认证用户的增多,session会占用大量的服务器内存.那么jwt是存储在客户端的,服务器不需要存储jwt,jwt里面有用户id,服务器拿到jwt验证后可以获得用户信息.也就实现了session的功能,但是相比session,jwt是无状态的,其不与任何机器绑定,只要签名秘钥足够的安全就能保证jwt的可靠性. JWT下服务端认为什么样子的请求是可信的?对于服务端来说,无法确定下一个请求是哪一个用户,哪一个终端发出,所以其需要一些信息定位到该用户或者该机器,对于JWT来说其Playload里面存储着UserId,那么服务端接收到Token后对其进行签名验证,验证成功,则认为其是可信的,然后通过UserId从DB或者Cache中查询出来用户信息. 为什么JWT能保证信息传输的安全可靠?比如现在有token123eyJhbGciOiJIUzI1NiJ9.eyJleHAiOjE0OTg0ODIxNTQsInN1YiI6InF1ZGluZyIsInVzZXJJZCI6IjEwMzc5NDAxIiwicm9sZSI6ImFkbWluIn0.-YFTYJ6FLlIQqD4G3hYcWvYlYE8H9eAA2369WEcJFVY 12345678910111213Header&#123; "alg": "HS256"&#125;Playload&#123; "exp": 1498482154, "sub": "quding", "userId": "10379401", "role": "admin"&#125;SignYFTYJ6FLlIQqD4G3hYcWvYlYE8H9eAA2369WEcJFVY 假设我的playload被其他人劫持了,其他人把userId修改为他自己的,比如123456,但是其没有签名的秘钥,所以他就没法生成签名.服务端收到该Token后,会用先Base64解码出来相应的信息,然后重新生成sign,使用该sign与客户端传来的Sign进行对比,一样则证明没被修改,也就是可信的请求,否则拒绝该请求. 下一篇开始实战. github地址: https://github.com/nl101531/JavaWEB]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Security学习记录(二) -- Spring Security的Filter]]></title>
    <url>%2F2017%2F06%2F22%2Fspring%2FSpring%20Security%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%BA%8C)%20--%20Spring%20Security%E7%9A%84Filter%2F</url>
    <content type="text"><![CDATA[上一篇学习了Spring Security是如何拦截请求,并把请求转向到Filter链的,该篇就主要学习下这些Filter链的节点的作用. 下面是之前配置的内容,本文也是对这些内容 的执行分析.123456789101112131415&lt;security:http &gt; &lt;security:intercept-url pattern="/**" access="hasRole('ROLE_USER')"/&gt; &lt;security:form-login/&gt; &lt;security:http-basic/&gt; &lt;security:logout/&gt; &lt;/security:http&gt; &lt;security:authentication-manager&gt; &lt;security:authentication-provider&gt; &lt;security:user-service&gt; &lt;security:user name="user" password="123456" authorities="ROLE_USER"/&gt; &lt;security:user name="admin" password="123456" authorities="ROLE_USER, ROLE_ADMIN"/&gt; &lt;/security:user-service&gt; &lt;/security:authentication-provider&gt; &lt;/security:authentication-manager&gt; 1.Filter链的由来由上文可知每一个security:http标签实际上对应的是一个SecurityFilterChain的类,也就是一条Filter链,可以通过其http属性指明其作用的URL,否则作用域全部的URL,如下配置,该security:http会产生一个对/login下的所有请求Filter链.123&lt;security:http pattern="/login/**"&gt; ******&lt;/security:http&gt; 打个断点可以很清楚的看到该Filter链 2.SecurityContextPersistenceFilter该类在所有的Filter之前,是从SecurityContextRepository中取出用户认证信息,默认实现类为HttpSessionSecurityContextRepository,其会从Session中取出已认证用户的信息,提高效率,避免每一次请求都要查询用户认证信息.取出之后会放入SecurityContextHolder中,以便其他filter使用,该类使用ThreadLocal存储用户认证信息,保证了线程之间的信息隔离,最后再finally中清除该信息.可以配置http的security-context-repository-ref属性来自己控制获取到已认证用户信息的方式,比如使用redis存储session等. 3.WebAsyncManagerIntegrationFilter提供了对securityContext和WebAsyncManager的集成,其会把SecurityContext设置到异步线程中,使其也能获取到用户上下文认证信息. 4.HeaderWriterFilter其会往该请求的Header中添加相应的信息,在http标签内部使用security:headers来控制. 5.CsrfFilterCsrf,跨站请求伪造,了解不是很深,只知道B网站使用A网站的可信Cookie发起请求,从而完成认证,伪造出正当请求.验证方式是通过客户端传来的token与服务端存储的token进行对比,来判断是否为伪造请求,有兴趣的可以查看源代码研究下. 6.LogoutFilter匹配URL,默认为/logout,匹配成功后则用户退出,清除认证信息. 7.UsernamePasswordAuthenticationFilter登录认证过滤器,默认是对/login的POST请求进行认证,首先该方法会先调用attemptAuthentication尝试认证获取一个Authentication的认证对象,然后通过sessionStrategy.onAuthentication执行持久化,也就是保存认证信息,转向下一个Filter,最后调用successfulAuthentication执行认证后事件. attemptAuthentication该方法是认证的主要方法,认证是委托配置的authentication-manager-&gt;authentication-provider进行.比如对于该Demo配置的为如下,则默认使用的manager为ProviderManager,使用的provider为DaoAuthenticationProvider,userDetailService为InMemoryUserDetailsManager也就是从内存中获取用户认证信息,也就是下面xml配置的user与admin信息.12345678&lt;security:authentication-manager&gt; &lt;security:authentication-provider&gt; &lt;security:user-service&gt; &lt;security:user name="user" password="123456" authorities="ROLE_USER"/&gt; &lt;security:user name="admin" password="123456" authorities="ROLE_USER, ROLE_ADMIN"/&gt; &lt;/security:user-service&gt; &lt;/security:authentication-provider&gt;&lt;/security:authentication-manager&gt; 认证基本流程为UserDeatilService根据用户名获取到认证用户的信息,然后通过UserDetailsChecker.check对用户进行状态校验,最后通过additionalAuthenticationChecks方法对用户进行密码校验成功后完成认证.返回一个认证对象. 都是面向接口编程,所以用户可以很轻松的扩展自己的验证方式. 8.DefaultLoginPageGeneratingFilter当请求为登录请求时,生成简单的登录页面返回 9.BasicAuthenticationFilterHttp Basci认证的支持,该认证会把用户名密码使用base64编码后放入header中传输,如下所示,认证成功后会把用户信息放入SecurityContextHolder中.1* Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== 10.RequestCacheAwareFilter恢复被打断的请求,具体未研究 11.SecurityContextHolderAwareRequestFilter针对Servlet api不同版本做的一些包装 12.AnonymousAuthenticationFilter当SecurityContextHolder中认证信息为空,则会创建一个匿名用户存入到SecurityContextHolder中 13.SessionManagementFilter与登录认证拦截时作用一样,持久化用户登录信息,可以保存到session中,也可以保存到cookie或者redis中. 14.ExceptionTranslationFilter异常拦截,其处在Filter链后部分,只能拦截其后面的节点并且着重处理AuthenticationException与AccessDeniedException两个异常. 15.FilterSecurityInterceptor主要是授权验证,方法为beforeInvocation,在其中调用12Collection&lt;ConfigAttribute&gt; attributes = this.obtainSecurityMetadataSource() .getAttributes(object); 获取到所配置资源访问的授权信息,对于上述配置,获取到的则为hasRole(&#39;ROLE_USER&#39;),然后根据SecurityContextHolder中存储的用户信息来决定其是否有权限,没权限则返回403,具体想了解可以关注HttpConfigurationBuilder.createFilterSecurityInterceptor()方法,分析其创建流程加载了哪些数据,或者分析SecurityExpressionOperations的子类,其是权限鉴定的实现方法. 总结整个认证授权流程如下图所示,图是网上盗的 因为是学习方面,使用的不是很多,如有错误请指出,以防误人子弟.简单来说,作为用户需要关心的地方是 登录验证UsernamePasswordAuthenticationFilter 访问验证BasicAuthenticationFilter 权限验证FilterSecurityInterceptor下一篇则讲述利用这三个验证实现JWT验证. 关于这些过滤器更详细的内容可参考博客: http://www.iteye.com/blogs/subjects/spring_security github地址: https://github.com/nl101531/JavaWEB]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Security学习记录(一) -- 初识Spring Security]]></title>
    <url>%2F2017%2F06%2F19%2Fspring%2FSpring%20Security%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%B8%80)%20--%20Spring%20Security%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%B8%80)%20--%20%E5%88%9D%E8%AF%86Spring%20Security%2F</url>
    <content type="text"><![CDATA[Spring Security是什么?Spring Security是一套认证授权框架,支持认证模式如HTTP BASIC 认证头 (基于 IETF RFC-based 标准),HTTP Digest 认证头 ( IETF RFC-based 标准),Form-based authentication (用于简单的用户界面),OpenID 认证等,Spring Security使得当前系统可以快速集成这些验证机制亦或是实现自己的一套验证机制. 使用Spring SecuritySpring Security3之后提供了Java Config的配置方式,但是我觉得xml方式比较容易理解其整体结构,所以本文都是基于xml配置的,在github上该项目会提供Java Config方式作为对比. pom依赖12345678910111213141516&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.4.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 由于使用了Spring Boot,所以需要使用@EnableWebSecurity注解启用Spring Security,并指明其配置文件为classpath下的spring-security.xml12345@Configuration@EnableWebSecurity@ImportResource(locations = "classpath:spring-security.xml")public class SecurityConfig &#123;&#125; xml配置在spring-security.xml中引入官方提供的命名空间,然后简单配置下,该配置大概意思是对所有请求的url拦截,必须有User权限的用户才能访问.12345678910111213141516171819202122232425&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:security="http://www.springframework.org/schema/security" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/security http://www.springframework.org/schema/security/spring-security.xsd"&gt; &lt;security:http &gt; &lt;security:intercept-url pattern="/**" access="hasRole('ROLE_USER')"/&gt; &lt;security:form-login/&gt; &lt;security:http-basic/&gt; &lt;security:logout/&gt; &lt;/security:http&gt; &lt;security:authentication-manager&gt; &lt;security:authentication-provider&gt; &lt;security:user-service&gt; &lt;security:user name="user" password="123456" authorities="ROLE_USER"/&gt; &lt;security:user name="admin" password="123456" authorities="ROLE_USER, ROLE_ADMIN"/&gt; &lt;/security:user-service&gt; &lt;/security:authentication-provider&gt; &lt;/security:authentication-manager&gt;&lt;/beans&gt; 访问测试该页面为Spring Security自动生成的登录页面,当我们访问任何连接都会被重定向到该登录页面,输入user:123456登录后才能有权限访问. 分析上述是一个简单的Demo,分析则是从这个Demo深入浅出.1.Spring Security是如何拦截请求的?传统的xml配置都会在web.xml里面配置如下过滤器.12345678&lt;filter&gt; &lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 可以看出入口点就是该类,该类会从Spring容器中读取名称为springSecurityFilterChain的一个Filter实例,从而获取到对应代理的Filter.1234567protected Filter initDelegate(WebApplicationContext wac) throws ServletException &#123; Filter delegate = wac.getBean(getTargetBeanName(), Filter.class); if (isTargetFilterLifecycle()) &#123; delegate.init(getFilterConfig()); &#125; return delegate;&#125; 然后在doFilter方法中调用该委托的filter,也就实现的拦截请求.123456protected void invokeDelegate( Filter delegate, ServletRequest request, ServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; delegate.doFilter(request, response, filterChain);&#125; 2. Spring Security拦截请求后是如何处理的?打断点可以发现DelegatingFilterProxy实际上代理的是FilterChainProxy这个类,该类中有private List&lt;SecurityFilterChain&gt; filterChains;全局变量,那么SecurityFilterChain为何物?123456public interface SecurityFilterChain &#123; boolean matches(HttpServletRequest request); List&lt;Filter&gt; getFilters();&#125; 从源码可以判断SecurityFilterChain是一套规则所对应的Filter链集合.再看源码getFilters,该方法会根据规则(也就是配置中的security:http标签)获取一个SecurityFilterChain中的一套对应规则的filter链.12345678private List&lt;Filter&gt; getFilters(HttpServletRequest request) &#123; for (SecurityFilterChain chain : filterChains) &#123; if (chain.matches(request)) &#123; return chain.getFilters(); &#125; &#125; return null;&#125; 最后在doFilterInternal方法中创建一个VirtualFilterChain类,调用其doFilter方法.VirtualFilterChain这个类很有意思,该类继承了FilterChain类,那么其就拥有了转交请求到指定filter的能力,另外其还拥有一套filter链List&lt;Filter&gt; additionalFilters;,那么这个类就控制了整个Spring Security的执行流程,那么它是怎么实现的呢?开始我以为是一个循环,然而看了源码才发现自己太low了.123 currentPosition++;Filter nextFilter = additionalFilters.get(currentPosition - 1);nextFilter.doFilter(request, response, this); currentPosition与additionalFilters都是全局变量,其在调用filter链的时候每次都把自己本身在doFilter传值过去,每一个Filter链节点执行完毕后再返回VirtualFilterChain的doFilter方法,开启下一个节点执行.其结构如下面代码所示:1234567891011121314151617181920212223242526272829303132333435363738interface IA&#123; void doSomeThing(IAChain chain); &#125; static class IAClass implements IA&#123; @Override public void doSomeThing(IAChain chain) &#123; System.out.println("i am IAClass"); chain.doSomeThing(); &#125; &#125; interface IAChain&#123; void doSomeThing(); &#125; static class IAChainClass implements IAChain&#123; List&lt;IA&gt; IAChains = new ArrayList&lt;IA&gt;(); public IAChainClass() &#123; IAChains.add(new IAClass()); IAChains.add(new IAClass()); IAChains.add(new IAClass()); &#125; int position = 0; @Override public void doSomeThing() &#123; if (position == IAChains.size()) &#123; System.out.println("end"); return; &#125; IA ia = IAChains.get(position++); ia.doSomeThing(this); &#125; &#125; 当调用iaChainClass.doSomeThing()输出1234i am IAClassi am IAClassi am IAClassend 调用链的实现还可以使用继承来实现,每次执行前先执行super()方法. github地址: https://github.com/nl101531/JavaWEB ok,下一章分析具体的Filter链中的节点,探究下Spring Security是如何进行用户认证与权限控制的.]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WEB小知识-HTTP请求对+和&的处理]]></title>
    <url>%2F2017%2F05%2F22%2Fweb%2FWEB%E5%B0%8F%E7%9F%A5%E8%AF%86-HTTP%E8%AF%B7%E6%B1%82%E5%AF%B9%2B%E5%92%8C%26%E7%9A%84%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[1.问题在HTTP请求中如果传的参数有一些特殊字符则会被编码成空格,导致服务端获取不到响应的信息. 对于+号会被编码为空格对于&amp;也会被编码成空格 举个例子,需要向服务端提交如下代码:123456789#include &lt;iostream&gt;using namespace std;int main()&#123; int a,b; cin &gt;&gt; a &gt;&gt; b; cout &lt;&lt; a+b &lt;&lt; endl; return 0;&#125; 编码后的内容如下,可以发现a+b被转换成了a b导致服务端接收到后编译失败.12345#include%20%3Ciostream%3E%0A%0Ausing%20namespace%20std;%0A%0Aint%20main()%0A%7B%0A%20%20%20%20int%20a,b;%0A%20%20%20%20cin%20%3E%3E%20a%20%3E%3E%20b;%0A%20%20%20%20cout%20%3C%3C%20a b%20%3C%3C%20endl;%0A%20%20%20%20return%200;%0A%7D 2.解决方案使用函数encodeURIComponent(),该函数会把特殊字符都给转义,转义结果如下面所示,可见a+b转换成了a%2Bb12345%23include%20%3Ciostream%3E%0A%0Ausing%20namespace%20std%3B%0A%0Aint%20main()%0A%7B%0A%20%20%20%20int%20a%2Cb%3B%0A%20%20%20%20cin%20%3E%3E%20a%20%3E%3E%20b%3B%0A%20%20%20%20cout%20%3C%3C%20a%2Bb%20%3C%3C%20endl%3B%0A%20%20%20%20return%200%3B%0A%7D 服务端需要使用URLDecoder对其进行反转义,该问题到此解决.]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>bug</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8学习记录(二)-Stream原理]]></title>
    <url>%2F2017%2F05%2F20%2Fjava%2FJava8%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%BA%8C)-Stream%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[推荐一篇博文,很好的介绍了Stream的原理.本文对其进行一些补充更加详细的讲解. 作者: 李豪地址: https://github.com/CarpenterLee/JavaLambdaInternals/blob/master/6-Stream%20Pipelines.md 需求: 从&quot;张三&quot;,&quot;李四&quot;,&quot;王二&quot;,&quot;张四五&quot;中选出以张开头的名字,然后从再从中选出名字最长的一个,输出其长度. 1.一种直白的实现 缺点: 迭代次数过多 频繁产生中间结果,性能无法接受 实际想要的效果:平常的写法:12345678int longest = 0;for(String str : strings)&#123; if(str.startsWith("张"))&#123;// 1. filter(), 保留以张开头的字符串 int len = str.length();// 2. mapToInt(), 转换成长度 longest = Math.max(len, longest);// 3. max(), 保留最长的长度 &#125;&#125;System.out.println(longest); Stream的做法:12345Stream.of("张三","李四","王二","张四五") .filter(x -&gt; x.startsWith("张")) .mapToInt(String::length) .max() .ifPresent(System.out::println); 2.Stream是怎么做到的?Stream的操作分类: 中间操作:返回一个新的Stream - 有状态 sorted(),必须等上一步操作完拿到全部元素后才可操作 - 无状态 filter(),该操作的元素不受上一步操作的影响 12list.stream().filter(x -&gt; x.startWith("张").map(x -&gt; x.length())list.stream().filter(x -&gt; x.startWith("张").sorted().map(x -&gt; x.length()) 终端操作:返回结果 - 短路操作findFirst(),找到一个则返回,也就是break当前的循环 - 非短路操作forEach(),遍历全部元素 以上操作决定了Stream一定是先构建完毕再执行的特点,也就是延迟执行,当需要结果(终端操作时)开始执行流水线.Stream做到的是对于多次调用合并到一次迭代中处理完所有的调用方式.换句话说就是解决了上述的两个缺点.大概思路是记录下每一步的操作,然后终端操作时对其迭代依次执行每一步的操作,最后再一次循环中处理. 问题: 操作是如何记录下来的? 操作是如何叠加的? 叠加完如何执行的? 执行完如何收集结果的? Stream结构示意图: 示例代码:123456789101112List&lt;String&gt; data = new ArrayList&lt;&gt;();data.add("张三");data.add("李四");data.add("王三");data.add("马六");data.stream() .filter(x -&gt; x.length() == 2) .map(x -&gt; x.replace("三","五")) .sorted() .filter(x -&gt; x.contains("五")) .forEach(System.out::println); 1. 操作是如何记录下来的? Head记录Stream起始操作 StatelessOp记录中间操作 StatefulOp记录有状态的中间操作这三个操作实例化会指向其父类AbstractPipeline,也就是在AbstractPipeline中建立了双向链表 对于Head12345678910AbstractPipeline(Spliterator&lt;?&gt; source, int sourceFlags, boolean parallel) &#123; this.previousStage = null; //首操作上一步为null this.sourceSpliterator = source; //数据 this.sourceStage = this; //Head操作 this.sourceOrOpFlags = sourceFlags &amp; StreamOpFlag.STREAM_MASK; this.combinedFlags = (~(sourceOrOpFlags &lt;&lt; 1)) &amp; StreamOpFlag.INITIAL_OPS_VALUE; this.depth = 0; this.parallel = parallel;&#125; 对于其他Stage:123456789101112131415AbstractPipeline(AbstractPipeline&lt;?, E_IN, ?&gt; previousStage, int opFlags) &#123; if (previousStage.linkedOrConsumed) throw new IllegalStateException(MSG_STREAM_LINKED); previousStage.linkedOrConsumed = true; //双向链表的建立 previousStage.nextStage = this; this.previousStage = previousStage; this.sourceStage = previousStage.sourceStage; this.depth = previousStage.depth + 1; this.sourceOrOpFlags = opFlags &amp; StreamOpFlag.OP_MASK; this.combinedFlags = StreamOpFlag.combineOpFlags(opFlags, previousStage.combinedFlags); if (opIsStateful()) sourceStage.sourceAnyStateful = true;&#125; 调用过程如此用双向链表串联起来,每一步都得知其上一步与下一步的操作. data.stream() .filter(x -&gt; x.length() == 2) .map(x -&gt; x.replace(“三”,”五”)) .sorted() .filter(x -&gt; x.contains(“五”)) .forEach(System.out::println); 2.操作是如何叠加的?Sink&lt;T&gt;接口: void begin(long size),循环开始前调用,通知每个Stage做好准备 void end(),循环结束时调用,依次调用每个Stage的end方法,处理结果 boolean cancellationRequested(),判断是否可以提前结束循环 void accept(T value),每一步的处理 其子类之一ChainedReference:12345678910111213141516171819static abstract class ChainedReference&lt;T, E_OUT&gt; implements Sink&lt;T&gt; &#123; protected final Sink&lt;? super E_OUT&gt; downstream; public ChainedReference(Sink&lt;? super E_OUT&gt; downstream) &#123; this.downstream = Objects.requireNonNull(downstream); &#125; @Override public void begin(long size) &#123; downstream.begin(size); &#125; @Override public void end() &#123; downstream.end(); &#125; @Override public boolean cancellationRequested() &#123; return downstream.cancellationRequested(); &#125;&#125; 例Filter:123456789101112131415161718192021222324@Overridepublic final Stream&lt;P_OUT&gt; filter(Predicate&lt;? super P_OUT&gt; predicate) &#123; Objects.requireNonNull(predicate); return new StatelessOp&lt;P_OUT, P_OUT&gt;(this, StreamShape.REFERENCE, StreamOpFlag.NOT_SIZED) &#123; @Override Sink&lt;P_OUT&gt; opWrapSink(int flags, Sink&lt;P_OUT&gt; sink) &#123; return new Sink.ChainedReference&lt;P_OUT, P_OUT&gt;(sink) &#123; @Override public void begin(long size) &#123; downstream.begin(-1); &#125; @Override public void accept(P_OUT u) &#123; //条件成立则传递给下一个操作,也因为如此所以有状态的操作必须放到 //end方法里面 if (predicate.test(u)) downstream.accept(u); &#125; &#125;; &#125; &#125;;&#125; 再例如sorted():1234567891011121314151617181920212223242526@Overridepublic void begin(long size) &#123; if (size &gt;= Nodes.MAX_ARRAY_SIZE) throw new IllegalArgumentException(Nodes.BAD_SIZE); list = (size &gt;= 0) ? new ArrayList&lt;T&gt;((int) size) : new ArrayList&lt;T&gt;();&#125;@Overridepublic void end() &#123; list.sort(comparator); downstream.begin(list.size()); if (!cancellationWasRequested) &#123; list.forEach(downstream::accept); &#125; else &#123; for (T t : list) &#123; if (downstream.cancellationRequested()) break; downstream.accept(t); &#125; &#125; downstream.end(); list = null;&#125;@Overridepublic void accept(T t) &#123; list.add(t);&#125; 叠加后如何执行?执行操作是由终端操作来触发的,例如foreach操作12345@Overridepublic void forEach(Consumer&lt;? super P_OUT&gt; action) &#123; //evaluate就是开关,一旦调用就立即执行整个Stream evaluate(ForEachOps.makeRef(action, false));&#125; 执行前会对操作从末尾到起始反向包裹起来,得到调用链1Sink opWrapSink(int flags, Sink&lt;P_OUT&gt; sink) ; 123456789//这个Sink是终端操作所对应的Sinkfinal &lt;P_IN&gt; Sink&lt;P_IN&gt; wrapSink(Sink&lt;E_OUT&gt; sink) &#123; Objects.requireNonNull(sink); for ( AbstractPipeline p=AbstractPipeline.this; p.depth &gt; 0; p=p.previousStage) &#123; sink = p.opWrapSink(p.previousStage.combinedFlags, sink); &#125; return (Sink&lt;P_IN&gt;) sink;&#125; 1234567891011121314@Overridefinal &lt;P_IN&gt; void copyInto(Sink&lt;P_IN&gt; wrappedSink, Spliterator&lt;P_IN&gt; spliterator) &#123; Objects.requireNonNull(wrappedSink); if (!StreamOpFlag.SHORT_CIRCUIT.isKnown(getStreamAndOpFlags())) &#123; //依次执行调用链 wrappedSink.begin(spliterator.getExactSizeIfKnown()); spliterator.forEachRemaining(wrappedSink); wrappedSink.end(); &#125; else &#123; copyIntoWithCancel(wrappedSink, spliterator); &#125;&#125; 有状态的中间操作何时执行?例如sorted()操作,其依赖上一次操作的结果集,按照调用链来说结果集必须在accept()调用完才会产生.那也就说明sorted操作需要在end中,然后再重新开启调用链. sorted的end方法:12345678910111213141516@Override public void end() &#123; list.sort(comparator); downstream.begin(list.size()); if (!cancellationWasRequested) &#123; list.forEach(downstream::accept); &#125; else &#123; for (T t : list) &#123; if (downstream.cancellationRequested()) break; downstream.accept(t); &#125; &#125; downstream.end(); list = null; &#125; 那么就相当于sorted给原有操作断路了一次,然后又重新接上,再次遍历. 如何收集到结果?foreach是不需要收集到结果的,但是对于collect这样的操作是需要拿到最终end产生的结果.end产生的结果在最后一个Sink中,这样的操作最终都会提供一个取出数据的get方法.12345@Override public &lt;P_IN&gt; R evaluateSequential(PipelineHelper&lt;T&gt; helper, Spliterator&lt;P_IN&gt; spliterator) &#123; return helper.wrapAndCopyInto(makeSink(), spliterator).get(); &#125; 如此拿到数据返回 个人博客 mrdear.cn ,欢迎交流]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8学习记录(一)-函数式接口]]></title>
    <url>%2F2017%2F05%2F18%2Fjava%2FJava8%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%B8%80)-%E5%87%BD%E6%95%B0%E5%BC%8F%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[实习前只是粗略的看了下Java8的一些基本语法,但是没有系统的学习过.在使用一段时间后决定系统的对其进行一次分析,加深对Java8函数式编程的理解,提高自己的编码技巧.另外kotlin崛起,感兴趣的朋友尝试下混编也未尝不可. 函数式接口函数式接口,对于Java来说就是接口内只有一个公开方法的接口,因为使用lanbda表达式,例如() -&gt; user.getName()对应的调用则可能是func.get(),编译器会根据接口推断所属于的方法,如果有两个则无法推断.Java8提供了很多函数式接口,一般都使用注解@FunctionalInterface声明,有必要了解如下一些函数式接口. 函数式接口 参数类型 返回类型 描述 Supplier 无 T 接收一个T类型的值 Consumer T 无 处理一个T类型的值 BiConsumer T,U 无 处理T类型和U类型的值 Predicate T boolean 处理T类型的值,并返回true或者false. ToIntFunction T int 处理T类型的值,并返回int值 ToLongFunction T long 处理T类型的值,并返回long值 ToDoubleFunction T double 处理T类型的值,并返回double值 Function T R 处理T类型的值,并返回R类型值 BiFunction T,U R 处理T类型和U类型的值,并返回R类型值 BiFunction T,U R 处理T类型和U类型的值,并返回R类型值 UnaryOperator T T 处理T类型值,并返回T类型值, BinaryOperator T,T T 处理T类型值,并返回T类型值 以上的函数每一个代表的都是一种基本的操作,操作之间可以自由组合,所以才有了stream这些灵活的操作. Stream操作Stream的操作是建立在函数式接口的组合上的,最好的学习方法是看Stream接口来学习.下面举一些例子来分析,假设有这样的一些初始数据.12345List&lt;String&gt; testData = new ArrayList&lt;String&gt;(); testData.add("张三"); testData.add("李四"); testData.add("王二"); testData.add("麻子"); filter1Stream&lt;T&gt; filter(Predicate&lt;? super T&gt; predicate); filter接收predicate函数,predicate是接收T值,返回boolean值,那么对应的引用就可以写成如下形式,意思是取集合中以’张’开头的名字.12testData.stream() .filter(x -&gt; x.startsWith("张")) map1&lt;R&gt; Stream&lt;R&gt; map(Function&lt;? super T, ? extends R&gt; mapper); map操作接收的是Function接口,对于Function接收T值返回R值,那map的作用就很明显是转换用的,比如下面代码,转换名称为对应的名称长度,也就是从输入String数据返回int数据.12testData.stream() .map(x -&gt; x.length()) flatMap1&lt;R&gt; Stream&lt;R&gt; flatMap(Function&lt;? super T, ? extends Stream&lt;? extends R&gt;&gt; mapper); flatMap和map都是使用Function接口,不同的是返回值flatMap限定为Stream类型.所以flatMap可以作为合并流使用,如以下代码,提取出所有的字符.1234testData.stream() .flatMap(x -&gt; Stream.of(x.split(""))) .collect(Collectors.toList()); //输出 [张, 三, 李, 四, 王, 二, 麻, 子] peek1Stream&lt;T&gt; peek(Consumer&lt;? super T&gt; action); peek参数为Consumer,Consumer接收T值,无返回,那么该方法就可以作为调试不影响stream中内容的一些操作,不过由于对象都是地址引用,你再此做一些对象内容操作也是可以的.reduce1&lt;U&gt; U reduce(U identity, BiFunction&lt;U, ? super T, U&gt; accumulator, BinaryOperator&lt;U&gt; combiner); Reduce比较复杂的一个接口,属于归纳性操作,看参数,第一个是U泛型,也就是输入类型的参数,最为初始值,第二个BiFunction,接收T,U参数,返回U类型参数,BinaryOperator接收U,U类型,并返回U类型.1234567891011 StringBuilder identity = new StringBuilder(); StringBuilder reduce = testData.stream() .flatMap(x -&gt; Stream.of(x.split(""))) .reduce(identity, (r, x) -&gt; &#123; r.append(x); return r; &#125;, StringBuilder::append); System.out.println(identity == reduce); System.out.println(reduce.toString()); //输出 true// 张三李四王二麻子 首先提供一个基本容器identity,然后两个参数r即是identity,x为每次输入参数,最后一个StringBuilder::append是并发下多个identity的合并策略.再举个例子,既然reduce属于归纳性操作,那么也可以当成collect使用,如下:1234567891011121314ArrayList&lt;String&gt; identity = new ArrayList&lt;&gt;(); ArrayList&lt;String&gt; result = testData.stream() .flatMap(x -&gt; Stream.of(x.split(""))) .reduce(identity, (r, x) -&gt; &#123; r.add(x); return r; &#125;,(r1,r2) -&gt; &#123; r1.addAll(r2); return r1; &#125;); System.out.println(identity == result); System.out.println(result); //输出 true //[张, 三, 李, 四, 王, 二, 麻, 子] 强大的collectcollect无疑是stream中最强大的操作,掌握了collect操作才能说掌握了stream.为了便于使用者,Java提供了Collectors类,该类提供了很多便捷的collect操作,如Collector&lt;T, ?, List&lt;T&gt;&gt; toList(),Collector&lt;T, ?, Set&lt;T&gt;&gt; toSet()等操作.这些操作最终都会调用如下构造函数构造出collector对象,因此掌握该本质是最佳的学习方式.1234567891011CollectorImpl(Supplier&lt;A&gt; supplier, BiConsumer&lt;A, T&gt; accumulator, BinaryOperator&lt;A&gt; combiner, Function&lt;A,R&gt; finisher, Set&lt;Characteristics&gt; characteristics) &#123; this.supplier = supplier; this.accumulator = accumulator; this.combiner = combiner; this.finisher = finisher; this.characteristics = characteristics; &#125; Supplier类似reduce中的u,接收一个元数据,BiConsumer则是操作数据,BinaryOperator并发下聚合,finisher完成时的转换操作,Set应该按照定义是优化一些操作中的转换.如下面的toList()操作,其finish操作为castingIdentity().123456public static &lt;T&gt; Collector&lt;T, ?, List&lt;T&gt;&gt; toList() &#123; return new CollectorImpl&lt;&gt;((Supplier&lt;List&lt;T&gt;&gt;) ArrayList::new, List::add, (left, right) -&gt; &#123; left.addAll(right); return left; &#125;, CH_ID); &#125; 再看toMap的实现12345678910public static &lt;T, K, U, M extends Map&lt;K, U&gt;&gt;Collector&lt;T, ?, M&gt; toMap(Function&lt;? super T, ? extends K&gt; keyMapper, Function&lt;? super T, ? extends U&gt; valueMapper, BinaryOperator&lt;U&gt; mergeFunction, Supplier&lt;M&gt; mapSupplier) &#123; BiConsumer&lt;M, T&gt; accumulator = (map, element) -&gt; map.merge(keyMapper.apply(element), valueMapper.apply(element), mergeFunction); return new CollectorImpl&lt;&gt;(mapSupplier, accumulator, mapMerger(mergeFunction), CH_ID);&#125; Function作为转换函数提供了key和value的转换,BinaryOperator提供了重复key合并策略,mapSupplier则表示最终收集到的容器.那么使用就很简单了123HashMap&lt;Character, String&gt; map = testData.stream() .collect(Collectors.toMap(x -&gt; x.charAt(0), Function.identity() , (v1, v2) -&gt; v2, HashMap::new)); 其他还有很多方法,就不一一叙述,主要是了解这些接口,知道他所拥有的功能,以及组合的意义,即可很好的掌握Java中的函数式编程. 个人博客 mrdear.cn ,欢迎交流]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中序列化相关知识]]></title>
    <url>%2F2017%2F05%2F02%2F%E5%B7%A5%E5%85%B7%2FJava%E4%B8%AD%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[今天线上遇到了DTO类实现了Serializable接口,但是其并没有显示声明serialVersionUID,这样的话每次打包有改动JDK就会为其重新生成serialVersionUID.这就带来了不同版本之间的实体类可能反序列化不成功,线上RPC调用出现了问题.那么就深入探讨一下原因. Serializable的作用看该类的JDK注释可以发现The serialization interface has no methods or fields and serves only to identify the semantics of being serializable.也就是说Serializable是一个标识接口,和Cloneable接口等一样的效果.如下面的User类,实现了序列化接口,并使用serialVersionUID标识其序列化对应的ID序号.12345static class User implements Serializable &#123; private static final long serialVersionUID = 5768430629641297769L; private String nickname; private String passwd; //省略get和set 如何序列化java.io.ObjectOutputStream代表对象输出流,其使用writeObject()方法把对象实例转换为字节流然后写入到文件,或者用于网络传输.12345678910@Testpublic void testWriteObj() throws IOException &#123; User userDO = new User(); userDO.setNickname("屈定"); userDO.setPasswd("123456"); File file = new File("user.out"); ObjectOutputStream outputStream = new ObjectOutputStream(new FileOutputStream(file)); outputStream.writeObject(userDO);//序列化写入到文件中. outputStream.close();&#125; 如何反序列化java.io.ObjectInputStream代表对象输入流,其使用readObject()方法读取序列化的字节,然后再转换为对象.12345678@Testpublic void testReadObj() throws IOException, ClassNotFoundException &#123; File file = new File(base+File.separator+"user.out"); ObjectInputStream inputStream = new ObjectInputStream(new FileInputStream(file)); User user = (User) inputStream.readObject(); Assert.assertTrue(StringUtils.equals(user.getNickname(),"屈定")); Assert.assertTrue(StringUtils.equals(user.getPasswd(),"123456"));&#125; serialVersionUID的作用按照上面代码,序列化和反序列化都是成功的,如果在已经序列化后,对User要作修改,增加一个email字段,再试试反序列化.123456 static class User implements Serializable &#123; private static final long serialVersionUID = 5768430629641297769L; private String nickname; private String passwd; private String email;&#125; 程序会正常运行,而且这个email会被很智能的初始化为null.修改serialVersionUID为1L再试试.1java.io.InvalidClassException: cn.edu.aust.test.ObjectTest$User; local class incompatible: stream classdesc serialVersionUID = 5768430629641297769, local class serialVersionUID = 1 报错很明显,两边类的serialVersionUID不一样,也就是说对于编译好的class,其serialVersionUID是其序列化的唯一标识,如果未显示声明JDK则会自动为其加上,换句话说serialVersionUID保证了对象的向上兼容,可以使用命令seriserialver可以查看一个class文件的serialVersionUID,当线上版本忘记加该字段的时候该命令还是很有用处的.12seriserialver cn.edu.aust.test.ObjectTest\$User cn.edu.aust.test.ObjectTest$User: private static final long serialVersionUID = 1L; 另外需要注意反序列化因为是直接从字节流里面构造出对象,因此并不会去执行构造函数.如果你的类有在构造函数中初始值的行为,那么这里就可能得到异常. transient的作用transient翻译为瞬时,也就是被其修饰的变量序列化时会忽略该字段.什么时候需要用到这个字段呢?在Java中对象之间的关系会组成一个对象图,序列化的过程是对该对象图的遍历,那么反序列化也仍然是对该对象图的遍历.对于对象里面的对象就是递归过程,对于链表之类的数据结构递归的话很容易引起栈溢出,那么就可以使用transient忽略该字段.]]></content>
      <categories>
        <category>工作问题</category>
      </categories>
      <tags>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对一个WEB请求的理解]]></title>
    <url>%2F2017%2F04%2F30%2F%E8%BF%90%E7%BB%B4%2F%E5%AF%B9%E4%B8%80%E4%B8%AAWEB%E8%AF%B7%E6%B1%82%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[随着写的WEB程序越来越多,项目的部署也越来越繁琐,对于一些线上问题总是搞不清楚是哪个环节出的问题,归根结底是对整个流程的不熟悉导致,所以分析下一个WEB请求从用户输入地址到页面出来到底经历过多少东西. URL解析首先把URL分割为几个部分,以地址http://mrdear.cn/2017/04/15/动漫推荐/为例协议: http网址: mrdear.cn资源路径: 2017/04/15/动漫推荐/ 浏览器拿到地址后会对其中非ASCII码的Unicode字符解析,比如空格会变成%20,汉字也会变成其16进制对应的编码值,如下例子:12上面链接等价于http://mrdear.cn/2017/04/15/%E5%8A%A8%E6%BC%AB/%E5%8A%A8%E6%BC%AB%E6%8E%A8%E8%8D%90/ 中间还有其他很复杂的流程,比如参数,协议,请求头,请求体等建立. DNS域名解析对于网址mrdear.cn,浏览器并不知道他所处的服务器位置,因此需要解析出其服务器ip,这个过程就是DNS域名解析. 浏览器首先检查自身缓存dns解析,以chrome为例,输入chrome://net-internals/#dns即可看到缓存列表.该缓存通常几分钟到几小时不等,存在的话就直接返回,否则下一步 和浏览器同样策略,OS对每一次解析结果也会做缓存,浏览器中不存在则在OS的缓存中查找.这个过成功也包括在本地hosts中查找.找到则返回,找不到则向本机的dns服务器发送查找请求. DNS服务器和本机在一个子网内,则APR解析到具体设备的mac地址,然后向其查找.如果不在一个子网,则直接ARP解析当前主机网关地址,网关一般是上一个路由节点,也就是把查询转交给上一层服务器,那么上一层服务器找不到还会转交给它的上一层,如此形成一个递归查询过程,直到查找到根服务器.找不到则返回失败.找到则返回ip地址和其TTL时间.linux和unix下的dns配置在/etc/resolv.conf中,可以使用nslookup或者dig查看解析过程. 解析成功后,浏览器创建与服务器的socket连接,构造请求信息,进行TCP三次握手,开始向服务器传输消息,并等服务器回复信息,这也是TPC可靠的一个原因. 服务器响应服务器以nginx+tomcat为例,经过以上步骤后请求到达了nginx,nginx对URL进行分析,验证其所在机器上有所需要的服务,并且用户是有权限调用的,决定该URL由哪一个tomcat服务处理,捕获处理结果,返回给请求者,最后四次挥手结束请求.到此完成浏览器,服务端的通信. 浏览器渲染浏览器拿到了服务器的返回信息后会对内容进行解析,展现成用户所需要的内容,如html,pdf等. 那么整个过程总结来看就是 用户输入URL -&gt; 浏览器解析地址 -&gt; DNS查找域名对应ip -&gt; 服务器响应 -&gt;浏览器拿到响应渲染. 附录1.CDN网络CDN又叫内容分布网络,一般用于静态资源如html,css,js的存储,简单的理解为一张大网,网上每一个节点都有着很多资源.那么每一个用户想要访问的时候就会去找离他最近的节点上面获取需要的内容.从而加快了网站整体访问速度.举个例子:用户访问taobao的某css文件,首先浏览器会发送请求 -&gt; DNS解析域名,这里一般会有一个DNS负载均衡服务器,其得到最适合用户的CDN节点ip -&gt; 用户拿到CDN节点ip得到资源. 2.DNS劫持了解了DNS的解析是一个递归过程,找到域名 &lt;-&gt; ip就返回,如果有人手动修改了该条映射信息,那么就会返回到错误的ip地址,这种行为也叫DNS劫持,对于客户端来说,没有很好地方式能认为服务器返回的信息是可靠的,也就是不可靠的HTTP通信,所以也就导致了这一层的攻击漏洞,而这种事一般是天朝的电信运营商能干得出来,所以选择一个靠谱的DNS是非常重要,推荐114.114.114.114 3.HTTPS应对HTTP的不可靠通信,所以诞生了HTTPS,即HTTP over SSL,使用SSL/TLS对HTTP的内容进行加密解密.整个流程如下图: 在SSL握手阶段，客户端浏览器会认证服务器的身份，这是通过“证书”来实现的，证书由证书权威（CA）为某个域名签发，可以理解为网站的身份证件，客户端需要对这个证件进行认证，需要确定该证书是否属于目标网站并确认证书本身是否有效。最后在握手阶段，通信的双方还会协商出一个用于加密和解密的会话密钥。 SSL握手阶段结束之后，服务器和客户端使用协商出的会话密钥对交互的数据进行加密/解密操作，对于HTTP协议来说，就是将HTTP请求和应答经过加密之后再发送到网络上。HTTPS协议对服务器进行了一次身份验证,所以即使DNS被劫持,定向到的服务器也会因为没证书而无法通过身份验证. 4.乱码问题流程清晰后乱码问题就很好解决了,把浏览器,Nginx,Tomcat等都当成水池的话,数据的乱码只能在每一个的入口端和出口端.如果发生了乱码,那么首先定位到是哪一个口产生了乱码,然后再去找原因,一般都能解决.以JavaWEB应用为例,乱码主要发生在IO交互的过程中.其一浏览器与服务器建立socket连接,浏览器对URL以及request转换编码.请求到达tomcat,tomcat会对其进行解码,这个解码可在tomcat目录下的conf/server.xml中配置URIEncoding12&lt;connector port=”8080″ protocol=”HTTP/1.1″ maxThreads=”150″ connectionTimeout=”200000″ redirecPort=”8443″ URIEncoding=”utf-8″/&gt; 这里要保证不乱码,下一步tomcat建立了ServletRequest和ServletResponse,那么这里也有编码,一般是post表单或者request body乱码,那么就需要指定ServletRequest和ServletResponse的编码格式12request.setCharacterEncoding(encoding);//设置请求信息编码response.setCharacterEncoding(encoding);//设置返回信息编码 Java程序在处理请求时和操作系统会有IO通信,和数据库会有IO通信,整个过程也会涉及编码,这种一般代码中会自动控制,出问题几率不大.浏览器拿到返回信息后对页面进行渲染,这一步也会有编码,这个一般手动指定下浏览器的渲染编码,比如Content-Type: text/html;charset=UTF-8,指定以UTF-8渲染该text/html返回. 5.几种域名解析域名解析记录主要分为：A 记录、MX记录、CNAME 记录、NS记录和 TXT记录 A记录：A 代表的是Address，用来指定域名对应的IP地址。域名可以多对一但是不能一对多。 MX记录：Mail Exchange,就是讲某个域名下的邮件服务器指向自己的Mail Server。 CNAME记录：别名解析。将一个域名设置一个或者多个别名。 NS记录：为某个域名指定DNS解析服务器。 TXT记录：为某个主机名或者域名设置文字说明。本站是托管于github的,主域名mrdear.cn是使用CNAME解析到nl101531.github.io的,二级域名oj.mrdear.cn和md.mrdear.cn都是使用A记录解析到对应主机的ip地址,到达主机后再使用Nginx进行不同的服务器转发. 后记个人总结,如有错误请指出,以免误人子弟.]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[少走弯路的10条建议(转)]]></title>
    <url>%2F2017%2F04%2F21%2F%E7%BB%8F%E9%AA%8C%2F%E5%B0%91%E8%B5%B0%E5%BC%AF%E8%B7%AF%E7%9A%8410%E6%9D%A1%E5%BB%BA%E8%AE%AE(%E8%BD%AC)%2F</url>
    <content type="text"><![CDATA[少走弯路的10条建议(转)标签（空格分隔）： 经验 转载自一个很佩服的大牛博客:孤傲苍狼 如何在涉世之初少走弯路，有一个好的开端，开始一番成功的事业？以下是一些先行者积累的10条有益的涉世忠告。好好地遵循、把握这些忠告和建议吧，比起所学的课堂课程来，它毫不逊色！ 1.1、买个闹钟，以便按时叫醒你 贪睡和不守时，都将成为你工作和事业上的绊脚石，任何时候都一样。不仅要学会准时，更要学会提前。就如你坐车去某地，沿途的风景很美，你忍不住下车看一看，后来虽然你还是赶到了某地，却不是准时到达。“闹钟”只是一种简单的标志和提示，真正灵活、实用的时间，掌握在每个人的心中。 1.2、如果你不喜欢现在的工作，要么辞职不干，要么就闭嘴不言 初出茅庐，往往眼高手低，心高气傲，大事做不了，小事不愿做。不要养成挑三拣四的习惯。不要雨天烦打伞，不带伞又怕淋雨，处处表现出不满的情绪。记住，不做则已，要做就要做好。 1.3、每个人都有孤独的时候 要学会忍受孤独，这样才会成熟起来。年轻人嘻嘻哈哈、打打闹闹惯了，到了一个陌生的环境，面对形形色色的人和事，一下子不知所措起来，有时连一个可以倾心说话的地方也没有。这时，千万别浮躁，学会静心，学会忍受孤独。在孤独中思考，在思考中成熟，在成熟中升华。不要因为寂寞而乱了方寸，而去做无聊无益的事情，白白浪费了宝贵的时间。 1.4、走运时要做好倒霉的准备 有一天，一只狐狸走到一个葡萄园外，看见里面水灵灵的葡萄垂涎欲滴。可是外面有栅栏挡着，无法进去。于是它一狠心绝食三日，减肥之后，终于钻进葡萄园内饱餐一顿。当它心满意足地想离开葡萄园时，发觉自己吃得太饱，怎么也钻不出栅栏了。相信任何人都不愿做这样的狐狸。退路同样重要。饱带干粮，晴带雨伞，点滴积累，水到渠成。有的东西今天似乎一文不值，但有朝一日也许就会身价百倍。 1.5、不要像玻璃那样脆弱 有的人眼睛总盯着自己，所以长不高看不远；总是喜欢怨天尤人，也使别人无比厌烦。没有苦中苦，哪来甜中甜？不要像玻璃那样脆弱，而应像水晶一样透明，太阳一样辉煌，腊梅一样坚强。既然睁开眼睛享受风的清凉，就不要埋怨风中细小的沙粒。 1.6、管住自己的嘴巴 不要谈论自己，更不要议论别人。谈论自己往往会自大虚伪，在名不副实中失去自己。议论别人往往陷入鸡毛蒜皮的是非口舌中纠缠不清。每天下班后和你的那些同事朋友喝酒聊天可不是件好事，因为，这中间往往会把议论同事、朋友当做话题。背后议论人总是不好的，尤其是议论别人的短处，这些会降低你的人格。 1.7、机会从不会“失掉”，你失掉了，自有别人会得到 不要凡事在天，守株待兔，更不要寄希望于“机会”。机会只不过是相对于充分准备而又善于创造机会的人而言的。也许，你正为失去一个机会而懊悔、埋怨的时候，机会正被你对面那个同样的“倒霉鬼”给抓住了。没有机会，就要创造机会，有了机会，就要巧妙地抓住。 1.8、若电话老是不响，你该打出去 很多时候，电话会给你带来意想不到的收获，它不是花瓶，仅仅成为一种摆设。交了新朋友，别忘了老朋友，朋友多了路好走。交际的一大诀窍就是主动。好的人缘好的口碑，往往助你的事业更上一个台阶。 1.9、千万不要因为自己已经到了结婚年龄而草率结婚 想结婚，就要找一个能和你心心相印、相辅相携的伴侣。不要因为放纵和游戏而恋爱，不要因为恋爱而影响工作和事业，更不要因一桩草率而失败的婚姻而使人生受阻。感情用事往往会因小失大。 1.10、写出你一生要做的事情，把单子放在皮夹里，经常拿出来看 人生要有目标，要有计划，要有提醒，要有紧迫感。一个又一个小目标串起来，就成了你一生的大目标。生活富足了，环境改善了，不要忘了皮夹里那张看似薄薄的单子。]]></content>
      <categories>
        <category>经验</category>
      </categories>
      <tags>
        <tag>经验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Angular2学习记录-给后端程序员的经验分享]]></title>
    <url>%2F2017%2F04%2F08%2Fweb%2Fangular2%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95-%E7%BB%99%E5%90%8E%E7%AB%AF%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[1.前言前几天刚下定决心把毕业设计改造下,因为毕业设计算是我学习的基石,学习到的东西都尽可能的在这个平台上施展,锻炼自己.改造为前后端分离,前端使用angular2,后端只提供接口.便于以后的维护.那么就要学习agular2了. 这里就要说下个人观点了,安利一波:我认为每个程序员都应该有自己的一个项目,一个可以让你学习的东西能施展到上面的项目,可能该项目一开始很简单,但是随着你不断的学习,不断的把新知识运用进去,这个项目就会伴随着你的成长而丰富起来,给你带来的则是更多的实战经验. 2.angular2简介 angular2是类似全家桶组合的框架,所需要的东西几乎都包办了,所以开发起来很迅速. 使用TypeScript作为开发语言,对于Java和C#程序员可以快速上手,还有就是我比较喜欢强类型语言,每个变量各司其职,由其的类型来限定,开发人员也很明确知道变量的作用. google和Microsoft支持 WebStorm对angular2的强大支持. 一篇安利文章http://www.infoq.com/cn/articles/why-choose-angular2/ 一些学习资料ECMAScript 6入门 http://es6.ruanyifeng.com/TypeScript入门 http://www.imooc.com/learn/763TypeScript中文网 https://www.tslang.cn/docs/tutorial.html慕课网1小时快速上手视频 http://www.imooc.com/learn/789官方文档 https://www.angular.cn/docs/ts/latest/cli-quickstart.html 3.遇到的问题3.1滚动监听要实现页面滚动后导航栏会变色的效果,如下图(图来自我的csdn博客,没找到其他好图床) 之前使用Jq是123$(window).scroll(function () &#123; indexApp.scrollBar = parseInt(document.body.scrollTop||document.documentElement.scrollTop);&#125;); 不打算依赖Jq,搜了点资料发现了下面两种写法.1234567891011//下面这种写法在TS下不会有效果. isAddBackColor()&#123; if (this.getIsIndex())&#123; var self = this; //该处使用匿名函数,而不是箭头函数. window.addEventListener('scroll',function () &#123; let marginTop = document.body.scrollTop|| document.documentElement.scrollTop; self.isBackColor = marginTop &gt; 20 &amp;&amp; self.getIsIndex(); &#125;); &#125; &#125; 12345678910111213/** * 判断是否需要加背景色(有效果的) * 使用isBackColor控制结果 */ isAddBackColor()&#123; if (this.getIsIndex())&#123; //监听事件使用箭头函数,这样ng2才会管理该变量 window.addEventListener('scroll',() =&gt; &#123; let marginTop = document.body.scrollTop|| document.documentElement.scrollTop; this.isBackColor = marginTop &gt; 20 &amp;&amp; this.getIsIndex(); &#125;); &#125; &#125; 原因不明,猜想是var self = this;赋值操作后相当于一个全新的变量,self并不受angular管理,导致刷新的变量是self中的isBackColor. 3.2http参数传递按照下面代码传参数应该是没有问题的,但是我遇到了url被编码问题,例如输入1111@qq.com会被转换为1111%40qq.com,导致服务端解析失败,找了很多原因才发现是URLSearchParams这个对象用错了,angular2提供了这个对象,es6里面也有一个该对象,换成ng2中对象即可,import {URLSearchParams} from &quot;@angular/http&quot;;12345678let urlParams = new URLSearchParams();urlParams.set('search',search);urlParams.set('order',order);urlParams.set('pageNum',pageNum.toString());urlParams.set('pageSize',pageSize.toString());return this.http.get(Config.url_problem_stage + stage,&#123;params:urlParams&#125;).toPromise() .then(response =&gt; response.json()) .catch(LogService.handleError) 3.3跨域问题浏览器要求同源下才可请求,否则就产生跨域问题. URL 说明 是否允许通信 http://www.a.com/a.jshttp://www.a.com/b.js 同一域名下 允许 http://www.a.com/lab/a.js http://www.a.com/script/b.js 同一域名下不同文件夹 允许 http://www.a.com:8000/a.js http://www.a.com/b.js 同一域名，不同端口 不允许 http://www.a.com/a.js https://www.a.com/b.js 同一域名，不同协议 不允许 http://www.a.com/a.js http://70.32.92.74/b.js 域名和域名对应ip 不允许 http://www.a.com/a.js http://script.a.com/b.js 主域相同，子域不同 不允许 http://www.a.com/a.js http://a.com/b.js 同一域名，不同二级域名（同上） 不允许（cookie这种情况下也不允许访问） http://www.cnblogs.com/a.js http://www.a.com/b.js 不同域名 不允许 解决方案是用nginx反向代理到不同端口,模拟同一域名下不同文件夹情况.nginx监听本地888端口,这个也是项目入口,对于带api标识的请求转到后端服务器,对于其他请求则到前端服务器.123456789101112131415server &#123; listen 8888; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location /api &#123; proxy_pass http://127.0.0.1:8080; &#125; location / &#123; proxy_pass http://127.0.0.1:4200; &#125;&#125; 3.4路由问题angular2的路由匹配规则是从根路由也就是forRoot()的这个开始.在该处匹配寻找规则. 根路由:12345678910111213141516171819export const appRoutes: Routes = [ &#123; path:'', component: IndexComponent, pathMatch:'full' &#125;, &#123; path:'aust', loadChildren:'./content/content.module#ContentAndAsideModule' &#125;, &#123; path:'index', component: IndexComponent, &#125;, &#123; path:'**', loadChildren:'./content/content.module#ContentAndAsideModule' &#125;,]; 子路由:12345678910export const childRouter : Routes = [ &#123; path: '', component:ContentAndAsideComponent, children:[ &#123;path:'',redirectTo:'/index',pathMatch:'full'&#125;, &#123;path:'start',component:StartComponent&#125;, ] &#125; ]; 举例:访问/,则先在根路由寻找,找到其跳转到IndexComponent,完成任务访问/aust.则先在根路由找,发现需要到子路由里面寻找,到子路由后,在children中发现被重定向到/index,那么回到根路由,找到IndexComponent完成任务.访问/aust/start,则先在根路由找,发现需要到子路由,到子路由匹配到StartComponent,完成任务. 路由参数路由传参数主要有两种方式,一种是restful风格的,一种是?号参数风格的.两种参数都保存在ActivatedRoute对象中,因此下面代码中的route为此对象— restful风格配置:{path:&#39;article/:id&#39;,component:ArticleComponent}链接:http://domain/article/1路由:[routerLink]=&quot;[&#39;article&#39;,article.id]&quot;或者直接拼接urljs获取:this.route.params中的一系列方法,或者this.route.snapshot.params[&#39;id&#39;]— 问号参数风格配置:{path:&#39;article&#39;,component:ArticleComponent}链接:http://domain/article?id=1路由:routerLink=&quot;article&quot; [queryParams]=&quot;{id: article.id}&quot;js获取:this.route.queryParams中的一系列方法,或者this.route.snapshot.queryParams[&#39;id&#39;],另外可以使用订阅模式queryParamMap.subscribe(),路由参数更新时自动通知 3.5组件通信父-&gt;子:子组件使用input装饰器,接受父组件的属性,并且可使用ngOnChanges或则setter监听变化,做额外处理.子-&gt;父:使用output装饰器加EventEmitter向上弹出事件到父组件,父组件监听后处理.任意组件:使用service通讯(要求service单例),service提供Observable的next发布,其他组件引用service对象subscribe该发布,那么就实现了信息的流动,并且是在只要订阅了该发布的组件中都能获取. 3.6单例?agular2的service是providers提供的,该组件如果引用了这个service,那么会先在自己的providers中寻找service,找不到则再向上找父组件,直到module.那么意味着每一个providers提供的是一个实例,旗下的组件都是享用这一个实例,那么怎么实现全局单例呢?很简单在根module中提供服务且其他组件不要自己providers该服务. 3.7组件生命周期组件生命周期看下面这张图.图中没有onChanges(changes: SimpleChanges)方法的调用,该方法检测到组件的输入属性发生变化时调用,也就是存在@input装饰的属性,该属性每次变化时会调该方法. 3.8部署问题单页应用部署到服务器上可能会出现访问www.domain.xx可以访问,并且点击什么的都能成功,但是直接访问其中一个路由www.domain.xx/aust/start却报404.先分析下问题的原因,我们的单页应用只有一个入口,报404也就是没找到这个入口.看nginx的配置.nginx收到请求后会去root下寻找aust/start下的index.html那么自然找不到,所以直接访问就会404.那么问题来了为什么访问www.domain.xx之后页面内跳转到路由没问题呢?这是因为访问主域名后angular的js都已经全部加载了,这个时候跳转是js来控制的,不经过nginx自然不会出现上面的问题.1234location / &#123; root /Users/niuli/workspace/web/austoj/dist; index index.html index.htm;&#125; 解决方法:解决方法就是让其对于路由都去加载index.html这个文件.使用try_files指令,该指令会把uri当成一个文件,去根目录下寻找,找不到的话则内部重定向到配置的/index.html.这样配置的好处,对于静态资源try_files会直接找到后就返回,对于路由则会定向到/index.html.12345location / &#123; try_files $uri /index.html; root /Users/niuli/workspace/web/austoj/dist; index index.html index.htm;&#125; 3.9文件上传文件上传是通过ajax操作上传,使用FormData形式,主要有以下问题要解决. 怎么获得input框所选中的文件(为input绑定change事件,然后获取$event,文件就是event.srcElement.files[0]) 怎么上传到服务器?(使用formData对象,调用其append方法添加文件,再使用angular2的http组件post上去)1234567uploadAvatar(file: any): Promise&lt;any&gt;&#123; let formData:FormData = new FormData(); formData.append('avatar',file); return this.http.post(Config.url_upload_img,formData).toPromise() .then(response =&gt; response.json()) .catch(LogService.handleError); &#125; angular2项目:https://github.com/nl101531/AUSTOJ-WEB]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>angular</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习记录(四)-SpringDataRedis分析]]></title>
    <url>%2F2017%2F03%2F29%2Flinux%2Fredis%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E5%9B%9B)-SpringDataRedis%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[redis学习记录(四)-SpringDataRedis分析标签（空格分隔）： redis Redis学习记录(一)–入门知识Redis学习记录(二)–使用Jedis连接redis学习记录(三)-redis中的数据结构 1.简介Spring Data Redis是对redis客户端(如jedis)的高度封装,支持多种客户端,因其高抽象,所以在某一个客户端不支持更新的时候可以容易切换到其他客户端. 本文是在Spring boot 1.5.2版本下测试. 需要引入架包12345678910111213141516171819202122232425262728&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.2.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!--spring boot start--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.配置在Spring Boot下默认使用jedis作为客户端,并在包org.springframework.boot.autoconfigure.data.redis下,提供自动配置类RedisProperties,RedisAutoConfiguration等. 根据RedisProperties可以定位到可配置的属性,如:123456789101112131415161718# Redis数据库索引（默认为0）spring.redis.database=0# Redis服务器地址spring.redis.host=115.159.185.14# Redis服务器连接端口spring.redis.port=6379# Redis服务器连接密码（默认为空）spring.redis.password=# 连接池最大连接数（使用负值表示没有限制）spring.redis.pool.max-active=8# 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.pool.max-wait=-1# 连接池中的最大空闲连接spring.redis.pool.max-idle=8# 连接池中的最小空闲连接spring.redis.pool.min-idle=0# 连接超时时间（毫秒）spring.redis.timeout=2000 在application.properties中配置即可,另外还有Sentinel和Cluster说明支持分布式和集群,博主研究不多就不瞎说这个了. 自动配置主要在RedisAutoConfiguration中,该类会提供三个bean: JedisConnectionFactory : jedis连接控制工厂 RedisTemplate : redis操作入口 StringRedisTemplate : redis操作入口 那么就开始入口学习. 3.RedisTemplateRedisTemplate是操作的入口.该类继承了RedisAccessor,可以通过其拿到redis连接,实现了RedisOperations接口,获得了操作redis的能力,如下图所示: 3.1 Test case那么具体操作过程是怎么样子的呢?写一个简单的测试去跟踪代码,如下代码,往redis中设置key为ping的字串.123456789101112@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = Application.class)public class RedisConnectTest &#123; @Resource private RedisTemplate&lt;String,String&gt; redisTemplate; @Test public void testSetAndGet() &#123; redisTemplate.opsForValue().set("ping","pong"); System.out.println(redisTemplate.opsForValue().get("ping")); &#125;&#125; 运行之后查看redis数据库,你会发现很奇怪的事情,如下图,代码中存入的是ping,但是到redis中后却是一堆字符+ping,这个原因是什么呢?接着跟踪代码. 3.2 XXXOperations上述代码的第一步先获取到了ValueOperations,在RedisTemplate中同样还有其他XXXOperations,根据官方文档,这些接口是针对redis的每一种命令的操作.如下表: 接口 操作 ValueOperations Redis string (or value) operations ListOperations Redis list operations SetOperations Redis set operations ZSetOperations Redis zset (or sorted set) operations HashOperations Redis hash operations HyperLogLogOperations Redis HyperLogLog operations like (pfadd, pfcount,…​) GeoOperations Redis geospatial operations like GEOADD, GEORADIUS,…​) BoundValueOperations Redis string (or value) key bound operations BoundListOperations Redis list key bound operations BoundSetOperations Redis set key bound operations BoundZSetOperations Redis zset (or sorted set) key bound operations BoundHashOperations Redis hash key bound operations BoundGeoOperations Redis key bound geospatial operations. 其中BoundXXXOperations是在key已知的情况下使用,其所有操作都是建立在有一个certain key的前提.可以看下源码就能明白了. 3.3 XXXSerializer那测试代码中第一步是获取了string类型的redis操作入口,然后执行set方法设置键和值,接着分析set方法. 12345678910public void set(K key, V value) &#123; final byte[] rawValue = rawValue(value); execute(new ValueDeserializingRedisCallback(key) &#123; protected byte[] inRedis(byte[] rawKey, RedisConnection connection) &#123; connection.set(rawKey, rawValue); return null; &#125; &#125;, true);&#125; 可以发现rawKey()方法和rawValue()方法对key和value进行了一次序列化操作.该序列化使用的类为RedisTemplate中的XXXSerializer,那么回到RedisTemplate,在afterPropertiesSet()方法中有以下初始化方法,默认使用的序列化方式为JdkSerializationRedisSerializer,也就是ObjectInputStream和ObjectOutputStream写入和读取.这也是写入到redis中却在redis数据库通过”ping”访问不到的原因.1234567891011121314151617181920212223if (defaultSerializer == null) &#123; defaultSerializer = new JdkSerializationRedisSerializer( classLoader != null ? classLoader : this.getClass().getClassLoader()); &#125; if (enableDefaultSerializer) &#123; if (keySerializer == null) &#123; keySerializer = defaultSerializer; defaultUsed = true; &#125; if (valueSerializer == null) &#123; valueSerializer = defaultSerializer; defaultUsed = true; &#125; if (hashKeySerializer == null) &#123; hashKeySerializer = defaultSerializer; defaultUsed = true; &#125; if (hashValueSerializer == null) &#123; hashValueSerializer = defaultSerializer; defaultUsed = true; &#125; &#125; 那么SpringDataRedis支持哪些序列化呢?从官网可以看到:StringRedisSerializer: string类型序列化,也是最常用的类型JdkSerializationRedisSerializer: jdk默认序列化OxmSerializer : xml格式JacksonJsonRedisSerializer : json格式 通过手动注入RedisTemplate,更改所选择的序列化方式.另外Spring提供了最常使用的StringRedisTemplate,实现了StringRedisSerializer序列化方式.1234567public StringRedisTemplate() &#123; RedisSerializer&lt;String&gt; stringSerializer = new StringRedisSerializer(); setKeySerializer(stringSerializer); setValueSerializer(stringSerializer); setHashKeySerializer(stringSerializer); setHashValueSerializer(stringSerializer);&#125; 更改成StringRedisTemplate,再次执行,正常了. 3.4 总结过程 获取RedisTemplate 获取操作入口XXXOperations 使用RedisSerializer序列化key和value 获取conn连接 执行命令 4.发布与订阅发布与订阅过程需要发布者,订阅者,以及把两者连在一起的桥梁.那么在SpringRedis中怎么实现呢?订阅者:里面有一个处理方法即可.12345678910111213141516@Componentpublic class Listen &#123; private static Logger logger = LoggerFactory.getLogger(Listen.class); private CountDownLatch latch = new CountDownLatch(1); public void handleMsg(String message) &#123; logger.info("reciver msg :" + message); latch.countDown(); &#125; public CountDownLatch getLatch() &#123; return latch; &#125;&#125; 发布者:XXXRedisTemplate.convertAndSend(chanel,msg)即作为发布者存在. 连接桥梁:RedisMessageListenerContainer,该container监听Redis的消息,分发给各自的监听者.关键代码为 123456789101112131415161718192021222324@Configurationpublic class PublishConfig &#123; /** * 注入消息容器 * @param jedisConnectionFactory jedis连接池 * @param listenerAdapter 监听适配器 * @return bean */ @Bean public RedisMessageListenerContainer container(RedisConnectionFactory jedisConnectionFactory, MessageListenerAdapter listenerAdapter)&#123; RedisMessageListenerContainer container = new RedisMessageListenerContainer(); container.setConnectionFactory(jedisConnectionFactory); //绑定监听者与信道的管理 container.addMessageListener(listenerAdapter,new PatternTopic("java")); return container; &#125; @Bean public MessageListenerAdapter adapter(Listen listen)&#123; //指定监听者和监听方法 return new MessageListenerAdapter(listen,"handleMsg"); &#125;&#125; 测试:12345@Testpublic void testPublish() throws InterruptedException &#123; stringRedisTemplate.convertAndSend("java","hello world"); listen.getLatch().await();&#125; 5.事务对于事务的操作是通过SessionCallback实现,该接口保证其内部所有操作都是在同一个Session中的,在最后exec的时候执行全部操作.关键代码如下12RedisConnectionUtils.bindConnection(factory, enableTransactionSupport);execute(this) 12345678910111213141516171819202122232425@Test public void testMulti() &#123; boolean isThrow = false; List&lt;Object&gt; result = null; try &#123; result = stringRedisTemplate.execute(new SessionCallback&lt;List&lt;Object&gt;&gt;() &#123; @Override public List&lt;Object&gt; execute(RedisOperations operations) throws DataAccessException &#123; operations.multi(); ValueOperations&lt;String,String&gt; ops = operations.opsForValue(); ops.set("ping1","pong1"); ops.set("ping2","pong2"); if (isThrow)&#123; throw new IllegalArgumentException("测试异常"); &#125; return operations.exec(); &#125; &#125;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; System.out.println(result); &#125; 6.管道直接引用官方案例1234567891011//pop a specified number of items from a queueList&lt;Object&gt; results = stringRedisTemplate.executePipelined( new RedisCallback&lt;Object&gt;() &#123; public Object doInRedis(RedisConnection connection) throws DataAccessException &#123; StringRedisConnection stringRedisConn = (StringRedisConnection)connection; for(int i=0; i&lt; batchSize; i++) &#123; stringRedisConn.rPop("myqueue"); &#125; return null; &#125;&#125;); 还有脚本执行等,在官方文档中都有案例,这里就不复制粘贴了,如有错误请指出,不胜感激. 参考文档: http://docs.spring.io/spring-data/redis/docs/1.8.1.RELEASE/reference/html/#redis:template github: https://github.com/nl101531/JavaWEB]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习记录(三)-redis中的数据结构]]></title>
    <url>%2F2017%2F03%2F26%2Flinux%2Fredis%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%B8%89)-redis%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[redis学习记录(三)-redis中的数据结构标签（空格分隔）： redis Redis学习记录(一)–入门知识oRedis学习记录(二)–使用Jedis连接 redis有五种数据类型,string,list,set,hash,sort set,不同场景使用不同数据结构的前提是了解每一种数据结构.那么结构图片是最佳的了解方式,图片来自慕课网. stringstring是的key-&gt;value类型的存储,可以存储字符串类型和数值类型,可对数值类型是可以增加减少,对string类型可以追加内容. listlist是列表,也就是一个key-&gt;多个value,可以支持双端队列,栈来操作,因此越靠近两端其查找速度越快,端点的复杂度查找为O(1),同时队列有阻塞操作,也就是可以当成阻塞队列使用. setset为无序,且不重复的集合,且提供O(1)复杂度度的快速查找.set集合支持集合的并,交,差操作,因为无序性,因此也提供迭代方法. hashhash类型适合存储对象,相比前面的string,所带来的优势是可以使用一个key查出该下面所有的键值对,并且可以单独对某一属性更改,如图所示: sort set可排序的集合,如图所示存在score排名分数,隐藏属性rank排名,0为最小.注意对sort set来说value是唯一性的,而不是score,如果两个score相同,则按照value的字典序排序. 应用场景string计数器:redis的incr操作是原子性的,因此可以应对高并发,如网站要求每个用户获取验证码后60秒内不得再次获取,那么第一次获取的时候用incr给该用户设置key,过期时间为60秒,如果结果等于1则为第一次请求,那么第二次获取时比较决定是否操作频繁. Listlist的优势的有序性,两端插入复杂度为O(1),那么对于最近文章列表等类似需求是最佳解决方案,维护一个定长的列表,每次插入后执行trim操作. Setset的优势是唯一性,O(1)的查找查找复杂度,并且支持差并集,那么二度好友问题就迎刃而解了. hashhash非常适合存储对象,不同的键为对象的特征,值为特征值,那么比string好的就是修改不需要每次都修改一个整串,而可以选择修改某一指定键值. sort setsort set可排序特性使其很容易解决排行榜类应用,但是要注意值需要存储不变的属性,因为值要求唯一性,score可不唯一.]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ERP叛逃者(转)]]></title>
    <url>%2F2017%2F03%2F19%2F%E9%9A%8F%E8%B0%88%2FERP%E5%8F%9B%E9%80%83%E8%80%85%2F</url>
    <content type="text"><![CDATA[ERP叛逃者(转)标签（空格分隔）： 随谈 作者:alswl原文链接:https://blog.alswl.com/2011/04/erp-defectors/ 一篇对于毕业生很有指导意义的文章,踏入职场,面临的第一个选择就是工作,第一份工作可能并不如你所期望的那样,那么你真正想要什么呢?文章会给你答案. 大四实习时候，跑去驻厂开发，当时主管跟我说”我们做的是企业信息化软件”。毕业之后找工作，进入一家国内还算有名的ERP公司，做ERPII产品（CRM/工作流/ 电子商务平台等ERP软件附属产品）的开发和二次开发。 在这一年半的时间里，我学习了一些行业知识，熟悉了公司自己的开发模式、框架和工具。浑浑噩噩的直到某一天，我发现我写代码没有键盘飞扬的感觉。我惶恐，我感觉我遇到 瓶颈停止成长了。我开始思索我这种状况的产生，我重新翻开曾经看的糊里糊涂的《人月神话》，研读阿朱的《走出软件作坊》，尝试找到问题和解决办法。 我回想我工作之后做的事情：我负责的是从顾问那里拿到伪SQL+伪代码，然后将它们在公司的框架上面实现起来，再手工完成功能性测试。我做一个极端的假设：如果早50 年，ERP公司给用户提供解决方案可以是在纸上提出，根本不需要电脑。所以ERP的本质是对业务的梳理，规范化的引导，让企业高效整合资源充分发挥产能的公司。这与我 想象的IT公司完全不一样，我所希望的IT公司能够追求极致，创造用户喜欢的，快速响应用户需求，扩展性强的产品。如果具备这些元素，会很快被同类公司超越。 可是公司立足于市场近30年，绝对不是这么不堪，她有自己的核心竞争力：标准的业务流程，强大的顾问和实施团队，本土化的产品。 我比较了知名互联网公司、创业型IT公司和传统管理软件行业的区别，惊讶的发现，原来，计算机科学与技术专业毕业的我，不在IT公司，在一家服务咨询公司！！！我把这 个想法和主管进行交流，主管也认同我们提供的是service而不是soft。 我简单比较了互联网企业和传统行业软件企业的差异。 目标人群不一样行业软件：企业用户 互联网产品：个人用户更多，也有企业用户 由于给企业用户进行定制，导致内部封闭现象严重，更新周期漫长。另外，企业用户可以强制要求用户使用某种操作方式或者某种环境，比如我就是要让你用IE6，你不用IE 6系统出现问题，那是你的原因。而互联网产品就面对所有网民，必须考虑到标准问题。 另外，企业用户更换系统平台频率低，系统一旦投入使用，需要经过几年的使用，才会可能考虑更换，其依赖性比互联网产品高出个数量级。由于互联网的开放性，互联网用户很 容易在不同产品之间进行更换。 盈利点不一样互联网：吸引用户使用，所以用户体验，速度是需要考虑的，依赖用户使用情况（VIP制度、广告收入）盈利。 行业软件：卖给产品和服务给用户，功能符合用户需要，顾问实施精准，依赖销售产品+服务盈利。 盈利点造成行业软件未必会把用户体验、速度这些相对次要的问题放在首位考虑，而是考虑先解决实际问题，满足用户需要。 核心竞争力行业软件最依赖的核心竞争力是对某个行业的了解，比如阿朱所在的明源专注于房地产，金蝶用友各有所擅长的行业。并不是他们不想在别的行业挣钱，而是对应行业的顾问极难 培养（行业/领域专家）。 互联网产品的核心竞争力就更多样化，Web2.0时代可以是用户关系，用户基数（腾讯，现在的人人），也可以是某一款特别大众需要的产品（淘宝，搜索引擎，书签服务） ，又或是核心技术（Google），这些核心竞争力会在发展过程中相互转换，相互渗透。 互联网产品的特性是快，这个快是表象，本质是在于互联网产品要充分挖掘用户需求，不断满足现有要求，并预测引领用户需求趋势，这也是创新精神具体体现。由于同质化严重 ，竞争白热化，导致互联网产品纷纷涌现，给人一种爆炸的感觉。其实，一款好的互联网产品从有创意到磨砺成熟，是需要经过一段还算长的时间的。（除非是搞搞微创新，大家 都知道怎么做，没什么核心竞争力，只是拼模拟速度了） 我在想清楚这些之后，发现ERP不是我的归宿，互联网才是我追寻的方向。]]></content>
      <categories>
        <category>经验</category>
      </categories>
      <tags>
        <tag>选择</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F03%2F09%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>随谈</category>
      </categories>
      <tags>
        <tag>随谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何学习一门新技术]]></title>
    <url>%2F2017%2F02%2F01%2F%E9%9A%8F%E8%B0%88%2F%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0%E4%B8%80%E9%97%A8%E6%96%B0%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[在看他人博客的时候发现的,自己也是一直按照这样的模式去学,现在分享下整个流程. 图片来源: dreamfy 是什么?为什么会出现?这一阶段主要是对该技术有一个整体了解,他所解决的是什么问题,他的整体结构等. 怎么做?最简单的是找一个上手视频,因为视频是非常直观的展示了技术的使用.先学会用是最根本的,对于没有视频的技术的话,就可以搜索XX上手教程,XX学习记录之类的关键词,很轻松就找到了相关的上手博文,这一阶段一般都是环境整合搭建,然后写一个简单的入门Demo. 第二个阶段,学会基本使用了就要去看官方文档,文档会让你更加详细的了解该技术的特性,开一个Demo项目把官方的一些例子都试试. 第三个阶段,尝试在一些复杂的项目中使用(非生产项目),使用过程中难免会遇到各种各样的问题,官方文档和搜索引擎会帮助你解决,这一过程你会对该技术掌握更加娴熟. 第三个阶段,去github上找一些别人的项目,主要是看他人的使用方法,模块设计,代码封装等. 第四个阶段,生产项目使用吧,遇到问题还是官方文档和搜索引擎. 分享好记性不如烂笔头,博客记录是一个很好地习惯,能把自己学的东西和他人讲清楚才叫真正的懂了这个技术.]]></content>
      <categories>
        <category>经验</category>
      </categories>
      <tags>
        <tag>学习方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面经]]></title>
    <url>%2F2017%2F01%2F10%2F%E9%9A%8F%E8%B0%88%2F%E9%9D%A2%E7%BB%8F%2F</url>
    <content type="text"><![CDATA[从2016.7来到上海后记录下自己的面试经历,希望能对其他人有所帮助,同时给自己一个提醒. 第二次面试2017.1 上一家公司干了六个月,做的还不错,中间涨了一次工资,也就5000左右,但是公司没技术氛围,而且加班是家常便饭,所以为了自己打算离开了,这里我是提前和领导说不打算续签的,自己离职不太好意思拿年终奖再离职,不过领导知道后还是给我申请了年终奖,感动Ing 第二次面试先电面再去公司面试的,总体感觉很不错,结果还在等… 1.电面首先自我介绍,这个很随意,技术人员一般都不看重这个.1.ArrayList的扩容机制.这个抓住几个点,本质是一个Object的数组,初始容量10,1.7JDK之后每次扩容是1.5倍,但是1.6的JDK版本是1.5倍+1,这个回答出来说明你研究过这个而不是直接背答案.每次add都会进行容量检查,扩容是调用一个native方法System.arrayCopy,2.Map的containsKey和List的contain方法效率一样吗?这个问题回答要表现出List基于数组在查找方面的缺点,就是最坏情况下是查找全部元素后才找到,但是Map是基于Hash链表,查找是根据hash计算出来的索引地址,找到索引后会判断上面是否有链表存在,有的话会接着查找,补充下JDK8之后的HashMap当哈希桶上的链表长度大于8则会转换为一颗红黑树,因此随着碰撞增加仍然会提供稳定的性能.3.自己的项目问题这个就实打实的说就好了.其中有一个项目提到了python,因此面试官问我python学的怎么样,可以来聊聊python,但是我就会基础,所以不了了之,简历上不熟的东西尽量少写. 2.现场面现场面就没问很多基础问题了,主要是一些突发的问题,问了不少Linux的知识,自己又不是太熟,所以处于被虐状态…1.Linux的top命令不会,我说因为公司有运维,用服务器也就查看日志什么,自己不是很了解.面试官说了一句话,说我们这是工程师和运维不分家的,一个好的工程师必然要了解代码是怎么运行的,也就需要对代码运行环境有很深的了解,这样才能写出优秀的代码,大概意思是这样的,感觉很有道理,自己Linux的服务器知识欠缺很多.2.Linux下怎么查看日志因为上面提到了自己用服务器查看日志,所以就直接被问了,博主说一般用cat命令配合grep来查看,或者使用VIM来查看,用tail -f查看实时日志,head查看开始日志等,然后被问了假设日志是10G大小,怎么快速找到自己想要的东西?这个问题想了一会,直接说不会….尴尬,后来提示用less命令,该命令不会全部加载文件.参考博文:Linux下的more和less的使用3.爬取新浪微博用户,怎么判断该用户是否已经爬过博主说了数据量小的话使用Map集合或者Set集合,数据量多的话,就把某一个唯一字段设置为数据库主键,爬取的用户插入到数据库,去重交给数据库来做就好了.接着面试官问如果不使用数据库呢?博主想了想,就随口说爬取一部分用户后写入到文件,然后生成MD5摘要,这样每次写入文件后判断该摘要是否已存在,存在就不写入,牺牲时间,保证最终的结果重复性最低.现在想来还是有问题,爬取是随机的,所以导致生成摘要碰撞几率太低.可能多一个字符少一个字符就导致摘要不同.没想到好办法…4.在做项目中有没有什么取巧的经历?一时间还真想不到…就没答上来.5.在项目中遇到的难点博主说了自己写的集成微信,支付宝,银联,预付费卡的一个支付模块,主要讲了遇到问题怎么解决的,然后怎么封装的.6.关于代码洁癖举个例子博主简历上写自己有代码洁癖,所以就被问了这个,我举了前公司,也就第一家面试的,使用JPA的多表查询时候返回一个Objec[]数组,导致代码没法维护,并且重复代码太多,自己使用queryDSL,对公司代码进行了大面积的修改. 本以为要挂了,最后说技术面过了,不知道是安慰我还是什么,接着是HR面,聊了聊公司现状,待遇问题等,最后也没说过还是不过等通知.因为现在时间点比较尴尬,我提出年后入职,也不知道可不可以….等消息中更新:已收到offer,年后入职,这家公司效率真不错,接下来希望自己有所提高! 第一次面试2016.7 首先简历很重要,程序员不需要太花哨的简历,尽可能的展现出自己的特点就可以了,推荐下面简历,很不错的一个模板.https://github.com/penglongli/My-Resume 第一次面试没有多紧张,可能对方是小公司吧,感觉很随意,面试就问了三个问题.1.谈一谈Java集合这种问题一般都很宽泛,博主就从List讲到Set再到Map这样的顺序来讲的,重点描述Arraylist,LinkedList,HashMap,TreeMap,最后再总结下什么样的场景用什么,算是回答好了.2.谈谈对Spring的理解.博主当时心里我哩个擦,又是这种宽泛的问题.但是还是微笑着回答Spring的核心是Ioc和AOP,其中Ioc是基于反射实现的,AOP是动态代理实现的,然后讲了从读取xml配置文件,实例化Spring容器,然后实例化Bean(这个过程挺复杂的,一会附上一张图),最后销毁Bean这一过程,结束.具体可以参考:Spring知识点提炼3.自己项目中的问题.自己在学校接到过一个微信公众号的开发,问了怎么实现的,遇到的问题之类的.这种问题回答要表现出自己不是很了解的情况下是如何快速解决一个问题的能力 拿到offer,博主是比较安逸的人,薪资还不错就不继续再找工作了,其实应该多投几家的,才能选择最适合自己的.]]></content>
      <categories>
        <category>经验</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
</search>
