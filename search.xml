<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[关于老项目替换dubbo的一点经验]]></title>
      <url>%2F2017%2F07%2F23%2Fdubbo%2F%E5%85%B3%E4%BA%8E%E8%80%81%E9%A1%B9%E7%9B%AE%E6%9B%BF%E6%8D%A2dubbo%E7%9A%84%E4%B8%80%E7%82%B9%E7%BB%8F%E9%AA%8C%2F</url>
      <content type="text"><![CDATA[背景公司一直以来使用内部编写的一个rpc框架,简称old_rpc这套RPC框架,由于历史原因,old_rpc存在如下缺点. old_rpc已经很久没人维护了,因此出了错误很难定位到具体的原因. old_rpc本身只是RPC框架,随着项目的增多各个项目之间的依赖关系已经很复杂了,需要一套支持服务治理的解决方案. old_rpc缺乏监控平台,对于动态部署,增加机器或者减少机器都比较麻烦. …这些缺点已经严重影响到线上稳定性,本文就dubbox替换掉old_rpc方案做的一个调研,对工作量,替换后的稳定性做一个评估,以供大家参考. 替换要求 支持平滑上线,也就是说替换后依然支持现有的测试系统,发布系统. 替换必须尽可能小的缩小对业务的影响,代码层面上来看就是业务处理代码中不应该有替换的代码 短期内需要支持dubbox与old_rpc两套方案,并且两套方案可以快速切换,防止替换后线上出现不可预料的问题. 替换思路 saturn作为服务提供者,替换比较简单,只需要在原有基础上,增加dubbo协议的Service. vienna作为消费者,使用dubbo协议引入dubbo的service vienna增加断路器配置,对于repo层引入的service,dubbox作为主service,old_rpc作为备份service,当主service调用失败则自动切换到备份service进行重试,此过程需要有监控. dubbox github: https://github.com/dangdangdotcom/dubboxclone下来后使用mvn package -DskipTests,会打包该项目,生成主要的dubbo.jar,以及管理平台dubbo-admin.war,监控平台dubbo-simple-monitor.tar.gz.我已经把相关jar,deploy到公司的nexus上了.mvn的pom中直接引入如下依赖,这里需要去除Spring依赖,dubbox是基于Spring3开发的,强制引入会与现有项目产生冲突.另外dubbox添加了kryo和FST序列化支持,以及多种新特性,使用的话均需要引入相应的jar,具体参考项目的github.1234567891011&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.8.4&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; zk注册中心dubbo的注册如下所示:实际操作下来,第三层还会有routers,configurators节点,当在dubbo-admin平台操作该service时,比如倍权,该操作会存在在这些节点中. 服务提供者saturnsaturn作为服务提供者,其任务是抛出新的dubbo服务RPC接口.在引入上述pom后,需要做少量的配置. dubbo基本配置因此demo只测试能否实现,每一个配置的详细内容并未研究,详细可以参考官方文档配置.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Configurationpublic class DubboConfig &#123; /** * 注册中心配置 */ @Bean public RegistryConfig registry() &#123; RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setAddress("115.159.185.14:2181"); registryConfig.setProtocol("zookeeper"); return registryConfig; &#125; /** * 当前应用配置 */ @Bean public ApplicationConfig application() &#123; ApplicationConfig applicationConfig = new ApplicationConfig(); applicationConfig.setName("saturn"); return applicationConfig; &#125; /** * 监控配置,监控需要dubbo-monitor */ @Bean public MonitorConfig monitorConfig() &#123; MonitorConfig mc = new MonitorConfig(); mc.setProtocol("registry"); return mc; &#125; /** * 提供者监控服务 */ @Bean public ProviderConfig provider() &#123; ProviderConfig providerConfig = new ProviderConfig(); providerConfig.setMonitor(monitorConfig()); return providerConfig; &#125; /** * 消费者监控 */ @Bean public ReferenceConfig referenceConfig() &#123; ReferenceConfig rc = new ReferenceConfig(); rc.setMonitor(monitorConfig()); return rc; &#125; /** * RPC协议配置 */ @Bean public ProtocolConfig protocol() &#123; ProtocolConfig protocolConfig = new ProtocolConfig(); protocolConfig.setPort(20880); return protocolConfig; &#125; &#125; 提供服务服务的提供利用的是ServiceBean包裹,形成该bean的代理类,可以写一个通用的配置函数123456789101112131415/** * 通用service配置类 * @param saturnService 对应服务 * @return dubbo服务 */private &lt;T&gt; ServiceBean&lt;T&gt; configService(T saturnService) &#123; ServiceBean&lt;T&gt; serviceBean = new ServiceBean&lt;&gt;(); serviceBean.setProxy("javassist"); serviceBean.setVersion("1.0"); serviceBean.setInterface(saturnService.getClass().getInterfaces()[0].getName()); serviceBean.setRef(saturnService); serviceBean.setTimeout(2000); serviceBean.setRetries(3); return serviceBean;&#125; 那么我想要抛出IUserService这个服务,只需要如下几行代码1234@Beanpublic ServiceBean&lt;IUserService&gt; userServiceExport(IUserService userService) &#123; return configService(userService);&#125; 到此提供者配置完毕. 服务消费者vienna(无断路器版本)vienna作为服务消费者与提供者一样也需要基本的dubbo配置,两者配置几乎一模一样. dubbo基本配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@Configuration@EnableAspectJAutoProxypublic class DubboConfig &#123; /** * 注册中心 */ @Bean public RegistryConfig registry() &#123; RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setAddress("115.159.185.14:2181"); registryConfig.setProtocol("zookeeper"); registryConfig.setTimeout(60000);// vienna不知道为什么链接zk很慢 return registryConfig; &#125; /** * 应用信息,计算依赖关系 */ @Bean public ApplicationConfig application() &#123; ApplicationConfig applicationConfig = new ApplicationConfig(); applicationConfig.setName("vienna"); return applicationConfig; &#125; /** * 监控中心地址 */ @Bean public MonitorConfig monitorConfig() &#123; MonitorConfig mc = new MonitorConfig(); mc.setProtocol("registry"); return mc; &#125; /** * 提供者监控服务 */ @Bean public ProviderConfig provider() &#123; ProviderConfig providerConfig = new ProviderConfig(); providerConfig.setMonitor(monitorConfig()); return providerConfig; &#125; /** * 消费者监控 */ @Bean public ReferenceConfig referenceConfig() &#123; ReferenceConfig rc = new ReferenceConfig(); rc.setMonitor(monitorConfig()); return rc; &#125; /** * 协议配置,自身无提供者的话可以不配置 */ @Bean public ProtocolConfig protocol() &#123; ProtocolConfig protocolConfig = new ProtocolConfig(); protocolConfig.setPort(20880); return protocolConfig; &#125;&#125; 配置消费者消费者是用ReferenceBean类来代理的,可以像提供者那样写一个通用的处理方法1234567891011121314/** * 基本配置类 * @param serviceReference 接口 */private &lt;T&gt; ReferenceBean&lt;T&gt; configReference(Class&lt;T&gt; serviceReference) &#123; ReferenceBean&lt;T&gt; ref = new ReferenceBean&lt;&gt;(); ref.setVersion("1.0"); ref.setInterface(serviceReference); ref.setTimeout(2000); ref.setRetries(3); ref.setCheck(false); ref.setLoadbalance("roundrobin"); return ref;&#125; 那么引用服务也就只需要几行代码即可,为了更好的与old_rpc服务区分对于dubbo引入的服务都加上dubbo前缀命名.1234@Bean(name = "dubboUserService")public ReferenceBean&lt;IUserService&gt; userService() &#123; return configReference(IUserService.class);&#125; 替换old_rpc无断路器版本替换就很简单了,找到引用该服务的地方,在Spring注入时为其选择注入dubbo服务即可.问题是一旦该服务出现了问题,那么需要手动切换回old_rpc服务.12@Resource private IUserService dubboUserService; 服务消费者vienna(断路器版本)断路器本身是做服务降级,防止系统因一个服务出问题而产生雪崩效应,对于当前系统的两套RPC方案可以利用这一点把要替换掉的old_rpc作为降级服务,当dubboService出现异常时可以立即去调取old_rpc的服务,从而保证系统的健壮性. 断路器要求 业务代码无侵入,可以使用方法级别的注解控制该方法是否走断路器.稳定后可以直接删除,不留痕迹. 支持自动熔断,自动恢复 有支持集群的监控服务,方便排查出现问题的服务. 断路器依赖对于上述要求,符合条件,又经得起生产考验的大概只有hystrix了,github地址为 https://github.com/Netflix/Hystrix,pom依赖如下,主要是核心服务包,注解包,监控包.12345678910&lt;dependency&gt; &lt;groupId&gt;com.netflix.hystrix&lt;/groupId&gt; &lt;artifactId&gt;hystrix-javanica&lt;/artifactId&gt; &lt;version&gt;1.5.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.netflix.hystrix&lt;/groupId&gt; &lt;artifactId&gt;hystrix-metrics-event-stream&lt;/artifactId&gt; &lt;version&gt;1.5.12&lt;/version&gt; &lt;/dependency&gt; 实现思路实现思路与feign对hystrix的包装很相像,以UserRepo为例,UserRepo中引入了userService服务,那么要自动切换则需要两个UserRepo,一个是引用了dubbox的dubboUserService,一个是引用了old_rpc的old_rpcUserService.断路器是方法级别的监控,使用AOP可以轻松地拦截UserRepo中每一个方法的执行,在执行时使用hystrix包装,执行失败时再使用另一个UserRepo重新执行该方法.上述流程有几个要点: 需要通过引用dubbo服务的UserRepo获取到引入old_rpc的UserRepo 需要获取到UserRepo中全部的public方法,方便二次调用. 可以从UserRepo中得到断路器的配置,比如分组,线程池等信息. 增强Repo功能上述的几个要点需要在UserRepo中附加的功能使用一个接口来抽象.12345678910111213141516171819public interface IDubboRepoProxy extends InitializingBean,ApplicationContextAware &#123; /** * 获取使用dubbo服务调用的Repo */ IDubboRepoProxy getDubboRepo(); /** * 获取当前类所有的public方法 * @return 键与值都是该方法 */ Map&lt;Method, Method&gt; getAllPublicMethods(); /** * 得到断路器的配置 */ HystrixCommand.Setter getHystrixSetter();&#125; 为了让实现类更少的写代码,再为其定义一个抽象类,该抽象类主要负责接口功能的实现,其中initOtherRepo作为抽象方法,需要子类来实现,也就是初始化备份的Repo.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public abstract class DubboRepoProxyImpl&lt;T extends IDubboRepoProxy&gt; implements IDubboRepoProxy&#123; @Getter private ApplicationContext context; @Setter private T otherRepo; private Map&lt;Method, Method&gt; publicMethodMap = Maps.newHashMap(); private HystrixCommand.Setter setter; @Override public IDubboRepoProxy getDubboRepo() &#123; return otherRepo; &#125; @Override public Map&lt;Method, Method&gt; getAllPublicMethods() &#123; return publicMethodMap; &#125; @Override public HystrixCommand.Setter getHystrixSetter() &#123; return setter; &#125; @Override public void afterPropertiesSet() throws Exception &#123; //init repo initOtherRepo(); //init method Class&lt;? extends IDubboRepoProxy&gt; old_rpcClass = this.otherRepo.getClass(); for (Method method : old_rpcClass.getDeclaredMethods()) &#123; publicMethodMap.put(method, method); &#125; //init setter setter = HystrixCommand.Setter .withGroupKey(HystrixCommandGroupKey.Factory.asKey(this.getClass().getName())) .andCommandKey(HystrixCommandKey.Factory.asKey(this.getClass().getSimpleName())); &#125; public abstract void initOtherRepo(); @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.context = applicationContext; &#125;&#125; 使用AOP动态切换上述接口与抽象类会赋予UserRepo我们想要的功能.接下来就是AOP拦截.因为断路器是方法级别的操作,因此该AOP只拦截方法,为了更好的配置增加一个AOP专用注解1234//该注解修饰的方法会被AOP拦截@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface AutoDubboAspect &#123;&#125; 然后写具体的拦截器.该拦截器责任就是按部就班的执行之前的思路.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Component@Aspectpublic class AutoDubboAspectImpl &#123; private static Logger logger = LoggerFactory.getLogger(AutoDubboAspectImpl.class); @Pointcut("@annotation(com.duitang.context.dubbo.AutoDubboAspect)") public void autoDubboAspect() &#123; &#125; //环绕通知 @Around("autoDubboAspect()") public Object autoCheck(ProceedingJoinPoint pjp) throws Throwable &#123; //要执行的主repo IDubboRepoProxy target = (IDubboRepoProxy) pjp.getTarget(); //备用repo IDubboRepoProxy otherRepo = target.getDubboRepo(); //该repo中所有方法 Map&lt;Method, Method&gt; methods = target.getAllPublicMethods(); //断路器执行 HystrixCommand&lt;Object&gt; hystrixCommand = new HystrixCommand&lt;Object&gt;( target.getHystrixSetter()) &#123; @Override protected Object run() throws Exception &#123; try &#123; return pjp.proceed(); &#125; catch (Throwable throwable) &#123; //异常直接抛出 throw new RuntimeException(throwable); &#125; &#125; /** * 备用降级方案 */ @Override protected Object getFallback() &#123; logger.error("start getFallback,this exception is &#123;&#125;", this.getFailedExecutionException()); logger.error("start getFallback", pjp.getSignature().toLongString()); MethodSignature signature = (MethodSignature) pjp.getSignature(); //获取执行方法 Method method = methods.get(signature.getMethod()); if (method == null) &#123; return null; &#125; try &#123; //使用备用repo执行该方法 return method.invoke(otherRepo, pjp.getArgs()); &#125; catch (IllegalAccessException | InvocationTargetException e) &#123; logger.error("getFallback error,&#123;&#125;",e); &#125; return null; &#125; &#125;; return hystrixCommand.execute(); &#125;&#125; 到此准备工作算是结束,下面是真正的替换. 开始替换old_rpc服务因为准备的充分,那么替换就变得相当简单了.首先为UserRepo增强功能,也就是继承抽象类DubboRepoProxyImpl1public class UserRepo extends DubboRepoProxyImpl&lt;UserRepo&gt; 然后实现initOtherRepo方法,该方法主要是从Spring容器中获取到old_rpc的服务,然后再初始化一个UserRepo.12345678910111213141516@Override public void initOtherRepo() &#123; if (null != getContext()) &#123; IUserService userService = getContext().getBean("userService", IUserService.class); IRelationshipService relationshipService = getContext().getBean("relationshipService", IRelationshipService.class); IUserInterestsService userInterestsService = getContext().getBean("userInterestsService", IUserInterestsService.class); IFriendRecomendService friendRecomendService = getContext().getBean("friendRecomendService", IFriendRecomendService.class); //备用old_rpc服务 UserRepo userRepo = new UserRepo(userService, this.appealAccountService, this.datasourceService, relationshipService, this.lifeArtistService, userInterestsService, this.jedisPersist, friendRecomendService); this.setOtherRepo(userRepo); &#125; &#125; 最后为想要实现短路功能的方法加上注解.1234@AutoDubboAspectpublic BaseUser findBasicInfo(long userId) &#123; ...&#125; 注意事项消费者无法从zk中获取提供者信息?这种情况大多数都是因为配置时两方信息不一致导致,可以去dubbo-admin平台检查提供者完整的url,再与日志中消费者引用的url做个比较,定位到问题. zk连接超时zk是我在自己服务器上部署的,在vienna项目中配置了外网地址,在prism环境中启动后总是出现zk连接超时,后来测试要连上zk大概需要20秒左右,索性把超时时间配置为60秒,解决,具体原因未知. saturn中配置zk注册服务后测试案例无法跑通这个问题是我在saturn配置了测试环境的zk,1234567@Beanpublic RegistryConfig registry() &#123; RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setAddress("10.1.4.10:2181"); registryConfig.setProtocol("zookeeper"); return registryConfig;&#125; 但是jenkins打包时,测试案例一直失败,大概要打包10多分钟,问题有点莫名其妙,在测试时避免Spring引入该bean即可解决. 总结整体过程是比较顺利的,下篇再记录dubbo-admin与dubbo-monitor,以及hystrix-dashborad的搭建.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Security学习记录(四) -- JSON Web Token实践(下)]]></title>
      <url>%2F2017%2F06%2F30%2Fspring%2FSpring%20Security%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E5%9B%9B)%20--%20JSON%20Web%20Token%E5%AE%9E%E8%B7%B5(%E4%B8%8B)%2F</url>
      <content type="text"><![CDATA[前提接着上篇的内容,了解了JWT Token后,发现这东西就是一个可信的用户信息存储方式,那么可信的话就可以省去验证这个步骤,只有当需要用户的详细信息时候才会去DB中查询用户的详细信息.那么现在的流程就是用户请求 -&gt; Spring Security通过token把tokenUser设置到上下文中 -&gt; Spring Security Token以及权限验证 -&gt; 具体的业务接口 -&gt; 需要详细信息则根据用户id去DB中获取那么就会有以下几个问题. token在什么时候生成?这个在登录接口中生成,登录后token放入用户id,用户权限等基础信息,以供验证使用. token签名的密钥该使用什么?这个我也不太清楚,写死一个密钥感觉很不安全,我的想法是使用用户的密码的密文作为签名密钥,这样当用户更改密码的时候原token都是失效.这样做有个缺点,用户密码的密文每次获取需要查询DB,势必会造成DB的压力,可以考虑加缓存,但要考虑缓存挂掉的情况下对DB的压力. token该怎么较少被盗后的损失?token既然被系统认为是可信的信息集合,那么就需要有相应的超时机制,超时机制是为了防止token被盗用后的损失也只能在一段时间内,就和session超时机制是一样的用处. 如何解决SSO?SSO需要借助cookie或者localStorge,把token放在顶级域名中,这样的话子系统都能使用到,也就完成的SSO机制.对于多域名,那要解决的问题就是如何跨域设置cookie了 如何解决CSRF?CSRF产生的原因是对方使用了你的Cookie也就是使用了你的认证信息,那么的话获取token这一步就不能依赖token,所以把cookie存在cookie中,然后请求时放入header中,解析时从header中获取token信息. 实践JWT签名与验签首先POM引入依赖包12345&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.7.0&lt;/version&gt;&lt;/dependency&gt; 接着定义一个简单的用户,用作存储在上下文中12345678public class TokenUserDTO &#123; private Long id; private String username; private String email; private String avatar; private List&lt;String&gt; roles; //省略get set&#125; 接着实现jwt123456789101112131415161718192021222324252627282930313233/** * 从用户中创建一个jwt Token * @param userDTO 用户 * @return token */ public String create(TokenUserDTO userDTO) &#123; return Jwts.builder() .setExpiration(new Date(System.currentTimeMillis() + VALIDITY_TIME_MS)) .setSubject(userDTO.getUsername()) .claim("id", userDTO.getId()) .claim("avatar", userDTO.getAvatar()) .claim("email", userDTO.getEmail()) .claim("roles", userDTO.getRoles()) .signWith(SignatureAlgorithm.HS256, secret) .compact(); &#125; /** * 从token中取出用户 */ public TokenUserDTO parse(String token) &#123; Claims claims = Jwts.parser() .setSigningKey(secret) .parseClaimsJws(token) .getBody(); TokenUserDTO userDTO = new TokenUserDTO(); userDTO.setId(NumberUtils.toLong(claims.getId())); userDTO.setAvatar(claims.get("avatar",String.class)); userDTO.setUsername(claims.get("username",String.class)); userDTO.setEmail(claims.get("email",String.class)); userDTO.setRoles((List&lt;String&gt;) claims.get("roles")); return userDTO; &#125; Spring Security过滤上述流程中Spring Security所承担的角色是验证token+保存token解析出来的用户到SecurityContextHolder中,弄清楚角色那么实现就很简单了.看之前的过滤器链,蓝色框内包含跨站攻击检测与用户信息获取校验,因为用的是jwt所以这些都可以省略掉,替换为解析并验证token,然后设置解析后的用户到上下文中. 首先SecurityContextHolder中存储的是Authentication对象,所以需要在TokenUser基础封装一层认证用户.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * Spring Security中存放的认证用户 * @author Niu Li * @since 2017/6/28 */public class TokenUserAuthentication implements Authentication &#123; private static final long serialVersionUID = 3730332217518791533L; private TokenUserDTO userDTO; private Boolean authentication = false; public TokenUserAuthentication(TokenUserDTO userDTO, Boolean authentication) &#123; this.userDTO = userDTO; this.authentication = authentication; &#125; //这里的权限是FilterSecurityInterceptor做权限验证使用 @Override public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() &#123; return userDTO.getRoles().stream() .map(SimpleGrantedAuthority::new).collect(Collectors.toList()); &#125; @Override public Object getCredentials() &#123; return ""; &#125; @Override public Object getDetails() &#123; return userDTO; &#125; @Override public Object getPrincipal() &#123; return userDTO.getUsername(); &#125; @Override public boolean isAuthenticated() &#123; return authentication; &#125; @Override public void setAuthenticated(boolean isAuthenticated) throws IllegalArgumentException &#123; this.authentication = isAuthenticated; &#125; @Override public String getName() &#123; return userDTO.getUsername(); &#125;&#125; 然后实现验签方法,验签是从header中取出相应的token,验签成功后返回一个Authentication的对象.12345678910111213/** * 验签 */public Optional&lt;Authentication&gt; verifyToken(HttpServletRequest request) &#123; final String token = request.getHeader(AUTH_HEADER_NAME); if (token != null &amp;&amp; !token.isEmpty())&#123; final TokenUserDTO user = parse(token.trim()); if (user != null) &#123; return Optional.of(new TokenUserAuthentication(user, true)); &#125; &#125; return Optional.empty();&#125; 最后实现验证Token的过滤器123456789101112131415161718192021222324252627/** * jwt token验证类,验证成功后设置进去SecurityContext中 * @author Niu Li * @since 2017/6/28 */@Slf4jpublic class VerifyTokenFilter extends OncePerRequestFilter &#123; private JwtTokenUtil jwtTokenUtil; public VerifyTokenFilter(JwtTokenUtil jwtTokenUtil) &#123; this.jwtTokenUtil = jwtTokenUtil; &#125; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; try &#123; Optional&lt;Authentication&gt; authentication = jwtTokenUtil.verifyToken(request); log.debug("VerifyTokenFilter result: &#123;&#125;",authentication.orElse(null)); SecurityContextHolder.getContext().setAuthentication(authentication.orElse(null)); filterChain.doFilter(request,response); &#125; catch (JwtException e) &#123; response.setStatus(HttpServletResponse.SC_UNAUTHORIZED); //可以在这里指定重定向还是返回错误接口示例 &#125; &#125;&#125; 配置下Spring Security,主要就是关闭一些不用的过滤器,实现自己的验证过滤器.123456789101112131415161718192021222324252627282930313233343536373839@Configuration@EnableWebSecuritypublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Resource private JwtTokenUtil jwtTokenUtil; /** * 在此配置不过滤的请求 */ @Override public void configure(WebSecurity web) throws Exception &#123; //每一个请求对应一个空的filter链,这里一般不要配置过多, // 因为查找处是一个for循环,过多就导致每个请求都需要循环一遍直到找到 web.ignoring().antMatchers("/","/login","/favicon.ico"); &#125; /** * 在此配置过滤链 */ @Override protected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() //角色定义,Spring Security会在其前面自动加上ROLE_,因此存储权限的时候也要加上ROLE_ADMIN .antMatchers("/detail").access("hasRole('ADMIN')") .anyRequest().permitAll().and() //异常处理,可以再此使用entrypoint来定义错误输出 .exceptionHandling().and() //不需要session来控制,所以这里可以去掉 .securityContext().securityContextRepository(new NullSecurityContextRepository()).and() //开启匿名访问 .anonymous().and() //退出登录自己来控制 .logout().disable() //因为没用到cookies,所以关闭cookies .csrf().disable() //验证token .addFilterBefore(new VerifyTokenFilter(jwtTokenUtil), UsernamePasswordAuthenticationFilter.class); &#125;&#125; 这样做的话,验证就需要在相应的代码中,或者对指定链接使用Spring Security的权限验证.1234567891011/** * 该链接尝试获取登录用户,返回该认证用户的信息,请求该链接需要在header中放入x-authorization: token */@GetMapping("/detail")public TokenUserDTO userDetail() &#123; Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); if (Objects.isNull(authentication)) &#123; return null; &#125; return (TokenUserDTO) authentication.getDetails();&#125; 或者123....antMatchers("/detail").access("hasRole('ADMIN')")... 这样的话就实现了jwt验证,SSO问题也就是token传输的问题,使用cookie就可以了,客户端去请求时从cookie中加载token,然后放入到header中,对这里的代码没影响. github地址: https://github.com/nl101531/JavaWEB]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Security学习记录(三) -- JSON Web Token实践(上)]]></title>
      <url>%2F2017%2F06%2F26%2Fspring%2FSpring%20Security%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%B8%89)%20--%20JSON%20Web%20Token%E5%AE%9E%E8%B7%B5(%E4%B8%8A)%2F</url>
      <content type="text"><![CDATA[JWT实际上与Spring Security没多大关系,本文打算使用Spring Security配合JWT这种方式完成用户的认证和授权. JSON Web Token(JWT),是一个开放安全的行业标准,用于多个系统之间传递安全可靠的信息.关于其解释可以参考博文:JSON Web Token - 在Web应用间安全地传递信息因为原作者写的很详细,这里就只说下个人认为比较重要的问题. JWT是什么样子的结构?JSON Web Token说到底也是一串token,其形式分三段,看下图,红色的为Header,指定token类型与签名类型,紫色的为请求体,存储用户id等关键信息,最后蓝色的为签名,保证整个信息的完整性,可靠性.其中playload中可以 iss: 该JWT的签发者 sub: 该JWT所面向的用户 aud: 接收该JWT的一方 exp(expires): 什么时候过期，这里是一个Unix时间戳 iat(issued at): 在什么时候签发的 nbf: 定义在什么时间之前，该jwt都是不可用的. jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。 JWT是一个怎样的流程? 客户端使用账户密码请求登录接口 登录成功后返回JWT 客户端再次请求其他接口时带上JWT 服务端接收到JWT后验证签名的有效性. JWT解决了什么问题?token被劫持一开始理解很容易陷入一个误区,比如有人会问对于JWT来说,jwt被劫持了的话,那么对方就可以伪造请求,这东西怎么能保证安全呢?这里问题是没理解好JWT,JWT解决的是认证与授权的问题,上述劫持或者类似的中间人攻击是JWT不可避免的,也是其他认证与授权方式不可避免的,想避免可以使用HTTPS,或者签发jwt的时候记录下Client的ip地址,这些就和JWT没关系了. 与Session的区别session实际上是基于cookie来传输的,最重要的session信息是存储在服务器的,所以服务器每次可以通过cookie中的sessionId获取到当前会话的用户,对于单台服务器这样做没问题,但是对于多台就涉及到共享session的问题了,而且认证用户的增多,session会占用大量的服务器内存.那么jwt是存储在客户端的,服务器不需要存储jwt,jwt里面有用户id,服务器拿到jwt验证后可以获得用户信息.也就实现了session的功能,但是相比session,jwt是无状态的,其不与任何机器绑定,只要签名秘钥足够的安全就能保证jwt的可靠性. JWT下服务端认为什么样子的请求是可信的?对于服务端来说,无法确定下一个请求是哪一个用户,哪一个终端发出,所以其需要一些信息定位到该用户或者该机器,对于JWT来说其Playload里面存储着UserId,那么服务端接收到Token后对其进行签名验证,验证成功,则认为其是可信的,然后通过UserId从DB或者Cache中查询出来用户信息. 为什么JWT能保证信息传输的安全可靠?比如现在有token123eyJhbGciOiJIUzI1NiJ9.eyJleHAiOjE0OTg0ODIxNTQsInN1YiI6InF1ZGluZyIsInVzZXJJZCI6IjEwMzc5NDAxIiwicm9sZSI6ImFkbWluIn0.-YFTYJ6FLlIQqD4G3hYcWvYlYE8H9eAA2369WEcJFVY 12345678910111213Header&#123; "alg": "HS256"&#125;Playload&#123; "exp": 1498482154, "sub": "quding", "userId": "10379401", "role": "admin"&#125;SignYFTYJ6FLlIQqD4G3hYcWvYlYE8H9eAA2369WEcJFVY 假设我的playload被其他人劫持了,其他人把userId修改为他自己的,比如123456,但是其没有签名的秘钥,所以他就没法生成签名.服务端收到该Token后,会用先Base64解码出来相应的信息,然后重新生成sign,使用该sign与客户端传来的Sign进行对比,一样则证明没被修改,也就是可信的请求,否则拒绝该请求. 下一篇开始实战.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Security学习记录(二) -- Spring Security的Filter]]></title>
      <url>%2F2017%2F06%2F22%2Fspring%2FSpring%20Security%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%BA%8C)%20--%20Spring%20Security%E7%9A%84Filter%2F</url>
      <content type="text"><![CDATA[上一篇学习了Spring Security是如何拦截请求,并把请求转向到Filter链的,该篇就主要学习下这些Filter链的节点的作用. 下面是之前配置的内容,本文也是对这些内容 的执行分析.123456789101112131415&lt;security:http &gt; &lt;security:intercept-url pattern="/**" access="hasRole('ROLE_USER')"/&gt; &lt;security:form-login/&gt; &lt;security:http-basic/&gt; &lt;security:logout/&gt; &lt;/security:http&gt; &lt;security:authentication-manager&gt; &lt;security:authentication-provider&gt; &lt;security:user-service&gt; &lt;security:user name="user" password="123456" authorities="ROLE_USER"/&gt; &lt;security:user name="admin" password="123456" authorities="ROLE_USER, ROLE_ADMIN"/&gt; &lt;/security:user-service&gt; &lt;/security:authentication-provider&gt; &lt;/security:authentication-manager&gt; 1.Filter链的由来由上文可知每一个security:http标签实际上对应的是一个SecurityFilterChain的类,也就是一条Filter链,可以通过其http属性指明其作用的URL,否则作用域全部的URL,如下配置,该security:http会产生一个对/login下的所有请求Filter链.123&lt;security:http pattern="/login/**"&gt; ******&lt;/security:http&gt; 打个断点可以很清楚的看到该Filter链 2.SecurityContextPersistenceFilter该类在所有的Filter之前,是从SecurityContextRepository中取出用户认证信息,默认实现类为HttpSessionSecurityContextRepository,其会从Session中取出已认证用户的信息,提高效率,避免每一次请求都要查询用户认证信息.取出之后会放入SecurityContextHolder中,以便其他filter使用,该类使用ThreadLocal存储用户认证信息,保证了线程之间的信息隔离,最后再finally中清除该信息.可以配置http的security-context-repository-ref属性来自己控制获取到已认证用户信息的方式,比如使用redis存储session等. 3.WebAsyncManagerIntegrationFilter提供了对securityContext和WebAsyncManager的集成,其会把SecurityContext设置到异步线程中,使其也能获取到用户上下文认证信息. 4.HeaderWriterFilter其会往该请求的Header中添加相应的信息,在http标签内部使用security:headers来控制. 5.CsrfFilterCsrf,跨站请求伪造,了解不是很深,只知道B网站使用A网站的可信Cookie发起请求,从而完成认证,伪造出正当请求.验证方式是通过客户端传来的token与服务端存储的token进行对比,来判断是否为伪造请求,有兴趣的可以查看源代码研究下. 6.LogoutFilter匹配URL,默认为/logout,匹配成功后则用户退出,清除认证信息. 7.UsernamePasswordAuthenticationFilter登录认证过滤器,默认是对/login的POST请求进行认证,首先该方法会先调用attemptAuthentication尝试认证获取一个Authentication的认证对象,然后通过sessionStrategy.onAuthentication执行持久化,也就是保存认证信息,转向下一个Filter,最后调用successfulAuthentication执行认证后事件. attemptAuthentication该方法是认证的主要方法,认证是委托配置的authentication-manager-&gt;authentication-provider进行.比如对于该Demo配置的为如下,则默认使用的manager为ProviderManager,使用的provider为DaoAuthenticationProvider,userDetailService为InMemoryUserDetailsManager也就是从内存中获取用户认证信息,也就是下面xml配置的user与admin信息.12345678&lt;security:authentication-manager&gt; &lt;security:authentication-provider&gt; &lt;security:user-service&gt; &lt;security:user name="user" password="123456" authorities="ROLE_USER"/&gt; &lt;security:user name="admin" password="123456" authorities="ROLE_USER, ROLE_ADMIN"/&gt; &lt;/security:user-service&gt; &lt;/security:authentication-provider&gt;&lt;/security:authentication-manager&gt; 认证基本流程为UserDeatilService根据用户名获取到认证用户的信息,然后通过UserDetailsChecker.check对用户进行状态校验,最后通过additionalAuthenticationChecks方法对用户进行密码校验成功后完成认证.返回一个认证对象. 都是面向接口编程,所以用户可以很轻松的扩展自己的验证方式. 8.DefaultLoginPageGeneratingFilter当请求为登录请求时,生成简单的登录页面返回 9.BasicAuthenticationFilterHttp Basci认证的支持,该认证会把用户名密码使用base64编码后放入header中传输,如下所示,认证成功后会把用户信息放入SecurityContextHolder中.1* Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== 10.RequestCacheAwareFilter恢复被打断的请求,具体未研究 11.SecurityContextHolderAwareRequestFilter针对Servlet api不同版本做的一些包装 12.AnonymousAuthenticationFilter当SecurityContextHolder中认证信息为空,则会创建一个匿名用户存入到SecurityContextHolder中 13.SessionManagementFilter与登录认证拦截时作用一样,持久化用户登录信息,可以保存到session中,也可以保存到cookie或者redis中. 14.ExceptionTranslationFilter异常拦截,其处在Filter链后部分,只能拦截其后面的节点并且着重处理AuthenticationException与AccessDeniedException两个异常. 15.FilterSecurityInterceptor主要是授权验证,方法为beforeInvocation,在其中调用12Collection&lt;ConfigAttribute&gt; attributes = this.obtainSecurityMetadataSource() .getAttributes(object); 获取到所配置资源访问的授权信息,对于上述配置,获取到的则为hasRole(&#39;ROLE_USER&#39;),然后根据SecurityContextHolder中存储的用户信息来决定其是否有权限,没权限则返回403,具体想了解可以关注HttpConfigurationBuilder.createFilterSecurityInterceptor()方法,分析其创建流程加载了哪些数据,或者分析SecurityExpressionOperations的子类,其是权限鉴定的实现方法. 总结整个认证授权流程如下图所示,图是网上盗的 因为是学习方面,使用的不是很多,如有错误请指出,以防误人子弟.简单来说,作为用户需要关心的地方是 登录验证UsernamePasswordAuthenticationFilter 访问验证BasicAuthenticationFilter 权限验证FilterSecurityInterceptor下一篇则讲述利用这三个验证实现JWT验证. 关于这些过滤器更详细的内容可参考博客: http://www.iteye.com/blogs/subjects/spring_security]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Security学习记录(一) -- 初识Spring Security]]></title>
      <url>%2F2017%2F06%2F19%2Fspring%2FSpring%20Security%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%B8%80)%20--%20Spring%20Security%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%B8%80)%20--%20%E5%88%9D%E8%AF%86Spring%20Security%2F</url>
      <content type="text"><![CDATA[Spring Security是什么?Spring Security是一套认证授权框架,支持认证模式如HTTP BASIC 认证头 (基于 IETF RFC-based 标准),HTTP Digest 认证头 ( IETF RFC-based 标准),Form-based authentication (用于简单的用户界面),OpenID 认证等,Spring Security使得当前系统可以快速集成这些验证机制亦或是实现自己的一套验证机制. 使用Spring SecuritySpring Security3之后提供了Java Config的配置方式,但是我觉得xml方式比较容易理解其整体结构,所以本文都是基于xml配置的,在github上该项目会提供Java Config方式作为对比. pom依赖12345678910111213141516&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.4.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 由于使用了Spring Boot,所以需要使用@EnableWebSecurity注解启用Spring Security,并指明其配置文件为classpath下的spring-security.xml12345@Configuration@EnableWebSecurity@ImportResource(locations = "classpath:spring-security.xml")public class SecurityConfig &#123;&#125; xml配置在spring-security.xml中引入官方提供的命名空间,然后简单配置下,该配置大概意思是对所有请求的url拦截,必须有User权限的用户才能访问.12345678910111213141516171819202122232425&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:security="http://www.springframework.org/schema/security" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/security http://www.springframework.org/schema/security/spring-security.xsd"&gt; &lt;security:http &gt; &lt;security:intercept-url pattern="/**" access="hasRole('ROLE_USER')"/&gt; &lt;security:form-login/&gt; &lt;security:http-basic/&gt; &lt;security:logout/&gt; &lt;/security:http&gt; &lt;security:authentication-manager&gt; &lt;security:authentication-provider&gt; &lt;security:user-service&gt; &lt;security:user name="user" password="123456" authorities="ROLE_USER"/&gt; &lt;security:user name="admin" password="123456" authorities="ROLE_USER, ROLE_ADMIN"/&gt; &lt;/security:user-service&gt; &lt;/security:authentication-provider&gt; &lt;/security:authentication-manager&gt;&lt;/beans&gt; 访问测试该页面为Spring Security自动生成的登录页面,当我们访问任何连接都会被重定向到该登录页面,输入user:123456登录后才能有权限访问. 分析上述是一个简单的Demo,分析则是从这个Demo深入浅出.1.Spring Security是如何拦截请求的?传统的xml配置都会在web.xml里面配置如下过滤器.12345678&lt;filter&gt; &lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 可以看出入口点就是该类,该类会从Spring容器中读取名称为springSecurityFilterChain的一个Filter实例,从而获取到对应代理的Filter.1234567protected Filter initDelegate(WebApplicationContext wac) throws ServletException &#123; Filter delegate = wac.getBean(getTargetBeanName(), Filter.class); if (isTargetFilterLifecycle()) &#123; delegate.init(getFilterConfig()); &#125; return delegate;&#125; 然后在doFilter方法中调用该委托的filter,也就实现的拦截请求.123456protected void invokeDelegate( Filter delegate, ServletRequest request, ServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; delegate.doFilter(request, response, filterChain);&#125; 2. Spring Security拦截请求后是如何处理的?打断点可以发现DelegatingFilterProxy实际上代理的是FilterChainProxy这个类,该类中有private List&lt;SecurityFilterChain&gt; filterChains;全局变量,那么SecurityFilterChain为何物?123456public interface SecurityFilterChain &#123; boolean matches(HttpServletRequest request); List&lt;Filter&gt; getFilters();&#125; 从源码可以判断SecurityFilterChain是一套规则所对应的Filter链集合.再看源码getFilters,该方法会根据规则(也就是配置中的security:http标签)获取一个SecurityFilterChain中的一套对应规则的filter链.12345678private List&lt;Filter&gt; getFilters(HttpServletRequest request) &#123; for (SecurityFilterChain chain : filterChains) &#123; if (chain.matches(request)) &#123; return chain.getFilters(); &#125; &#125; return null;&#125; 最后在doFilterInternal方法中创建一个VirtualFilterChain类,调用其doFilter方法.VirtualFilterChain这个类很有意思,该类继承了FilterChain类,那么其就拥有了转交请求到指定filter的能力,另外其还拥有一套filter链List&lt;Filter&gt; additionalFilters;,那么这个类就控制了整个Spring Security的执行流程,那么它是怎么实现的呢?开始我以为是一个循环,然而看了源码才发现自己太low了.123 currentPosition++;Filter nextFilter = additionalFilters.get(currentPosition - 1);nextFilter.doFilter(request, response, this); currentPosition与additionalFilters都是全局变量,其在调用filter链的时候每次都把自己本身在doFilter传值过去,每一个Filter链节点执行完毕后再返回VirtualFilterChain的doFilter方法,开启下一个节点执行.其结构如下面代码所示:1234567891011121314151617181920212223242526272829303132333435363738interface IA&#123; void doSomeThing(IAChain chain); &#125; static class IAClass implements IA&#123; @Override public void doSomeThing(IAChain chain) &#123; System.out.println("i am IAClass"); chain.doSomeThing(); &#125; &#125; interface IAChain&#123; void doSomeThing(); &#125; static class IAChainClass implements IAChain&#123; List&lt;IA&gt; IAChains = new ArrayList&lt;IA&gt;(); public IAChainClass() &#123; IAChains.add(new IAClass()); IAChains.add(new IAClass()); IAChains.add(new IAClass()); &#125; int position = 0; @Override public void doSomeThing() &#123; if (position == IAChains.size()) &#123; System.out.println("end"); return; &#125; IA ia = IAChains.get(position++); ia.doSomeThing(this); &#125; &#125; 当调用iaChainClass.doSomeThing()输出1234i am IAClassi am IAClassi am IAClassend 调用链的实现还可以使用继承来实现,每次执行前先执行super()方法. ok,下一章分析具体的Filter链中的节点,探究下Spring Security是如何进行用户认证与权限控制的.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Cloud学习记录(二)--服务治理]]></title>
      <url>%2F2017%2F06%2F04%2Fspring%2FSpring%20Cloud%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%BA%8C)--%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86%2F</url>
      <content type="text"><![CDATA[看到了网易乐得团队的一篇服务治理文章,很全面,直接贴地址了 Spring Cloud技术分析（1）——服务治理Spring Cloud技术分析（2）—— 服务治理实践 下面会更新一些实战中遇到的问题 关于配置配置主要是查看官方文档,其次再看代码,而代码大多都是AUTOCONFIG等类似的配置类,其本质大多都是注入为Spring Bean,比如我想配置feign所使用的的Httpclient,那么我会发现FeignRibbonClientAutoConfiguration这个类,在其中有如下的代码12345678910111213141516171819202122@Configuration@ConditionalOnClass(ApacheHttpClient.class)@ConditionalOnProperty(value = "feign.httpclient.enabled", matchIfMissing = true)protected static class HttpClientFeignLoadBalancedConfiguration &#123; @Autowired(required = false) private HttpClient httpClient; @Bean @ConditionalOnMissingBean(Client.class) public Client feignClient(CachingSpringLoadBalancerFactory cachingFactory, SpringClientFactory clientFactory) &#123; ApacheHttpClient delegate; if (this.httpClient != null) &#123; delegate = new ApacheHttpClient(this.httpClient); &#125; else &#123; delegate = new ApacheHttpClient(); &#125; return new LoadBalancerFeignClient(delegate, cachingFactory, clientFactory); &#125;&#125; 那么就可以得知首先我需要引入ApacheHttpClient所在的架包,其次配置文件配置feign.httpclient.enabled=true,另外我还可以对httpClient自定义,然后注入到Spring中,那么就会默认使用我注入的这个HTTPClient了,然后打个断点,debug看下是否自动配置成功. Feign与RibbonFeign中默认开启的负载均衡,至于算法则使用的是Ribbon轮询算法,在LoadBalancerFeignClient中有CachingSpringLoadBalancerFactory则会缓存每一个server-name对应的负载均衡算法实例,这些实例都来自于SpringClientFactory中,根据server-name从中获取,那么意味着要更改对应服务的负载均衡算法只需要在Spring中注入服务名对应的负载均衡实例即可.最好的方式是在配置文件中声明,如下方式指定负载均衡使用随机规则123server-name: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRule Demo地址:Spring Cloud Demo : https://github.com/nl101531/JavaWEB]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Cloud学习记录(一)--为什么需要Spring Cloud?]]></title>
      <url>%2F2017%2F06%2F03%2Fspring%2FSpring%20Cloud%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%B8%80)--%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%BE%AE%E6%9C%8D%E5%8A%A1%2F</url>
      <content type="text"><![CDATA[最近看了周立大大关于Spring Cloud的分享itmuch.com,自己做了一些总结,加深自己的理解. 理解有误,占坑]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[WEB小知识-HTTP请求对+和&的处理]]></title>
      <url>%2F2017%2F05%2F22%2Fweb%2FWEB%E5%B0%8F%E7%9F%A5%E8%AF%86-HTTP%E8%AF%B7%E6%B1%82%E5%AF%B9%2B%E5%92%8C%26%E7%9A%84%E5%A4%84%E7%90%86%2F</url>
      <content type="text"><![CDATA[1.问题在HTTP请求中如果传的参数有一些特殊字符则会被编码成空格,导致服务端获取不到响应的信息. 对于+号会被编码为空格对于&amp;也会被编码成空格 举个例子,需要向服务端提交如下代码:123456789#include &lt;iostream&gt;using namespace std;int main()&#123; int a,b; cin &gt;&gt; a &gt;&gt; b; cout &lt;&lt; a+b &lt;&lt; endl; return 0;&#125; 编码后的内容如下,可以发现a+b被转换成了a b导致服务端接收到后编译失败.12345#include%20%3Ciostream%3E%0A%0Ausing%20namespace%20std;%0A%0Aint%20main()%0A%7B%0A%20%20%20%20int%20a,b;%0A%20%20%20%20cin%20%3E%3E%20a%20%3E%3E%20b;%0A%20%20%20%20cout%20%3C%3C%20a b%20%3C%3C%20endl;%0A%20%20%20%20return%200;%0A%7D 2.解决方案使用函数encodeURIComponent(),该函数会把特殊字符都给转义,转义结果如下面所示,可见a+b转换成了a%2Bb12345%23include%20%3Ciostream%3E%0A%0Ausing%20namespace%20std%3B%0A%0Aint%20main()%0A%7B%0A%20%20%20%20int%20a%2Cb%3B%0A%20%20%20%20cin%20%3E%3E%20a%20%3E%3E%20b%3B%0A%20%20%20%20cout%20%3C%3C%20a%2Bb%20%3C%3C%20endl%3B%0A%20%20%20%20return%200%3B%0A%7D 服务端需要使用URLDecoder对其进行反转义,该问题到此解决.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java8学习记录(二)-Stream原理]]></title>
      <url>%2F2017%2F05%2F20%2Fjava%2FJava8%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%BA%8C)-Stream%E5%8E%9F%E7%90%86%2F</url>
      <content type="text"><![CDATA[推荐一篇博文,很好的介绍了Stream的原理.本文对其进行一些补充更加详细的讲解. 作者: 李豪地址: https://github.com/CarpenterLee/JavaLambdaInternals/blob/master/6-Stream%20Pipelines.md 需求: 从&quot;张三&quot;,&quot;李四&quot;,&quot;王二&quot;,&quot;张四五&quot;中选出以张开头的名字,然后从再从中选出名字最长的一个,输出其长度. 1.一种直白的实现 缺点: 迭代次数过多 频繁产生中间结果,性能无法接受 实际想要的效果:平常的写法:12345678int longest = 0;for(String str : strings)&#123; if(str.startsWith("张"))&#123;// 1. filter(), 保留以张开头的字符串 int len = str.length();// 2. mapToInt(), 转换成长度 longest = Math.max(len, longest);// 3. max(), 保留最长的长度 &#125;&#125;System.out.println(longest); Stream的做法:12345Stream.of("张三","李四","王二","张四五") .filter(x -&gt; x.startsWith("张")) .mapToInt(String::length) .max() .ifPresent(System.out::println); 2.Stream是怎么做到的?Stream的操作分类: 中间操作:返回一个新的Stream - 有状态 sorted(),必须等上一步操作完拿到全部元素后才可操作 - 无状态 filter(),该操作的元素不受上一步操作的影响 12list.stream().filter(x -&gt; x.startWith("张").map(x -&gt; x.length())list.stream().filter(x -&gt; x.startWith("张").sorted().map(x -&gt; x.length()) 终端操作:返回结果 - 短路操作findFirst(),找到一个则返回,也就是break当前的循环 - 非短路操作forEach(),遍历全部元素 以上操作决定了Stream一定是先构建完毕再执行的特点,也就是延迟执行,当需要结果(终端操作时)开始执行流水线.Stream做到的是对于多次调用合并到一次迭代中处理完所有的调用方式.换句话说就是解决了上述的两个缺点.大概思路是记录下每一步的操作,然后终端操作时对其迭代依次执行每一步的操作,最后再一次循环中处理. 问题: 操作是如何记录下来的? 操作是如何叠加的? 叠加完如何执行的? 执行完如何收集结果的? Stream结构示意图: 示例代码:123456789101112List&lt;String&gt; data = new ArrayList&lt;&gt;();data.add("张三");data.add("李四");data.add("王三");data.add("马六");data.stream() .filter(x -&gt; x.length() == 2) .map(x -&gt; x.replace("三","五")) .sorted() .filter(x -&gt; x.contains("五")) .forEach(System.out::println); 1. 操作是如何记录下来的? Head记录Stream起始操作 StatelessOp记录中间操作 StatefulOp记录有状态的中间操作这三个操作实例化会指向其父类AbstractPipeline,也就是在AbstractPipeline中建立了双向链表 对于Head12345678910AbstractPipeline(Spliterator&lt;?&gt; source, int sourceFlags, boolean parallel) &#123; this.previousStage = null; //首操作上一步为null this.sourceSpliterator = source; //数据 this.sourceStage = this; //Head操作 this.sourceOrOpFlags = sourceFlags &amp; StreamOpFlag.STREAM_MASK; this.combinedFlags = (~(sourceOrOpFlags &lt;&lt; 1)) &amp; StreamOpFlag.INITIAL_OPS_VALUE; this.depth = 0; this.parallel = parallel;&#125; 对于其他Stage:123456789101112131415AbstractPipeline(AbstractPipeline&lt;?, E_IN, ?&gt; previousStage, int opFlags) &#123; if (previousStage.linkedOrConsumed) throw new IllegalStateException(MSG_STREAM_LINKED); previousStage.linkedOrConsumed = true; //双向链表的建立 previousStage.nextStage = this; this.previousStage = previousStage; this.sourceStage = previousStage.sourceStage; this.depth = previousStage.depth + 1; this.sourceOrOpFlags = opFlags &amp; StreamOpFlag.OP_MASK; this.combinedFlags = StreamOpFlag.combineOpFlags(opFlags, previousStage.combinedFlags); if (opIsStateful()) sourceStage.sourceAnyStateful = true;&#125; 调用过程如此用双向链表串联起来,每一步都得知其上一步与下一步的操作. data.stream() .filter(x -&gt; x.length() == 2) .map(x -&gt; x.replace(“三”,”五”)) .sorted() .filter(x -&gt; x.contains(“五”)) .forEach(System.out::println); 2.操作是如何叠加的?Sink&lt;T&gt;接口: void begin(long size),循环开始前调用,通知每个Stage做好准备 void end(),循环结束时调用,依次调用每个Stage的end方法,处理结果 boolean cancellationRequested(),判断是否可以提前结束循环 void accept(T value),每一步的处理 其子类之一ChainedReference:12345678910111213141516171819static abstract class ChainedReference&lt;T, E_OUT&gt; implements Sink&lt;T&gt; &#123; protected final Sink&lt;? super E_OUT&gt; downstream; public ChainedReference(Sink&lt;? super E_OUT&gt; downstream) &#123; this.downstream = Objects.requireNonNull(downstream); &#125; @Override public void begin(long size) &#123; downstream.begin(size); &#125; @Override public void end() &#123; downstream.end(); &#125; @Override public boolean cancellationRequested() &#123; return downstream.cancellationRequested(); &#125;&#125; 例Filter:123456789101112131415161718192021222324@Overridepublic final Stream&lt;P_OUT&gt; filter(Predicate&lt;? super P_OUT&gt; predicate) &#123; Objects.requireNonNull(predicate); return new StatelessOp&lt;P_OUT, P_OUT&gt;(this, StreamShape.REFERENCE, StreamOpFlag.NOT_SIZED) &#123; @Override Sink&lt;P_OUT&gt; opWrapSink(int flags, Sink&lt;P_OUT&gt; sink) &#123; return new Sink.ChainedReference&lt;P_OUT, P_OUT&gt;(sink) &#123; @Override public void begin(long size) &#123; downstream.begin(-1); &#125; @Override public void accept(P_OUT u) &#123; //条件成立则传递给下一个操作,也因为如此所以有状态的操作必须放到 //end方法里面 if (predicate.test(u)) downstream.accept(u); &#125; &#125;; &#125; &#125;;&#125; 再例如sorted():1234567891011121314151617181920212223242526@Overridepublic void begin(long size) &#123; if (size &gt;= Nodes.MAX_ARRAY_SIZE) throw new IllegalArgumentException(Nodes.BAD_SIZE); list = (size &gt;= 0) ? new ArrayList&lt;T&gt;((int) size) : new ArrayList&lt;T&gt;();&#125;@Overridepublic void end() &#123; list.sort(comparator); downstream.begin(list.size()); if (!cancellationWasRequested) &#123; list.forEach(downstream::accept); &#125; else &#123; for (T t : list) &#123; if (downstream.cancellationRequested()) break; downstream.accept(t); &#125; &#125; downstream.end(); list = null;&#125;@Overridepublic void accept(T t) &#123; list.add(t);&#125; 叠加后如何执行?执行操作是由终端操作来触发的,例如foreach操作12345@Overridepublic void forEach(Consumer&lt;? super P_OUT&gt; action) &#123; //evaluate就是开关,一旦调用就立即执行整个Stream evaluate(ForEachOps.makeRef(action, false));&#125; 执行前会对操作从末尾到起始反向包裹起来,得到调用链1Sink opWrapSink(int flags, Sink&lt;P_OUT&gt; sink) ; 123456789//这个Sink是终端操作所对应的Sinkfinal &lt;P_IN&gt; Sink&lt;P_IN&gt; wrapSink(Sink&lt;E_OUT&gt; sink) &#123; Objects.requireNonNull(sink); for ( AbstractPipeline p=AbstractPipeline.this; p.depth &gt; 0; p=p.previousStage) &#123; sink = p.opWrapSink(p.previousStage.combinedFlags, sink); &#125; return (Sink&lt;P_IN&gt;) sink;&#125; 1234567891011121314@Overridefinal &lt;P_IN&gt; void copyInto(Sink&lt;P_IN&gt; wrappedSink, Spliterator&lt;P_IN&gt; spliterator) &#123; Objects.requireNonNull(wrappedSink); if (!StreamOpFlag.SHORT_CIRCUIT.isKnown(getStreamAndOpFlags())) &#123; //依次执行调用链 wrappedSink.begin(spliterator.getExactSizeIfKnown()); spliterator.forEachRemaining(wrappedSink); wrappedSink.end(); &#125; else &#123; copyIntoWithCancel(wrappedSink, spliterator); &#125;&#125; 有状态的中间操作何时执行?例如sorted()操作,其依赖上一次操作的结果集,按照调用链来说结果集必须在accept()调用完才会产生.那也就说明sorted操作需要在end中,然后再重新开启调用链. sorted的end方法:12345678910111213141516@Override public void end() &#123; list.sort(comparator); downstream.begin(list.size()); if (!cancellationWasRequested) &#123; list.forEach(downstream::accept); &#125; else &#123; for (T t : list) &#123; if (downstream.cancellationRequested()) break; downstream.accept(t); &#125; &#125; downstream.end(); list = null; &#125; 那么就相当于sorted给原有操作断路了一次,然后又重新接上,再次遍历. 如何收集到结果?foreach是不需要收集到结果的,但是对于collect这样的操作是需要拿到最终end产生的结果.end产生的结果在最后一个Sink中,这样的操作最终都会提供一个取出数据的get方法.12345@Override public &lt;P_IN&gt; R evaluateSequential(PipelineHelper&lt;T&gt; helper, Spliterator&lt;P_IN&gt; spliterator) &#123; return helper.wrapAndCopyInto(makeSink(), spliterator).get(); &#125; 如此拿到数据返回]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java8学习记录(一)-函数式接口]]></title>
      <url>%2F2017%2F05%2F18%2Fjava%2FJava8%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%B8%80)-%E5%87%BD%E6%95%B0%E5%BC%8F%E6%8E%A5%E5%8F%A3%2F</url>
      <content type="text"><![CDATA[实习前只是粗略的看了下Java8的一些基本语法,但是没有系统的学习过.在使用一段时间后决定系统的对其进行一次分析,加深对Java8函数式编程的理解,提高自己的编码技巧.另外kotlin崛起,感兴趣的朋友尝试下混编也未尝不可. 函数式接口函数式接口,对于Java来说就是接口内只有一个公开方法的接口,因为使用lanbda表达式,例如() -&gt; user.getName()对应的调用则可能是func.get(),编译器会根据接口推断所属于的方法,如果有两个则无法推断.Java8提供了很多函数式接口,一般都使用注解@FunctionalInterface声明,有必要了解如下一些函数式接口. 函数式接口 参数类型 返回类型 描述 Supplier 无 T 接收一个T类型的值 Consumer T 无 处理一个T类型的值 BiConsumer T,U 无 处理T类型和U类型的值 Predicate T boolean 处理T类型的值,并返回true或者false. ToIntFunction T int 处理T类型的值,并返回int值 ToLongFunction T long 处理T类型的值,并返回long值 ToDoubleFunction T double 处理T类型的值,并返回double值 Function T R 处理T类型的值,并返回R类型值 BiFunction T,U R 处理T类型和U类型的值,并返回R类型值 BiFunction T,U R 处理T类型和U类型的值,并返回R类型值 UnaryOperator T T 处理T类型值,并返回T类型值, BinaryOperator T,T T 处理T类型值,并返回T类型值 以上的函数每一个代表的都是一种基本的操作,操作之间可以自由组合,所以才有了stream这些灵活的操作. Stream操作Stream的操作是建立在函数式接口的组合上的,最好的学习方法是看Stream接口来学习.下面举一些例子来分析,假设有这样的一些初始数据.12345List&lt;String&gt; testData = new ArrayList&lt;String&gt;(); testData.add("张三"); testData.add("李四"); testData.add("王二"); testData.add("麻子"); filter1Stream&lt;T&gt; filter(Predicate&lt;? super T&gt; predicate); filter接收predicate函数,predicate是接收T值,返回boolean值,那么对应的引用就可以写成如下形式,意思是取集合中以’张’开头的名字.12testData.stream() .filter(x -&gt; x.startsWith("张")) map1&lt;R&gt; Stream&lt;R&gt; map(Function&lt;? super T, ? extends R&gt; mapper); map操作接收的是Function接口,对于Function接收T值返回R值,那map的作用就很明显是转换用的,比如下面代码,转换名称为对应的名称长度,也就是从输入String数据返回int数据.12testData.stream() .map(x -&gt; x.length()) flatMap1&lt;R&gt; Stream&lt;R&gt; flatMap(Function&lt;? super T, ? extends Stream&lt;? extends R&gt;&gt; mapper); flatMap和map都是使用Function接口,不同的是返回值flatMap限定为Stream类型.所以flatMap可以作为合并流使用,如以下代码,提取出所有的字符.1234testData.stream() .flatMap(x -&gt; Stream.of(x.split(""))) .collect(Collectors.toList()); //输出 [张, 三, 李, 四, 王, 二, 麻, 子] peek1Stream&lt;T&gt; peek(Consumer&lt;? super T&gt; action); peek参数为Consumer,Consumer接收T值,无返回,那么该方法就可以作为调试不影响stream中内容的一些操作,不过由于对象都是地址引用,你再此做一些对象内容操作也是可以的.reduce1&lt;U&gt; U reduce(U identity, BiFunction&lt;U, ? super T, U&gt; accumulator, BinaryOperator&lt;U&gt; combiner); Reduce比较复杂的一个接口,属于归纳性操作,看参数,第一个是U泛型,也就是输入类型的参数,最为初始值,第二个BiFunction,接收T,U参数,返回U类型参数,BinaryOperator接收U,U类型,并返回U类型.1234567891011 StringBuilder identity = new StringBuilder(); StringBuilder reduce = testData.stream() .flatMap(x -&gt; Stream.of(x.split(""))) .reduce(identity, (r, x) -&gt; &#123; r.append(x); return r; &#125;, StringBuilder::append); System.out.println(identity == reduce); System.out.println(reduce.toString()); //输出 true// 张三李四王二麻子 首先提供一个基本容器identity,然后两个参数r即是identity,x为每次输入参数,最后一个StringBuilder::append是并发下多个identity的合并策略.再举个例子,既然reduce属于归纳性操作,那么也可以当成collect使用,如下:1234567891011121314ArrayList&lt;String&gt; identity = new ArrayList&lt;&gt;(); ArrayList&lt;String&gt; result = testData.stream() .flatMap(x -&gt; Stream.of(x.split(""))) .reduce(identity, (r, x) -&gt; &#123; r.add(x); return r; &#125;,(r1,r2) -&gt; &#123; r1.addAll(r2); return r1; &#125;); System.out.println(identity == result); System.out.println(result); //输出 true //[张, 三, 李, 四, 王, 二, 麻, 子] 强大的collectcollect无疑是stream中最强大的操作,掌握了collect操作才能说掌握了stream.为了便于使用者,Java提供了Collectors类,该类提供了很多便捷的collect操作,如Collector&lt;T, ?, List&lt;T&gt;&gt; toList(),Collector&lt;T, ?, Set&lt;T&gt;&gt; toSet()等操作.这些操作最终都会调用如下构造函数构造出collector对象,因此掌握该本质是最佳的学习方式.1234567891011CollectorImpl(Supplier&lt;A&gt; supplier, BiConsumer&lt;A, T&gt; accumulator, BinaryOperator&lt;A&gt; combiner, Function&lt;A,R&gt; finisher, Set&lt;Characteristics&gt; characteristics) &#123; this.supplier = supplier; this.accumulator = accumulator; this.combiner = combiner; this.finisher = finisher; this.characteristics = characteristics; &#125; Supplier类似reduce中的u,接收一个元数据,BiConsumer则是操作数据,BinaryOperator并发下聚合,finisher完成时的转换操作,Set应该按照定义是优化一些操作中的转换.如下面的toList()操作,其finish操作为castingIdentity().123456public static &lt;T&gt; Collector&lt;T, ?, List&lt;T&gt;&gt; toList() &#123; return new CollectorImpl&lt;&gt;((Supplier&lt;List&lt;T&gt;&gt;) ArrayList::new, List::add, (left, right) -&gt; &#123; left.addAll(right); return left; &#125;, CH_ID); &#125; 再看toMap的实现12345678910public static &lt;T, K, U, M extends Map&lt;K, U&gt;&gt;Collector&lt;T, ?, M&gt; toMap(Function&lt;? super T, ? extends K&gt; keyMapper, Function&lt;? super T, ? extends U&gt; valueMapper, BinaryOperator&lt;U&gt; mergeFunction, Supplier&lt;M&gt; mapSupplier) &#123; BiConsumer&lt;M, T&gt; accumulator = (map, element) -&gt; map.merge(keyMapper.apply(element), valueMapper.apply(element), mergeFunction); return new CollectorImpl&lt;&gt;(mapSupplier, accumulator, mapMerger(mergeFunction), CH_ID);&#125; Function作为转换函数提供了key和value的转换,BinaryOperator提供了重复key合并策略,mapSupplier则表示最终收集到的容器.那么使用就很简单了123HashMap&lt;Character, String&gt; map = testData.stream() .collect(Collectors.toMap(x -&gt; x.charAt(0), Function.identity() , (v1, v2) -&gt; v2, HashMap::new)); 其他还有很多方法,就不一一叙述,主要是了解这些接口,知道他所拥有的功能,以及组合的意义,即可很好的掌握Java中的函数式编程.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java中序列化相关知识]]></title>
      <url>%2F2017%2F05%2F02%2F%E5%B7%A5%E5%85%B7%2FJava%E4%B8%AD%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%2F</url>
      <content type="text"><![CDATA[今天线上遇到了DTO类实现了Serializable接口,但是其并没有显示声明serialVersionUID,这样的话每次打包有改动JDK就会为其重新生成serialVersionUID.这就带来了不同版本之间的实体类可能反序列化不成功,线上RPC调用出现了问题.那么就深入探讨一下原因. Serializable的作用看该类的JDK注释可以发现The serialization interface has no methods or fields and serves only to identify the semantics of being serializable.也就是说Serializable是一个标识接口,和Cloneable接口等一样的效果.如下面的User类,实现了序列化接口,并使用serialVersionUID标识其序列化对应的ID序号.12345static class User implements Serializable &#123; private static final long serialVersionUID = 5768430629641297769L; private String nickname; private String passwd; //省略get和set 如何序列化java.io.ObjectOutputStream代表对象输出流,其使用writeObject()方法把对象实例转换为字节流然后写入到文件,或者用于网络传输.12345678910@Testpublic void testWriteObj() throws IOException &#123; User userDO = new User(); userDO.setNickname("屈定"); userDO.setPasswd("123456"); File file = new File("user.out"); ObjectOutputStream outputStream = new ObjectOutputStream(new FileOutputStream(file)); outputStream.writeObject(userDO);//序列化写入到文件中. outputStream.close();&#125; 如何反序列化java.io.ObjectInputStream代表对象输入流,其使用readObject()方法读取序列化的字节,然后再转换为对象.12345678@Testpublic void testReadObj() throws IOException, ClassNotFoundException &#123; File file = new File(base+File.separator+"user.out"); ObjectInputStream inputStream = new ObjectInputStream(new FileInputStream(file)); User user = (User) inputStream.readObject(); Assert.assertTrue(StringUtils.equals(user.getNickname(),"屈定")); Assert.assertTrue(StringUtils.equals(user.getPasswd(),"123456"));&#125; serialVersionUID的作用按照上面代码,序列化和反序列化都是成功的,如果在已经序列化后,对User要作修改,增加一个email字段,再试试反序列化.123456 static class User implements Serializable &#123; private static final long serialVersionUID = 5768430629641297769L; private String nickname; private String passwd; private String email;&#125; 程序会正常运行,而且这个email会被很智能的初始化为null.修改serialVersionUID为1L再试试.1java.io.InvalidClassException: cn.edu.aust.test.ObjectTest$User; local class incompatible: stream classdesc serialVersionUID = 5768430629641297769, local class serialVersionUID = 1 报错很明显,两边类的serialVersionUID不一样,也就是说对于编译好的class,其serialVersionUID是其序列化的唯一标识,如果未显示声明JDK则会自动为其加上,可以使用命令seriserialver可以查看一个class文件的serialVersionUID,当线上版本忘记加该字段的时候该命令还是很有用处的.12seriserialver cn.edu.aust.test.ObjectTest\$User cn.edu.aust.test.ObjectTest$User: private static final long serialVersionUID = 1L; transient的作用transient翻译为瞬时,也就是被其修饰的变量序列化时会忽略该字段.什么时候需要用到这个字段呢?在Java中对象之间的关系会组成一个对象图,序列化的过程是对该对象图的遍历,那么反序列化也仍然是对该对象图的遍历.对于对象里面的对象就是递归过程,对于链表之类的数据结构递归的话很容易引起栈溢出,那么就可以使用transient忽略该字段.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[对一个WEB请求的理解]]></title>
      <url>%2F2017%2F04%2F30%2F%E8%BF%90%E7%BB%B4%2F%E5%AF%B9%E4%B8%80%E4%B8%AAWEB%E8%AF%B7%E6%B1%82%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[随着写的WEB程序越来越多,项目的部署也越来越繁琐,对于一些线上问题总是搞不清楚是哪个环节出的问题,归根结底是对整个流程的不熟悉导致,所以分析下一个WEB请求从用户输入地址到页面出来到底经历过多少东西. URL解析首先把URL分割为几个部分,以地址http://mrdear.cn/2017/04/15/动漫推荐/为例协议: http网址: mrdear.cn资源路径: 2017/04/15/动漫推荐/ 浏览器拿到地址后会对其中非ASCII码的Unicode字符解析,比如空格会变成%20,汉字也会变成其16进制对应的编码值,如下例子:12上面链接等价于http://mrdear.cn/2017/04/15/%E5%8A%A8%E6%BC%AB/%E5%8A%A8%E6%BC%AB%E6%8E%A8%E8%8D%90/ 中间还有其他很复杂的流程,比如参数,协议,请求头,请求体等建立. DNS域名解析对于网址mrdear.cn,浏览器并不知道他所处的服务器位置,因此需要解析出其服务器ip,这个过程就是DNS域名解析. 浏览器首先检查自身缓存dns解析,以chrome为例,输入chrome://net-internals/#dns即可看到缓存列表.该缓存通常几分钟到几小时不等,存在的话就直接返回,否则下一步 和浏览器同样策略,OS对每一次解析结果也会做缓存,浏览器中不存在则在OS的缓存中查找.这个过成功也包括在本地hosts中查找.找到则返回,找不到则向本机的dns服务器发送查找请求. DNS服务器和本机在一个子网内,则APR解析到具体设备的mac地址,然后向其查找.如果不在一个子网,则直接ARP解析当前主机网关地址,网关一般是上一个路由节点,也就是把查询转交给上一层服务器,那么上一层服务器找不到还会转交给它的上一层,如此形成一个递归查询过程,直到查找到根服务器.找不到则返回失败.找到则返回ip地址和其TTL时间.linux和unix下的dns配置在/etc/resolv.conf中,可以使用nslookup或者dig查看解析过程. 解析成功后,浏览器创建与服务器的socket连接,构造请求信息,进行TCP三次握手,开始向服务器传输消息,并等服务器回复信息,这也是TPC可靠的一个原因. 服务器响应服务器以nginx+tomcat为例,经过以上步骤后请求到达了nginx,nginx对URL进行分析,验证其所在机器上有所需要的服务,并且用户是有权限调用的,决定该URL由哪一个tomcat服务处理,捕获处理结果,返回给请求者,最后四次挥手结束请求.到此完成浏览器,服务端的通信. 浏览器渲染浏览器拿到了服务器的返回信息后会对内容进行解析,展现成用户所需要的内容,如html,pdf等. 那么整个过程总结来看就是 用户输入URL -&gt; 浏览器解析地址 -&gt; DNS查找域名对应ip -&gt; 服务器响应 -&gt;浏览器拿到响应渲染. 附录1.CDN网络CDN又叫内容分布网络,一般用于静态资源如html,css,js的存储,简单的理解为一张大网,网上每一个节点都有着很多资源.那么每一个用户想要访问的时候就会去找离他最近的节点上面获取需要的内容.从而加快了网站整体访问速度.举个例子:用户访问taobao的某css文件,首先浏览器会发送请求 -&gt; DNS解析域名,这里一般会有一个DNS负载均衡服务器,其得到最适合用户的CDN节点ip -&gt; 用户拿到CDN节点ip得到资源. 2.DNS劫持了解了DNS的解析是一个递归过程,找到域名 &lt;-&gt; ip就返回,如果有人手动修改了该条映射信息,那么就会返回到错误的ip地址,这种行为也叫DNS劫持,对于客户端来说,没有很好地方式能认为服务器返回的信息是可靠的,也就是不可靠的HTTP通信,所以也就导致了这一层的攻击漏洞,而这种事一般是天朝的电信运营商能干得出来,所以选择一个靠谱的DNS是非常重要,推荐114.114.114.114 3.HTTPS应对HTTP的不可靠通信,所以诞生了HTTPS,即HTTP over SSL,使用SSL/TLS对HTTP的内容进行加密解密.整个流程如下图: 在SSL握手阶段，客户端浏览器会认证服务器的身份，这是通过“证书”来实现的，证书由证书权威（CA）为某个域名签发，可以理解为网站的身份证件，客户端需要对这个证件进行认证，需要确定该证书是否属于目标网站并确认证书本身是否有效。最后在握手阶段，通信的双方还会协商出一个用于加密和解密的会话密钥。 SSL握手阶段结束之后，服务器和客户端使用协商出的会话密钥对交互的数据进行加密/解密操作，对于HTTP协议来说，就是将HTTP请求和应答经过加密之后再发送到网络上。HTTPS协议对服务器进行了一次身份验证,所以即使DNS被劫持,定向到的服务器也会因为没证书而无法通过身份验证. 4.乱码问题流程清晰后乱码问题就很好解决了,把浏览器,Nginx,Tomcat等都当成水池的话,数据的乱码只能在每一个的入口端和出口端.如果发生了乱码,那么首先定位到是哪一个口产生了乱码,然后再去找原因,一般都能解决.以JavaWEB应用为例,乱码主要发生在IO交互的过程中.其一浏览器与服务器建立socket连接,浏览器对URL以及request转换编码.请求到达tomcat,tomcat会对其进行解码,这个解码可在tomcat目录下的conf/server.xml中配置URIEncoding12&lt;connector port=”8080″ protocol=”HTTP/1.1″ maxThreads=”150″ connectionTimeout=”200000″ redirecPort=”8443″ URIEncoding=”utf-8″/&gt; 这里要保证不乱码,下一步tomcat建立了ServletRequest和ServletResponse,那么这里也有编码,一般是post表单或者request body乱码,那么就需要指定ServletRequest和ServletResponse的编码格式12request.setCharacterEncoding(encoding);//设置请求信息编码response.setCharacterEncoding(encoding);//设置返回信息编码 Java程序在处理请求时和操作系统会有IO通信,和数据库会有IO通信,整个过程也会涉及编码,这种一般代码中会自动控制,出问题几率不大.浏览器拿到返回信息后对页面进行渲染,这一步也会有编码,这个一般手动指定下浏览器的渲染编码,比如Content-Type: text/html;charset=UTF-8,指定以UTF-8渲染该text/html返回. 5.几种域名解析域名解析记录主要分为：A 记录、MX记录、CNAME 记录、NS记录和 TXT记录 A记录：A 代表的是Address，用来指定域名对应的IP地址。域名可以多对一但是不能一对多。 MX记录：Mail Exchange,就是讲某个域名下的邮件服务器指向自己的Mail Server。 CNAME记录：别名解析。将一个域名设置一个或者多个别名。 NS记录：为某个域名指定DNS解析服务器。 TXT记录：为某个主机名或者域名设置文字说明。本站是托管于github的,主域名mrdear.cn是使用CNAME解析到nl101531.github.io的,二级域名oj.mrdear.cn和md.mrdear.cn都是使用A记录解析到对应主机的ip地址,到达主机后再使用Nginx进行不同的服务器转发. 后记个人总结,如有错误请指出,以免误人子弟.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[毕业设计周记(八)]]></title>
      <url>%2F2017%2F04%2F29%2F%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%2F%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E5%91%A8%E8%AE%B0(%E5%85%AB)%2F</url>
      <content type="text"><![CDATA[写毕业设计过程中发现一些设计不是很好的地方,比如说结构上之前maven模块化分层,dao,service,controller每一个都是单独的maven项目,导致开发起来比较麻烦,所以改掉了,把数据库模型对应的DO单独放入一个架包,然后dao,service,controller等放入一个war包中,明白了对于一个小项目来说过多的分层是系统开发的累赘. 修改数据库模型后代码不少地方重新写了下,耽误了点时间,五一期间仍然是写毕业论文. 前端项目地址: https://github.com/nl101531/AUSTOJ-WEB 后端项目地址: https://github.com/nl101531/AUSTOJ2 测试地址: http://oj.mrdear.cn 测试账号: 1015315668@qq.com 111111 等待完成: 1.毕业论文]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[毕业设计周记(七)]]></title>
      <url>%2F2017%2F04%2F24%2F%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%2F%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E5%91%A8%E8%AE%B0(%E4%B8%83)%2F</url>
      <content type="text"><![CDATA[本周把个人中心完成了,用户注册后的邮件验证,以及注册后的更新自身信息,找回密码等功能都完成. 毕业论文正在写系统整体设计,需要画一些图.预计五一假期之后初稿出来. 前端项目地址: https://github.com/nl101531/AUSTOJ-WEB 后端项目地址: https://github.com/nl101531/AUSTOJ2 测试地址: http://oj.mrdear.cn 测试账号: 1015315668@qq.com 111111 等待完成: 1.毕业论文]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[少走弯路的10条建议(转)]]></title>
      <url>%2F2017%2F04%2F21%2F%E7%BB%8F%E9%AA%8C%2F%E5%B0%91%E8%B5%B0%E5%BC%AF%E8%B7%AF%E7%9A%8410%E6%9D%A1%E5%BB%BA%E8%AE%AE(%E8%BD%AC)%2F</url>
      <content type="text"><![CDATA[少走弯路的10条建议(转)标签（空格分隔）： 经验 转载自一个很佩服的大牛博客:孤傲苍狼 如何在涉世之初少走弯路，有一个好的开端，开始一番成功的事业？以下是一些先行者积累的10条有益的涉世忠告。好好地遵循、把握这些忠告和建议吧，比起所学的课堂课程来，它毫不逊色！ 1.1、买个闹钟，以便按时叫醒你 贪睡和不守时，都将成为你工作和事业上的绊脚石，任何时候都一样。不仅要学会准时，更要学会提前。就如你坐车去某地，沿途的风景很美，你忍不住下车看一看，后来虽然你还是赶到了某地，却不是准时到达。“闹钟”只是一种简单的标志和提示，真正灵活、实用的时间，掌握在每个人的心中。 1.2、如果你不喜欢现在的工作，要么辞职不干，要么就闭嘴不言 初出茅庐，往往眼高手低，心高气傲，大事做不了，小事不愿做。不要养成挑三拣四的习惯。不要雨天烦打伞，不带伞又怕淋雨，处处表现出不满的情绪。记住，不做则已，要做就要做好。 1.3、每个人都有孤独的时候 要学会忍受孤独，这样才会成熟起来。年轻人嘻嘻哈哈、打打闹闹惯了，到了一个陌生的环境，面对形形色色的人和事，一下子不知所措起来，有时连一个可以倾心说话的地方也没有。这时，千万别浮躁，学会静心，学会忍受孤独。在孤独中思考，在思考中成熟，在成熟中升华。不要因为寂寞而乱了方寸，而去做无聊无益的事情，白白浪费了宝贵的时间。 1.4、走运时要做好倒霉的准备 有一天，一只狐狸走到一个葡萄园外，看见里面水灵灵的葡萄垂涎欲滴。可是外面有栅栏挡着，无法进去。于是它一狠心绝食三日，减肥之后，终于钻进葡萄园内饱餐一顿。当它心满意足地想离开葡萄园时，发觉自己吃得太饱，怎么也钻不出栅栏了。相信任何人都不愿做这样的狐狸。退路同样重要。饱带干粮，晴带雨伞，点滴积累，水到渠成。有的东西今天似乎一文不值，但有朝一日也许就会身价百倍。 1.5、不要像玻璃那样脆弱 有的人眼睛总盯着自己，所以长不高看不远；总是喜欢怨天尤人，也使别人无比厌烦。没有苦中苦，哪来甜中甜？不要像玻璃那样脆弱，而应像水晶一样透明，太阳一样辉煌，腊梅一样坚强。既然睁开眼睛享受风的清凉，就不要埋怨风中细小的沙粒。 1.6、管住自己的嘴巴 不要谈论自己，更不要议论别人。谈论自己往往会自大虚伪，在名不副实中失去自己。议论别人往往陷入鸡毛蒜皮的是非口舌中纠缠不清。每天下班后和你的那些同事朋友喝酒聊天可不是件好事，因为，这中间往往会把议论同事、朋友当做话题。背后议论人总是不好的，尤其是议论别人的短处，这些会降低你的人格。 1.7、机会从不会“失掉”，你失掉了，自有别人会得到 不要凡事在天，守株待兔，更不要寄希望于“机会”。机会只不过是相对于充分准备而又善于创造机会的人而言的。也许，你正为失去一个机会而懊悔、埋怨的时候，机会正被你对面那个同样的“倒霉鬼”给抓住了。没有机会，就要创造机会，有了机会，就要巧妙地抓住。 1.8、若电话老是不响，你该打出去 很多时候，电话会给你带来意想不到的收获，它不是花瓶，仅仅成为一种摆设。交了新朋友，别忘了老朋友，朋友多了路好走。交际的一大诀窍就是主动。好的人缘好的口碑，往往助你的事业更上一个台阶。 1.9、千万不要因为自己已经到了结婚年龄而草率结婚 想结婚，就要找一个能和你心心相印、相辅相携的伴侣。不要因为放纵和游戏而恋爱，不要因为恋爱而影响工作和事业，更不要因一桩草率而失败的婚姻而使人生受阻。感情用事往往会因小失大。 1.10、写出你一生要做的事情，把单子放在皮夹里，经常拿出来看 人生要有目标，要有计划，要有提醒，要有紧迫感。一个又一个小目标串起来，就成了你一生的大目标。生活富足了，环境改善了，不要忘了皮夹里那张看似薄薄的单子。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[毕业设计周记(六)]]></title>
      <url>%2F2017%2F04%2F16%2F%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%2F%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E5%91%A8%E8%AE%B0(%E5%85%AD)%2F</url>
      <content type="text"><![CDATA[前端项目重构完毕,目前已部署到个人服务器上了. 接下来写毕业论文,然后对OJ的功能进行测试,并且对其中的小bug进行修复. 前端项目地址: https://github.com/nl101531/AUSTOJ-WEB 后端项目地址: https://github.com/nl101531/AUSTOJ2 测试地址: http://oj.mrdear.cn 测试账号: 1015315668@qq.com 111111 等待完成: 1.毕业论文]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[动漫推荐]]></title>
      <url>%2F2017%2F04%2F15%2F%E5%8A%A8%E6%BC%AB%2F%E5%8A%A8%E6%BC%AB%E6%8E%A8%E8%8D%90%2F</url>
      <content type="text"><![CDATA[动漫推荐标签（空格分隔）： 动漫 从小就是个动漫爱好者,年轻时追番,现在老了追不动了,只追动漫电影和一些经典动漫剧场版.我也不知道自己是什么风格的动漫迷,只是觉得好看,有共鸣就认为是好作品.人们总是把自己喜爱的东西推荐给别人,我也不例外,下面推荐我认为很不错的片子.(排名不分先后) 异邦人 无皇刃谭2017年初来在上海实习时看的,故事很温情,对于刚到一个陌生城市打拼的青年来说很容易引起共鸣,也因此我感触颇深,异邦人都是孤独的存在,内心是挣扎的,想要找到自己的归属,然而哪里才是归属?背景音乐很赞,听起来内心有点温暖,但是又会觉得很伤感,充满了无奈 秒速五厘米大概高一的时候第一次看了这个作品,唯美的画面,伤感的故事,再加上年少懵懂的恋爱经历,从此新海诚一生粉.回想以前是不是很多事情都可以 One more time,One more chance 你看起来很好吃相当有趣的一部动漫,看起来完全没有负重感,从母爱,父爱,独立,自强等方面诠释了一个龙的成长.电影版是温情的结局,萌萌的画面,治愈的故事,给心情带来不一样的体验.记住:哭闹的孩子 不管在哪里都会被霸王龙叼走 萤火之森无法触碰的爱情,只是梦中的憧憬,这样的动漫是提醒你,在你年轻的时候曾经心里也住着一个无法触碰的他/她. fate stay night作为番剧来说最喜欢的一个系列,fate stay night也是最早出来的一部,配乐,战斗,剧情都那么引人入胜,虽然fate zero也非常不错,但是让我来选择的话还是该部更让我难忘. 怪物之子细田守家族系列电影,复杂成长的环境会造成我们内心的空洞,然而填补这些空洞的方式就是父母的爱,即使在你眼中认为一无是处,半吊子的父亲,在最关键的时候也会奋不顾身的化身为剑去填补你内心的黑暗,细细回想小时候学习父亲的一举一动或许是每个人都无法忘记的时刻. 斩·赤红之瞳有点虐的番剧,几乎每个角色都是主角的设定,所以每个人角色的个性都很鲜明,也导致了每一个人物死去所带来的感染力.尤其看到结局,最初的一群角色就剩一个赤瞳了,其帮助革命军成立了新国家,然而其还要背负革命军为了革命所做的恶.该番剧有点杀红了眼,所以看的话就要做好心理准备. 亚人这两周把亚人的电影版和TV版都看了一遍,首先电影版绝对是圈钱的作品,还是直接看TV版本吧,剧情一样.整个看下来感觉亚人一部很理性的动漫,无论是主角的处事风格,还是亚人和搜查官的联合,都是利益组建了一个关系网,截止到第二季来说目前还是这样的理性,不知道后期有没有变化.能把不死这一老套的技能演绎出这么多惊心动魄的故事场景的估计也只有亚人了吧.另外这动漫也透漏出政府只是比较大的土匪头子而已. 犬夜叉剧场版犬夜叉是儿时的回忆,尤其是其四个剧场版,小时候最喜欢看天下霸道之剑这一部,犬夜叉相比火影之类动漫的优点是其有一条爱情线,犬夜叉与阿离(我喜欢台版的这个翻译),犬夜叉与桔梗这之间复杂但却互相信任的关系.最喜欢的人物莫过于桔梗,其只是想过上普通的生活,然而命运却让其至死也无法得到想要的生活,悲情人物总能引起观看者的同情.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[angular2学习记录-给后端程序员的经验分享]]></title>
      <url>%2F2017%2F04%2F08%2Fweb%2Fangular2%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95-%E7%BB%99%E5%90%8E%E7%AB%AF%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%2F</url>
      <content type="text"><![CDATA[1.前言前几天刚下定决心把毕业设计改造下,因为毕业设计算是我学习的基石,学习到的东西都尽可能的在这个平台上施展,锻炼自己.改造为前后端分离,前端使用angular2,后端只提供接口.便于以后的维护.那么就要学习agular2了. 这里就要说下个人观点了,安利一波:我认为每个程序员都应该有自己的一个项目,一个可以让你学习的东西能施展到上面的项目,可能该项目一开始很简单,但是随着你不断的学习,不断的把新知识运用进去,这个项目就会伴随着你的成长而丰富起来,给你带来的则是更多的实战经验. 2.angular2简介 angular2是类似全家桶组合的框架,所需要的东西几乎都包办了,所以开发起来很迅速. 使用TypeScript作为开发语言,对于Java和C#程序员可以快速上手,还有就是我比较喜欢强类型语言,每个变量各司其职,由其的类型来限定,开发人员也很明确知道变量的作用. google和Microsoft支持 WebStorm对angular2的强大支持. 一篇安利文章http://www.infoq.com/cn/articles/why-choose-angular2/ 一些学习资料ECMAScript 6入门 http://es6.ruanyifeng.com/TypeScript入门 http://www.imooc.com/learn/763TypeScript中文网 https://www.tslang.cn/docs/tutorial.html慕课网1小时快速上手视频 http://www.imooc.com/learn/789官方文档 https://www.angular.cn/docs/ts/latest/cli-quickstart.html 3.遇到的问题3.1滚动监听要实现页面滚动后导航栏会变色的效果,如下图(图来自我的csdn博客,没找到其他好图床) 之前使用Jq是123$(window).scroll(function () &#123; indexApp.scrollBar = parseInt(document.body.scrollTop||document.documentElement.scrollTop);&#125;); 不打算依赖Jq,搜了点资料发现了下面两种写法.1234567891011//下面这种写法在TS下不会有效果. isAddBackColor()&#123; if (this.getIsIndex())&#123; var self = this; //该处使用匿名函数,而不是箭头函数. window.addEventListener('scroll',function () &#123; let marginTop = document.body.scrollTop|| document.documentElement.scrollTop; self.isBackColor = marginTop &gt; 20 &amp;&amp; self.getIsIndex(); &#125;); &#125; &#125; 12345678910111213/** * 判断是否需要加背景色(有效果的) * 使用isBackColor控制结果 */ isAddBackColor()&#123; if (this.getIsIndex())&#123; //监听事件使用箭头函数,这样ng2才会管理该变量 window.addEventListener('scroll',() =&gt; &#123; let marginTop = document.body.scrollTop|| document.documentElement.scrollTop; this.isBackColor = marginTop &gt; 20 &amp;&amp; this.getIsIndex(); &#125;); &#125; &#125; 原因不明,猜想是var self = this;赋值操作后相当于一个全新的变量,self并不受angular管理,导致刷新的变量是self中的isBackColor. 3.2http参数传递按照下面代码传参数应该是没有问题的,但是我遇到了url被编码问题,例如输入1111@qq.com会被转换为1111%40qq.com,导致服务端解析失败,找了很多原因才发现是URLSearchParams这个对象用错了,angular2提供了这个对象,es6里面也有一个该对象,换成ng2中对象即可,import {URLSearchParams} from &quot;@angular/http&quot;;12345678let urlParams = new URLSearchParams();urlParams.set('search',search);urlParams.set('order',order);urlParams.set('pageNum',pageNum.toString());urlParams.set('pageSize',pageSize.toString());return this.http.get(Config.url_problem_stage + stage,&#123;params:urlParams&#125;).toPromise() .then(response =&gt; response.json()) .catch(LogService.handleError) 3.3跨域问题浏览器要求同源下才可请求,否则就产生跨域问题. URL 说明 是否允许通信 http://www.a.com/a.jshttp://www.a.com/b.js 同一域名下 允许 http://www.a.com/lab/a.js http://www.a.com/script/b.js 同一域名下不同文件夹 允许 http://www.a.com:8000/a.js http://www.a.com/b.js 同一域名，不同端口 不允许 http://www.a.com/a.js https://www.a.com/b.js 同一域名，不同协议 不允许 http://www.a.com/a.js http://70.32.92.74/b.js 域名和域名对应ip 不允许 http://www.a.com/a.js http://script.a.com/b.js 主域相同，子域不同 不允许 http://www.a.com/a.js http://a.com/b.js 同一域名，不同二级域名（同上） 不允许（cookie这种情况下也不允许访问） http://www.cnblogs.com/a.js http://www.a.com/b.js 不同域名 不允许 解决方案是用nginx反向代理到不同端口,模拟同一域名下不同文件夹情况.nginx监听本地888端口,这个也是项目入口,对于带api标识的请求转到后端服务器,对于其他请求则到前端服务器.123456789101112131415server &#123; listen 8888; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location /api &#123; proxy_pass http://127.0.0.1:8080; &#125; location / &#123; proxy_pass http://127.0.0.1:4200; &#125;&#125; 3.4路由问题angular2的路由匹配规则是从根路由也就是forRoot()的这个开始.在该处匹配寻找规则. 根路由:12345678910111213141516171819export const appRoutes: Routes = [ &#123; path:'', component: IndexComponent, pathMatch:'full' &#125;, &#123; path:'aust', loadChildren:'./content/content.module#ContentAndAsideModule' &#125;, &#123; path:'index', component: IndexComponent, &#125;, &#123; path:'**', loadChildren:'./content/content.module#ContentAndAsideModule' &#125;,]; 子路由:12345678910export const childRouter : Routes = [ &#123; path: '', component:ContentAndAsideComponent, children:[ &#123;path:'',redirectTo:'/index',pathMatch:'full'&#125;, &#123;path:'start',component:StartComponent&#125;, ] &#125; ]; 举例:访问/,则先在根路由寻找,找到其跳转到IndexComponent,完成任务访问/aust.则先在根路由找,发现需要到子路由里面寻找,到子路由后,在children中发现被重定向到/index,那么回到根路由,找到IndexComponent完成任务.访问/aust/start,则先在根路由找,发现需要到子路由,到子路由匹配到StartComponent,完成任务. 路由参数路由传参数主要有两种方式,一种是restful风格的,一种是?号参数风格的.两种参数都保存在ActivatedRoute对象中,因此下面代码中的route为此对象— restful风格配置:{path:&#39;article/:id&#39;,component:ArticleComponent}链接:http://domain/article/1路由:[routerLink]=&quot;[&#39;article&#39;,article.id]&quot;或者直接拼接urljs获取:this.route.params中的一系列方法,或者this.route.snapshot.params[&#39;id&#39;]— 问号参数风格配置:{path:&#39;article&#39;,component:ArticleComponent}链接:http://domain/article?id=1路由:routerLink=&quot;article&quot; [queryParams]=&quot;{id: article.id}&quot;js获取:this.route.queryParams中的一系列方法,或者this.route.snapshot.queryParams[&#39;id&#39;],另外可以使用订阅模式queryParamMap.subscribe(),路由参数更新时自动通知 3.5组件通信父-&gt;子:子组件使用input装饰器,接受父组件的属性,并且可使用ngOnChanges或则setter监听变化,做额外处理.子-&gt;父:使用output装饰器加EventEmitter向上弹出事件到父组件,父组件监听后处理.任意组件:使用service通讯(要求service单例),service提供Observable的next发布,其他组件引用service对象subscribe该发布,那么就实现了信息的流动,并且是在只要订阅了该发布的组件中都能获取. 3.6单例?agular2的service是providers提供的,该组件如果引用了这个service,那么会先在自己的providers中寻找service,找不到则再向上找父组件,直到module.那么意味着每一个providers提供的是一个实例,旗下的组件都是享用这一个实例,那么怎么实现全局单例呢?很简单在根module中提供服务且其他组件不要自己providers该服务. 3.7组件生命周期组件生命周期看下面这张图.图中没有onChanges(changes: SimpleChanges)方法的调用,该方法检测到组件的输入属性发生变化时调用,也就是存在@input装饰的属性,该属性每次变化时会调该方法. 3.8部署问题单页应用部署到服务器上可能会出现访问www.domain.xx可以访问,并且点击什么的都能成功,但是直接访问其中一个路由www.domain.xx/aust/start却报404.先分析下问题的原因,我们的单页应用只有一个入口,报404也就是没找到这个入口.看nginx的配置.nginx收到请求后会去root下寻找aust/start下的index.html那么自然找不到,所以直接访问就会404.那么问题来了为什么访问www.domain.xx之后页面内跳转到路由没问题呢?这是因为访问主域名后angular的js都已经全部加载了,这个时候跳转是js来控制的,不经过nginx自然不会出现上面的问题.1234location / &#123; root /Users/niuli/workspace/web/austoj/dist; index index.html index.htm;&#125; 解决方法:解决方法就是让其对于路由都去加载index.html这个文件.使用try_files指令,该指令会把uri当成一个文件,去根目录下寻找,找不到的话则内部重定向到配置的/index.html.这样配置的好处,对于静态资源try_files会直接找到后就返回,对于路由则会定向到/index.html.12345location / &#123; try_files $uri /index.html; root /Users/niuli/workspace/web/austoj/dist; index index.html index.htm;&#125; 3.9文件上传文件上传是通过ajax操作上传,使用FormData形式,主要有以下问题要解决. 怎么获得input框所选中的文件(为input绑定change事件,然后获取$event,文件就是event.srcElement.files[0]) 怎么上传到服务器?(使用formData对象,调用其append方法添加文件,再使用angular2的http组件post上去)1234567uploadAvatar(file: any): Promise&lt;any&gt;&#123; let formData:FormData = new FormData(); formData.append('avatar',file); return this.http.post(Config.url_upload_img,formData).toPromise() .then(response =&gt; response.json()) .catch(LogService.handleError); &#125; angular2项目:https://github.com/nl101531/AUSTOJ-WEB]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[毕业设计周记(五)]]></title>
      <url>%2F2017%2F04%2F08%2F%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%2F%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E5%91%A8%E8%AE%B0(%E4%BA%94)%2F</url>
      <content type="text"><![CDATA[本周一直在重构前端,目前登录注册+侧边栏都已经完成,在此过程熟悉了angular2的开发模式,不得不佩服这些前端大神们,搞出来ng2这种类似后端写法的框架,下周进度会更加快,希望下周重构完成. 前端项目地址: https://github.com/nl101531/AUSTOJ-WEB 等待完成: 1.前端页面的重构 源码地址: https://github.com/nl101531/AUSTOJ2]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[毕业设计周记(四)]]></title>
      <url>%2F2017%2F04%2F03%2F%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%2F%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E5%91%A8%E8%AE%B0(%E5%9B%9B)%2F</url>
      <content type="text"><![CDATA[上周注册流程等都写完了,开始重构前端页面,最终选择使用angular2来重构,其类似后端的写法以及typescript语法对js的修正使得其很容易上手.这周任务主要是在重构中熟悉angular的写法.到五月份的话不知道能不能重构完,尽力而为了. 测试地址: http://oj.mrdear.cn/ 服务器比价渣,速度比较慢 测试账号: 1015315668@qq.com 密码: 111111 等待完成: 1.前端页面的重构 源码地址: https://github.com/nl101531/AUSTOJ2]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[redis学习记录(四)-SpringDataRedis分析]]></title>
      <url>%2F2017%2F03%2F29%2Flinux%2Fredis%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E5%9B%9B)-SpringDataRedis%E5%88%86%E6%9E%90%2F</url>
      <content type="text"><![CDATA[redis学习记录(四)-SpringDataRedis分析标签（空格分隔）： redis Redis学习记录(一)–入门知识Redis学习记录(二)–使用Jedis连接redis学习记录(三)-redis中的数据结构 1.简介Spring Data Redis是对redis客户端(如jedis)的高度封装,支持多种客户端,因其高抽象,所以在某一个客户端不支持更新的时候可以容易切换到其他客户端. 本文是在Spring boot 1.5.2版本下测试. 需要引入架包12345678910111213141516171819202122232425262728&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.2.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!--spring boot start--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.配置在Spring Boot下默认使用jedis作为客户端,并在包org.springframework.boot.autoconfigure.data.redis下,提供自动配置类RedisProperties,RedisAutoConfiguration等. 根据RedisProperties可以定位到可配置的属性,如:123456789101112131415161718# Redis数据库索引（默认为0）spring.redis.database=0# Redis服务器地址spring.redis.host=115.159.185.14# Redis服务器连接端口spring.redis.port=6379# Redis服务器连接密码（默认为空）spring.redis.password=# 连接池最大连接数（使用负值表示没有限制）spring.redis.pool.max-active=8# 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.pool.max-wait=-1# 连接池中的最大空闲连接spring.redis.pool.max-idle=8# 连接池中的最小空闲连接spring.redis.pool.min-idle=0# 连接超时时间（毫秒）spring.redis.timeout=2000 在application.properties中配置即可,另外还有Sentinel和Cluster说明支持分布式和集群,博主研究不多就不瞎说这个了. 自动配置主要在RedisAutoConfiguration中,该类会提供三个bean: JedisConnectionFactory : jedis连接控制工厂 RedisTemplate : redis操作入口 StringRedisTemplate : redis操作入口 那么就开始入口学习. 3.RedisTemplateRedisTemplate是操作的入口.该类继承了RedisAccessor,可以通过其拿到redis连接,实现了RedisOperations接口,获得了操作redis的能力,如下图所示: 3.1 Test case那么具体操作过程是怎么样子的呢?写一个简单的测试去跟踪代码,如下代码,往redis中设置key为ping的字串.123456789101112@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = Application.class)public class RedisConnectTest &#123; @Resource private RedisTemplate&lt;String,String&gt; redisTemplate; @Test public void testSetAndGet() &#123; redisTemplate.opsForValue().set("ping","pong"); System.out.println(redisTemplate.opsForValue().get("ping")); &#125;&#125; 运行之后查看redis数据库,你会发现很奇怪的事情,如下图,代码中存入的是ping,但是到redis中后却是一堆字符+ping,这个原因是什么呢?接着跟踪代码. 3.2 XXXOperations上述代码的第一步先获取到了ValueOperations,在RedisTemplate中同样还有其他XXXOperations,根据官方文档,这些接口是针对redis的每一种命令的操作.如下表: 接口 操作 ValueOperations Redis string (or value) operations ListOperations Redis list operations SetOperations Redis set operations ZSetOperations Redis zset (or sorted set) operations HashOperations Redis hash operations HyperLogLogOperations Redis HyperLogLog operations like (pfadd, pfcount,…​) GeoOperations Redis geospatial operations like GEOADD, GEORADIUS,…​) BoundValueOperations Redis string (or value) key bound operations BoundListOperations Redis list key bound operations BoundSetOperations Redis set key bound operations BoundZSetOperations Redis zset (or sorted set) key bound operations BoundHashOperations Redis hash key bound operations BoundGeoOperations Redis key bound geospatial operations. 其中BoundXXXOperations是在key已知的情况下使用,其所有操作都是建立在有一个certain key的前提.可以看下源码就能明白了. 3.3 XXXSerializer那测试代码中第一步是获取了string类型的redis操作入口,然后执行set方法设置键和值,接着分析set方法. 12345678910public void set(K key, V value) &#123; final byte[] rawValue = rawValue(value); execute(new ValueDeserializingRedisCallback(key) &#123; protected byte[] inRedis(byte[] rawKey, RedisConnection connection) &#123; connection.set(rawKey, rawValue); return null; &#125; &#125;, true);&#125; 可以发现rawKey()方法和rawValue()方法对key和value进行了一次序列化操作.该序列化使用的类为RedisTemplate中的XXXSerializer,那么回到RedisTemplate,在afterPropertiesSet()方法中有以下初始化方法,默认使用的序列化方式为JdkSerializationRedisSerializer,也就是ObjectInputStream和ObjectOutputStream写入和读取.这也是写入到redis中却在redis数据库通过”ping”访问不到的原因.1234567891011121314151617181920212223if (defaultSerializer == null) &#123; defaultSerializer = new JdkSerializationRedisSerializer( classLoader != null ? classLoader : this.getClass().getClassLoader()); &#125; if (enableDefaultSerializer) &#123; if (keySerializer == null) &#123; keySerializer = defaultSerializer; defaultUsed = true; &#125; if (valueSerializer == null) &#123; valueSerializer = defaultSerializer; defaultUsed = true; &#125; if (hashKeySerializer == null) &#123; hashKeySerializer = defaultSerializer; defaultUsed = true; &#125; if (hashValueSerializer == null) &#123; hashValueSerializer = defaultSerializer; defaultUsed = true; &#125; &#125; 那么SpringDataRedis支持哪些序列化呢?从官网可以看到:StringRedisSerializer: string类型序列化,也是最常用的类型JdkSerializationRedisSerializer: jdk默认序列化OxmSerializer : xml格式JacksonJsonRedisSerializer : json格式 通过手动注入RedisTemplate,更改所选择的序列化方式.另外Spring提供了最常使用的StringRedisTemplate,实现了StringRedisSerializer序列化方式.1234567public StringRedisTemplate() &#123; RedisSerializer&lt;String&gt; stringSerializer = new StringRedisSerializer(); setKeySerializer(stringSerializer); setValueSerializer(stringSerializer); setHashKeySerializer(stringSerializer); setHashValueSerializer(stringSerializer);&#125; 更改成StringRedisTemplate,再次执行,正常了. 3.4 总结过程 获取RedisTemplate 获取操作入口XXXOperations 使用RedisSerializer序列化key和value 获取conn连接 执行命令 4.发布与订阅发布与订阅过程需要发布者,订阅者,以及把两者连在一起的桥梁.那么在SpringRedis中怎么实现呢?订阅者:里面有一个处理方法即可.12345678910111213141516@Componentpublic class Listen &#123; private static Logger logger = LoggerFactory.getLogger(Listen.class); private CountDownLatch latch = new CountDownLatch(1); public void handleMsg(String message) &#123; logger.info("reciver msg :" + message); latch.countDown(); &#125; public CountDownLatch getLatch() &#123; return latch; &#125;&#125; 发布者:XXXRedisTemplate.convertAndSend(chanel,msg)即作为发布者存在. 连接桥梁:RedisMessageListenerContainer,该container监听Redis的消息,分发给各自的监听者.关键代码为 123456789101112131415161718192021222324@Configurationpublic class PublishConfig &#123; /** * 注入消息容器 * @param jedisConnectionFactory jedis连接池 * @param listenerAdapter 监听适配器 * @return bean */ @Bean public RedisMessageListenerContainer container(RedisConnectionFactory jedisConnectionFactory, MessageListenerAdapter listenerAdapter)&#123; RedisMessageListenerContainer container = new RedisMessageListenerContainer(); container.setConnectionFactory(jedisConnectionFactory); //绑定监听者与信道的管理 container.addMessageListener(listenerAdapter,new PatternTopic("java")); return container; &#125; @Bean public MessageListenerAdapter adapter(Listen listen)&#123; //指定监听者和监听方法 return new MessageListenerAdapter(listen,"handleMsg"); &#125;&#125; 测试:12345@Testpublic void testPublish() throws InterruptedException &#123; stringRedisTemplate.convertAndSend("java","hello world"); listen.getLatch().await();&#125; 5.事务对于事务的操作是通过SessionCallback实现,该接口保证其内部所有操作都是在同一个Session中的,在最后exec的时候执行全部操作.关键代码如下12RedisConnectionUtils.bindConnection(factory, enableTransactionSupport);execute(this) 12345678910111213141516171819202122232425@Test public void testMulti() &#123; boolean isThrow = false; List&lt;Object&gt; result = null; try &#123; result = stringRedisTemplate.execute(new SessionCallback&lt;List&lt;Object&gt;&gt;() &#123; @Override public List&lt;Object&gt; execute(RedisOperations operations) throws DataAccessException &#123; operations.multi(); ValueOperations&lt;String,String&gt; ops = operations.opsForValue(); ops.set("ping1","pong1"); ops.set("ping2","pong2"); if (isThrow)&#123; throw new IllegalArgumentException("测试异常"); &#125; return operations.exec(); &#125; &#125;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; System.out.println(result); &#125; 6.管道直接引用官方案例1234567891011//pop a specified number of items from a queueList&lt;Object&gt; results = stringRedisTemplate.executePipelined( new RedisCallback&lt;Object&gt;() &#123; public Object doInRedis(RedisConnection connection) throws DataAccessException &#123; StringRedisConnection stringRedisConn = (StringRedisConnection)connection; for(int i=0; i&lt; batchSize; i++) &#123; stringRedisConn.rPop("myqueue"); &#125; return null; &#125;&#125;); 还有脚本执行等,在官方文档中都有案例,这里就不复制粘贴了,如有错误请指出,不胜感激. 参考文档: http://docs.spring.io/spring-data/redis/docs/1.8.1.RELEASE/reference/html/#redis:template github: https://github.com/nl101531/JavaWEB]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[redis学习记录(三)-redis中的数据结构]]></title>
      <url>%2F2017%2F03%2F26%2Flinux%2Fredis%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%B8%89)-redis%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
      <content type="text"><![CDATA[redis学习记录(三)-redis中的数据结构标签（空格分隔）： redis Redis学习记录(一)–入门知识oRedis学习记录(二)–使用Jedis连接 redis有五种数据类型,string,list,set,hash,sort set,不同场景使用不同数据结构的前提是了解每一种数据结构.那么结构图片是最佳的了解方式,图片来自慕课网. stringstring是的key-&gt;value类型的存储,可以存储字符串类型和数值类型,可对数值类型是可以增加减少,对string类型可以追加内容. listlist是列表,也就是一个key-&gt;多个value,可以支持双端队列,栈来操作,因此越靠近两端其查找速度越快,端点的复杂度查找为O(1),同时队列有阻塞操作,也就是可以当成阻塞队列使用. setset为无序,且不重复的集合,且提供O(1)复杂度度的快速查找.set集合支持集合的并,交,差操作,因为无序性,因此也提供迭代方法. hashhash类型适合存储对象,相比前面的string,所带来的优势是可以使用一个key查出该下面所有的键值对,并且可以单独对某一属性更改,如图所示: sort set可排序的集合,如图所示存在score排名分数,隐藏属性rank排名,0为最小.注意对sort set来说value是唯一性的,而不是score,如果两个score相同,则按照value的字典序排序. 应用场景string计数器:redis的incr操作是原子性的,因此可以应对高并发,如网站要求每个用户获取验证码后60秒内不得再次获取,那么第一次获取的时候用incr给该用户设置key,过期时间为60秒,如果结果等于1则为第一次请求,那么第二次获取时比较决定是否操作频繁. Listlist的优势的有序性,两端插入复杂度为O(1),那么对于最近文章列表等类似需求是最佳解决方案,维护一个定长的列表,每次插入后执行trim操作. Setset的优势是唯一性,O(1)的查找查找复杂度,并且支持差并集,那么二度好友问题就迎刃而解了. hashhash非常适合存储对象,不同的键为对象的特征,值为特征值,那么比string好的就是修改不需要每次都修改一个整串,而可以选择修改某一指定键值. sort setsort set可排序特性使其很容易解决排行榜类应用,但是要注意值需要存储不变的属性,因为值要求唯一性,score可不唯一.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[毕业设计周记(三)]]></title>
      <url>%2F2017%2F03%2F25%2F%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%2F%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E5%91%A8%E8%AE%B0(%E4%B8%89)%2F</url>
      <content type="text"><![CDATA[3.26更新周末把竞赛支持也写好了,但是总觉得和自己想要的不太一样了,前端太乏力,因此下周开始重构前端,采用VUE写成一个单页逻辑应用.希望不会耽误太多时间. 花了一下午的时间把服务器重装了,所有实例包括mysql,redis,nginx都跑在docker中,项目也是跑在docker中,目前来看效果很不错,对服务器的利用率比之前高太多了. 部署的OJ漏洞挺多的,体验上也没怎么优化,尤其是注册流程,问题多多,接下来要优化代码,优化这个流程. 竞赛方面的支持,因为上周公司出了几个大活动,一直比较忙,而没去做,本周也继续做竞赛方面支持. 因此目前进度: 服务器部署全部docker化 线上可以直接判题 测试地址: http://oj.mrdear.cn/ 服务器比价渣,速度比较慢 测试账号: 1015315668@qq.com 密码: 111111 等待完成: 1.竞赛的支持2.注册流程优化 源码地址: https://github.com/nl101531/AUSTOJ2]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ERP叛逃者(转)]]></title>
      <url>%2F2017%2F03%2F19%2F%E9%9A%8F%E8%B0%88%2FERP%E5%8F%9B%E9%80%83%E8%80%85%2F</url>
      <content type="text"><![CDATA[ERP叛逃者(转)标签（空格分隔）： 随谈 作者:alswl原文链接:https://blog.alswl.com/2011/04/erp-defectors/ 一篇对于毕业生很有指导意义的文章,踏入职场,面临的第一个选择就是工作,第一份工作可能并不如你所期望的那样,那么你真正想要什么呢?文章会给你答案. 大四实习时候，跑去驻厂开发，当时主管跟我说”我们做的是企业信息化软件”。毕业之后找工作，进入一家国内还算有名的ERP公司，做ERPII产品（CRM/工作流/ 电子商务平台等ERP软件附属产品）的开发和二次开发。 在这一年半的时间里，我学习了一些行业知识，熟悉了公司自己的开发模式、框架和工具。浑浑噩噩的直到某一天，我发现我写代码没有键盘飞扬的感觉。我惶恐，我感觉我遇到 瓶颈停止成长了。我开始思索我这种状况的产生，我重新翻开曾经看的糊里糊涂的《人月神话》，研读阿朱的《走出软件作坊》，尝试找到问题和解决办法。 我回想我工作之后做的事情：我负责的是从顾问那里拿到伪SQL+伪代码，然后将它们在公司的框架上面实现起来，再手工完成功能性测试。我做一个极端的假设：如果早50 年，ERP公司给用户提供解决方案可以是在纸上提出，根本不需要电脑。所以ERP的本质是对业务的梳理，规范化的引导，让企业高效整合资源充分发挥产能的公司。这与我 想象的IT公司完全不一样，我所希望的IT公司能够追求极致，创造用户喜欢的，快速响应用户需求，扩展性强的产品。如果具备这些元素，会很快被同类公司超越。 可是公司立足于市场近30年，绝对不是这么不堪，她有自己的核心竞争力：标准的业务流程，强大的顾问和实施团队，本土化的产品。 我比较了知名互联网公司、创业型IT公司和传统管理软件行业的区别，惊讶的发现，原来，计算机科学与技术专业毕业的我，不在IT公司，在一家服务咨询公司！！！我把这 个想法和主管进行交流，主管也认同我们提供的是service而不是soft。 我简单比较了互联网企业和传统行业软件企业的差异。 目标人群不一样行业软件：企业用户 互联网产品：个人用户更多，也有企业用户 由于给企业用户进行定制，导致内部封闭现象严重，更新周期漫长。另外，企业用户可以强制要求用户使用某种操作方式或者某种环境，比如我就是要让你用IE6，你不用IE 6系统出现问题，那是你的原因。而互联网产品就面对所有网民，必须考虑到标准问题。 另外，企业用户更换系统平台频率低，系统一旦投入使用，需要经过几年的使用，才会可能考虑更换，其依赖性比互联网产品高出个数量级。由于互联网的开放性，互联网用户很 容易在不同产品之间进行更换。 盈利点不一样互联网：吸引用户使用，所以用户体验，速度是需要考虑的，依赖用户使用情况（VIP制度、广告收入）盈利。 行业软件：卖给产品和服务给用户，功能符合用户需要，顾问实施精准，依赖销售产品+服务盈利。 盈利点造成行业软件未必会把用户体验、速度这些相对次要的问题放在首位考虑，而是考虑先解决实际问题，满足用户需要。 核心竞争力行业软件最依赖的核心竞争力是对某个行业的了解，比如阿朱所在的明源专注于房地产，金蝶用友各有所擅长的行业。并不是他们不想在别的行业挣钱，而是对应行业的顾问极难 培养（行业/领域专家）。 互联网产品的核心竞争力就更多样化，Web2.0时代可以是用户关系，用户基数（腾讯，现在的人人），也可以是某一款特别大众需要的产品（淘宝，搜索引擎，书签服务） ，又或是核心技术（Google），这些核心竞争力会在发展过程中相互转换，相互渗透。 互联网产品的特性是快，这个快是表象，本质是在于互联网产品要充分挖掘用户需求，不断满足现有要求，并预测引领用户需求趋势，这也是创新精神具体体现。由于同质化严重 ，竞争白热化，导致互联网产品纷纷涌现，给人一种爆炸的感觉。其实，一款好的互联网产品从有创意到磨砺成熟，是需要经过一段还算长的时间的。（除非是搞搞微创新，大家 都知道怎么做，没什么核心竞争力，只是拼模拟速度了） 我在想清楚这些之后，发现ERP不是我的归宿，互联网才是我追寻的方向。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[毕业设计周记(二)]]></title>
      <url>%2F2017%2F03%2F18%2F%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%2F%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E5%91%A8%E8%AE%B0(%E4%BA%8C)%2F</url>
      <content type="text"><![CDATA[上周学习docker之后,建立起docker的判题环境,目前已成功判题,前端部分也打通.目前支持语言C,C++,Java,后续会添加更多语言支持.接下来的任务是整理代码,重构部分逻辑代码,还有竞赛判题的支持.预计下周完成. 因此目前进度: WEB端和Judge端打通,近期部署到自己的服务器上,以便展示. 等待完成: 1.竞赛的支持2.代码重构,一些体验上的逻辑优化 源码地址: https://github.com/nl101531/AUSTOJ2]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker学习记录(三)-构建非跨平台项目编译环境]]></title>
      <url>%2F2017%2F03%2F12%2Fdocker%2FDocker%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%B8%89)-%E6%9E%84%E5%BB%BA%E9%9D%9E%E8%B7%A8%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE%E7%BC%96%E8%AF%91%E7%8E%AF%E5%A2%83%2F</url>
      <content type="text"><![CDATA[Docker学习记录(三)-构建非跨平台项目编译环境标签（空格分隔）： docker 个人独立博客: http://mrdear.cn 因为毕业设计的问题所以去学了docker,本文描述这个问题解决的过程. 1.问题在毕业设计AUSTOJ中,判题端使用JNI方式调用C++来编译和执行代码,得到输出结果,Java端进行结果对比.然而该C++代码在mac下无法编译,总是会报错,JNI也会出问题.另外该子模块在mac下无法使用maven打包,所以打包也需要放在docker中.因此docker需要环境 java maven gcc g++ make 2.构建编译环境编写dockerfile文件,该文件的maven包我是从本机复制进去的,同样你也可以从外网下载.Dockerfile:123456789101112131415161718192021#构建judger端需要的环境,方便本地测试#基于java8环境FROM java:8#维护人信息MAINTAINER quding niudear@foxmail.com#更新源RUN apt-get update#gcc g++ make安装RUN apt-get install -y gcc-4.9RUN apt-get install -y g++-4.9RUN apt-get install -y build-essential#配置mvn环境ADD apache-maven-3.3.9.tar.gz /usr/localENV M2_HOME /usr/local/apache-maven-3.3.9ENV PATH $PATH:$JAVA_HOME/bin:$M2_HOME/bin#jni环境RUN cp $JAVA_HOME/include/linux/jawt_md.h $JAVA_HOME/include/RUN cp $JAVA_HOME/include/linux/jni_md.h $JAVA_HOME/include/ 构建命令:docker build -t dev . 3.挂载运行运行时需要挂载本项目到docker中,该挂载是映射,因此本地和docker任意位置改变项目中文件都会反映在真实项目中,这也是想要的结果.挂载命令:12docker run -ti -p 50013:50013 -v /Users/niuli/workspace/git/AUSTOJ2/:/AUSTOJ2 -v /Users/niuli/workspace/git/testcase/:/austoj/testcase dev 该命令以交互模式启动一个docker容器,同时绑定docker的50013端口到此容器的50013,因为我的项目使用的是50013端口.另外我挂载了本项目目录AUSTOJ2和测试数据目录分别到docker的/AUSTOJ2目录和/austoj/testcase目录. 那么启动之后如下所示: ok,到此编译环境搞定,可以随心所欲的编译启动该子模块,并且还能实时反映到本机目录下]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker学习记录(二)-Dockerfile创建镜像]]></title>
      <url>%2F2017%2F03%2F10%2Fdocker%2FDocker%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%BA%8C)-Dockerfile%E5%88%9B%E5%BB%BA%E9%95%9C%E5%83%8F%2F</url>
      <content type="text"><![CDATA[Docker学习记录(二)-Dockerfile创建镜像标签（空格分隔）： docker 本文学习Dcokerfile的基本命令,并且创建一个支持ssh服务的镜像. 1.Dockerfile1.1基本案例dockerfile可以说是docker的描述符,该文件定义了docker镜像的所能拥有哪些东西.基本格式如下:123456789101112第一行指定该镜像基于的基础镜像(必须)FROM java:8维护者信息MAINTAINER quding niudear@foxmail.com镜像操作指令RUN echo $JAVA_HOME启动时操作的命令CMD ./usr/sbin/nginx 该文件说明从Java8这个基础镜像创建一个新的镜像,输出Java路径,启动成功则启动nginx服务,这也是一个Dockerfile需要包含的操作步骤. 1.2指令详解1.FROM：格式为 FROM &lt;image&gt;或FROM&lt;image&gt;:&lt;tag&gt;第一条指令必须是FROM指令。并且，如果在同一个Dockerfile中创建多个镜像时，可以使用多个FROM指令（每个镜像一次）。 2.MAINTAINER：格式为MAINTAIER，指定维护者信息。 3.RUN：格式为RUN &lt;command&gt;或者RUN [“executable”，“param1”，“param2”]。前者将在shell终端中运行的命令，即/bin/sh–c；后者则使用exec执行。指定使用其他终端可以通过第二种方式实现，例如RUN[“/bin/bash”，“-c”，“echohello”]。每条RUN指令将在当前镜像基础上执行指定命令，并提交为新的镜像。当命令较长时可以使用\来换行。这实际上就是在容器构建时需要执行哪些指令，例如容器构建时需要下拉代码，但是默认启动的容器中是没有Git指令的，就需要下载，可以执行：RUN apt-get install -y git，然后RUN git clonexxxx 4.CMD：指定容器启动后执行的命令命令格式为:sh格式: CMD &lt;命令&gt;exec格式:CMD [“可执行文件”,”参数1”,”参数2”]一般都是早就写好的脚本或者启动一个服务，例如：CMD[“/run.sh”]。注意：如果Dockerfile中指定了多条命令，只有最后一条会被执行。如果用户启动时候加了运行的命令，则会覆盖掉CMD指定的指令。 这里有一个问题,很多时候我们想要docker一直在后台运行,但是往往docker启动后就停止.原因就在于此.比如执行CMD serice mysql start,那么翻译过来的话是CMD [&quot;sh&quot;,&quot;-c&quot;,&quot;serice mysql start&quot;],那么对于docker来说CMD主进程为sh,那么sh执行完该命令就结束,所以导致docker停止.所以要改成直接启动文件形式CMD [&quot;nginx&quot;,&quot;-g&quot;,&quot;&quot;daemon off;],指定前台运行. 5.EXPOSE：告诉Docker服务端容器需要暴露的端口号，供互联系统使用。在启动容器时需要通过-P（注意是大写），Docker主机会自动分配一个端口转发到指定的端口；使用-p，则可以具体指定哪个本地端口映射过来。例如：我在elasticsearch镜像的Dockerfile中指定了暴露出9200和9300端口，我可以在Dockerfile中写：EXPOSE 9200 9300 6.ENV：创建的时候给容器中加上个需要的环境变量。指定一个值，为后续的RUN指令服务 7.COPY：复制本地的文件或目录到容器中。目标路径不存在时，会自动创建。 8.ENTRYPOINT：配置容器启动后执行的命令，并且不可被docker run 提供的参数覆盖。每个Dockerfile中只能有一个ENTRYPOINT，当指定多个ENTRYPOINT时，只有最后一个生效 9.VOLUME：创建一个挂在点，可以从本机或其他容器挂载的挂载点。意思就是从容器中暴露出一部分，和外界共享这块东西，一般放数据库的数据或者是代码。在容器启动运行的时候，如果需要将volume暴露的东西和本地的一个文件夹进行映射，想要通过本地文件直接访问容器中暴露的部分，可以在运行的时候进行映射： 10.USER：指定运行容器时的用户名或者UID，后续的RUN也会使用指定的用户。当服务不需要管理员权限时，可以通过该命令指定运行用户。并且可以在之前创建所需要的用户。要临时获取管理员权限的时候要使用gosu，不推荐使用sudo。如果不指定，容器默认是root运行。 11.WORKDIR：定义工作目录，如果容器中没有此目录，会自动创建 创建指令docker build 路径,该命令会读取路径下的Dockerfile文件和其他文件,然后发送给服务端,由服务端创建镜像. 2.创建SSH服务镜像2.1准备Java8环境后续教程需要利用到Java8环境,因此先下载一个官方的Java8镜像作为基础镜像.直接执行如下命令.可以利用之前的教程,启动容器查看下java路径.1docker pull java:8 2.2编写Dockerfilessh服务主要是openssh-server来提供,因此需要在容器中安装该服务.Dockerfile:1234567891011121314151617181920212223242526272829#显示该镜像是基于java8镜像FROM java:8#维护人信息MAINTAINER quding niudear@foxmail.com#更新源RUN apt-get update#安装软件RUN apt-get install -y openssh-serverRUN mkdir -p /var/run/sshdRUN mkdir -p /root/.ssh#取消pam限制RUN sed -ri &apos;s/session required pam_loginuid.so/#session required pam_loginuid.so/g&apos; /etc/pam.d/sshd#复制配置文件到相应位置COPY authorized_keys /root/.ssh/authorized_keysCOPY run.sh /run.sh#赋予脚本权限RUN chmod 755 /run.sh#开放端口EXPOSE 22#设置启动命令CMD [&quot;/run.sh&quot;] run.sh12#!/bin/bash/usr/sbin/sshd -D 拷贝本机的id_ras12cat ~/.ssh/id_rsa.pub &gt;authorized_keys//用来免密的 执行构建1docker build -t sshd:java . 构建成功后使用docker images即可查看,然后像上篇一样启动容器,暴露出端口,再使用ssh连接,和一般linux系统就没什么差别了.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker学习记录(一)-基本概念]]></title>
      <url>%2F2017%2F03%2F10%2Fdocker%2FDocker%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E4%B8%80)-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
      <content type="text"><![CDATA[Docker学习记录(一)-基本概念标签（空格分隔）： docker 因为做的项目用到了docker,所以开始学习下这方面的知识. 1.基本概念docker虚拟机:docker环境,docker的操作都要依赖此虚拟机,可以理解为JDK.docker镜像:镜像可以用面向对象中的Model类来理解,就是一个已经建立好的模型.docker容器:容器可以关联面向对象中的实例来理解,实例是依赖类来创建,所以容器就是依赖镜像创建,同样一个类可以有多个实例,那么一个镜像也可以对应多个容器.docker仓库:仓库是镜像市场,里面有别人建立好的Model类,也就是镜像,可以直接拿来使用. 这样说应该很好理解了吧. 因此创建一个helloworld的流程就和清晰了.启动docker虚拟机-&gt;创建docker镜像(或者从仓库拉取)-&gt;创建docker容器(运行helloworld)-&gt;结束 2.docker虚拟机首先docker安装后自带的虚拟机配置下载镜像又要GFW的原因速度很慢,一般使用阿里云加速器,登陆后找到加速器按照要求先创建一个新的docker主机,然后启动该主机.这里要注意,阿里云给的命令是创建一个名字为default的主机,安装后自带了一个default,所以先运行docker-machine rm default删除默认主机. 2.1新建主机 2.2为当前shell配置环境 2.3验证 到此docker虚拟机创建完毕,这里需要掌握一些基本增删改查基本命令.123456789101112docker-machine kill 停止某个Docker主机docker-machine ls 列出所有管理的Docker主机docker-machine regenerate-certs 为某个主机重新成功TLS认证信息docker-machine restart 重启Docker主机docker-machine rm 删除Docker主机docker-machine scp 在Docker主机之间复制文件docker-machine ssh SSH到主机上执行命令docker-machine start 启动一个主机docker-machine status 查看一个主机状态docker-machine stop 停止一个主机docker-machine upgrade 更新主机Docker版本为最新docker-machine url 获取主机的URL 3.docker镜像使用docker images可以列出机器上所有的docker镜像. 其中:REPOSTITORY：表示镜像的仓库源TAG：镜像的标签IMAGE ID：镜像IDCREATED：镜像创建时间SIZE：镜像大小 使用docker search 镜像名查找某一镜像,例如查找hello world,可以看到带有OFFICIAL的为官方提供的镜像. 使用docker pull 镜像名获取一个镜像,这里获取hello world,另外镜像后可以跟版本号,例如docker pull redis:3.2,就指定拉去redis3.2版本 使用docker run 镜像名从该镜像启动一个实例. 常见命令,另外对于docker镜像的创建和运行比较重要,后续文章单独学习分析.123456docker inspect 查看镜像详情docker rmi 删除镜像,带上-f参数则强制删除docker save 导出镜像docker load 导入镜像docker push 上传镜像到仓库docker tag 给镜像设置标签 4.docker容器容器是应用的实例,使用docker create创建一个容器,使用docker start启动一个容器,另一个简单方式就是docker run,等价于先创建再启动. 那么使用docker run的时候后台做了哪些操作? 查找是否存在指定镜像,不存在则从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统,在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接到容器中去 从地址池配置一个ip地址给容器 执行用户指定应用程序 执行完毕后容器被终止 使用docker ps -a查看最近启动的容器 使用docker rm删除容器,清理完毕后再删除hello world镜像. 下面使用redis镜像实战整个流程,并学习容器常用命令. 5.创建redis镜像有了helloworld经历,这里流程就很清晰了,搜索镜像-&gt;拉去镜像-&gt;创建实例-&gt;连接交互 可以看到启动了redis,但是这里直接输出到当前控制台了,可以通过参数配置使其后台运行.docker run参数12345678910111213141516-a stdin: 指定标准输入输出内容类型，可选 STDIN/STDOUT/STDERR 三项；-d: 后台运行容器，并返回容器ID；-i: 以交互模式运行容器，通常与 -t 同时使用；-t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用；--name=&quot;nginx-lb&quot;: 为容器指定一个名称；--dns 8.8.8.8: 指定容器使用的DNS服务器，默认和宿主一致；--dns-search example.com: 指定容器DNS搜索域名，默认和宿主一致；-h &quot;mars&quot;: 指定容器的hostname；-e username=&quot;ritchie&quot;: 设置环境变量；--env-file=[]: 从指定文件读入环境变量；--cpuset=&quot;0-2&quot; or --cpuset=&quot;0,1,2&quot;: 绑定容器到指定CPU运行；-m :设置容器使用内存最大值；--net=&quot;bridge&quot;: 指定容器的网络连接类型，支持 bridge/host/none/Container: 四种类型；--link=[]: 添加链接到另一个容器；--expose=[]: 开放一个端口或一组端口；-p 指定容器端口映射,该参数可以使得容器端口和主机端口相互映射 首先使用-d -p参数,可以看到redis跑在了后台. 外部连接:使用docker port 容器id查看映射出来的端口,该端口为docker主机的哈,所以要通过docker主机ip:端口才可以访问.比如我的docker主机ip为:192.168.99.100(使用docker-machine env查看),docker分配映射端口为32768,那么访问就是192.168.99.100:32768,如果想用主机地址访问的话,就需要-p参数加上主机端口映射了 进入容器使用docker exec命令可以进入容器内部,参数和run的参数作用相同. 其他命令1234docker stop 停止一个容器docker rm 删除一个容器docker import 导入一个容器docker export 导出一个容器]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[毕业设计周记(一)]]></title>
      <url>%2F2017%2F03%2F10%2F%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%2F%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E5%91%A8%E8%AE%B0(%E4%B8%80)%2F</url>
      <content type="text"><![CDATA[本周算是正式开始做毕业设计,之前虽然一直在做,但是处于刚学习阶段,各方面做的都不是很好,因此自己也把第一版删除了,目前重构第二版.现在不止把这个当成毕业设计,而是想把他当成一个平台.用于自己学习到的技能在上面施展,因此很多没必要使用的东西都用上了. 关于判题内核,这个是一个难点.目前采取开源的方案,C++判题,使用JNI调用方式,(第一版是开源的windows判题内核,问题多多)WEB端和Judge端使用gRPC通信.目前卡在的难点判题内核是在linux下运行,但是自己用的是MAC,所以想采用Docker方案,这样的话还顺便更进一步解决了Judge的安全性问题,因此在学习Docker的知识. 因此目前进度: WEB端基本完成 Judge端完成 等待完成: Judge移植到Docker中 打通WEB端和Judge端的通信,也就是实现判题. 源码地址: https://github.com/nl101531/AUSTOJ2]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>%2F2017%2F03%2F09%2Fhello-world%2F</url>
      <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[工作经验]]></title>
      <url>%2F2017%2F02%2F28%2F%E9%9A%8F%E8%B0%88%2F%E5%B7%A5%E4%BD%9C%E7%BB%8F%E9%AA%8C(%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0)%2F</url>
      <content type="text"><![CDATA[记录自己工作中的一点小经验,有不足的地方请指正. 1.调第三方的的服务的时候切记不能直接调用,为了扩展性要使用自己定义封装.例子:我要使用支付宝的sdk调用支付宝的支付,那么为了让支付宝的SDK不侵染业务代码,那么就应该在上层再封装一层,保证自己业务的代码中不出现其他的方的代码. 2.服务封装要尽可能确保只为一个层服务,尽量减少跨层级调用,比如controller层就应该避免调用dao层,而是调用service层. 3.某一个方法无关状态,且复用性高的话最好写成静态类调用方式.语义清晰,调用方便. 4.接手某一个业务时,最好先画出该业务的流程图,设计出大概的代码结构后再去写代码,这样虽然前期成本高,但是综合来看的话最节省时间和精力. 5.业务性的代码怎么安全怎么写,在安全的基础上适当保证代码简洁.比如simpleDateFormat是线程不安全的,最简单的做法就是在需要的时候new一个,在业务性的代码中不要使用ThreadLocal这些东西进行优化,这样会增加CR成本. 6.对于工作中出现的一些在他人帮助下解决的问题,自己要想办法复现,然后尝试自己独立解决. 7.updateXXX 不应该出现在 XXXService 里,因为不同的业务流程不同导致update的原因可能很多,这样就带来了无谓的复杂度,该操作应该放在DAO层,Service 层的功能是做某个逻辑，而不是做某个数据操作。职责不一样的.所谓的Service层复用指的是业务操作复用,而不是简单的代码复用. 8.对于和第三方服务商服务交互的报文信息尽可能的全部打出来,避免以后因为某业务撕逼.这很重要! 9.数据库经常有一些extend字段,对于这些字段对应DO提供String映射,在DTO中提供HashMap映射,因为该字段可能存出多种类型数据.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[如何学习一门新技术]]></title>
      <url>%2F2017%2F02%2F01%2F%E9%9A%8F%E8%B0%88%2F%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0%E4%B8%80%E9%97%A8%E6%96%B0%E6%8A%80%E6%9C%AF%2F</url>
      <content type="text"><![CDATA[在看他人博客的时候发现的,自己也是一直按照这样的模式去学,现在分享下整个流程. 图片来源: dreamfy 是什么?为什么会出现?这一阶段主要是对该技术有一个整体了解,他所解决的是什么问题,他的整体结构等. 怎么做?最简单的是找一个上手视频,因为视频是非常直观的展示了技术的使用.先学会用是最根本的,对于没有视频的技术的话,就可以搜索XX上手教程,XX学习记录之类的关键词,很轻松就找到了相关的上手博文,这一阶段一般都是环境整合搭建,然后写一个简单的入门Demo. 第二个阶段,学会基本使用了就要去看官方文档,文档会让你更加详细的了解该技术的特性,开一个Demo项目把官方的一些例子都试试. 第三个阶段,尝试在一些复杂的项目中使用(非生产项目),使用过程中难免会遇到各种各样的问题,官方文档和搜索引擎会帮助你解决,这一过程你会对该技术掌握更加娴熟. 第三个阶段,去github上找一些别人的项目,主要是看他人的使用方法,模块设计,代码封装等. 第四个阶段,生产项目使用吧,遇到问题还是官方文档和搜索引擎. 分享好记性不如烂笔头,博客记录是一个很好地习惯,能把自己学的东西和他人讲清楚才叫真正的懂了这个技术.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[面经]]></title>
      <url>%2F2017%2F01%2F10%2F%E9%9A%8F%E8%B0%88%2F%E9%9D%A2%E7%BB%8F%2F</url>
      <content type="text"><![CDATA[从2016.7来到上海后记录下自己的面试经历,希望能对其他人有所帮助,同时给自己一个提醒. 第二次面试2017.1 上一家公司干了六个月,做的还不错,中间涨了一次工资,也就5000左右,但是公司没技术氛围,而且加班是家常便饭,所以为了自己打算离开了,这里我是提前和领导说不打算续签的,自己离职不太好意思拿年终奖再离职,不过领导知道后还是给我申请了年终奖,感动Ing 第二次面试先电面再去公司面试的,总体感觉很不错,结果还在等… 1.电面首先自我介绍,这个很随意,技术人员一般都不看重这个.1.ArrayList的扩容机制.这个抓住几个点,本质是一个Object的数组,初始容量10,1.7JDK之后每次扩容是1.5倍,但是1.6的JDK版本是1.5倍+1,这个回答出来说明你研究过这个而不是直接背答案.每次add都会进行容量检查,扩容是调用一个native方法System.arrayCopy,2.Map的containsKey和List的contain方法效率一样吗?这个问题回答要表现出List基于数组在查找方面的缺点,就是最坏情况下是查找全部元素后才找到,但是Map是基于Hash链表,查找是根据hash计算出来的索引地址,找到索引后会判断上面是否有链表存在,有的话会接着查找,补充下JDK8之后的HashMap当哈希桶上的链表长度大于8则会转换为一颗红黑树,因此随着碰撞增加仍然会提供稳定的性能.3.自己的项目问题这个就实打实的说就好了.其中有一个项目提到了python,因此面试官问我python学的怎么样,可以来聊聊python,但是我就会基础,所以不了了之,简历上不熟的东西尽量少写. 2.现场面现场面就没问很多基础问题了,主要是一些突发的问题,问了不少Linux的知识,自己又不是太熟,所以处于被虐状态…1.Linux的top命令不会,我说因为公司有运维,用服务器也就查看日志什么,自己不是很了解.面试官说了一句话,说我们这是工程师和运维不分家的,一个好的工程师必然要了解代码是怎么运行的,也就需要对代码运行环境有很深的了解,这样才能写出优秀的代码,大概意思是这样的,感觉很有道理,自己Linux的服务器知识欠缺很多.2.Linux下怎么查看日志因为上面提到了自己用服务器查看日志,所以就直接被问了,博主说一般用cat命令配合grep来查看,或者使用VIM来查看,用tail -f查看实时日志,head查看开始日志等,然后被问了假设日志是10G大小,怎么快速找到自己想要的东西?这个问题想了一会,直接说不会….尴尬,后来提示用less命令,该命令不会全部加载文件.参考博文:Linux下的more和less的使用3.爬取新浪微博用户,怎么判断该用户是否已经爬过博主说了数据量小的话使用Map集合或者Set集合,数据量多的话,就把某一个唯一字段设置为数据库主键,爬取的用户插入到数据库,去重交给数据库来做就好了.接着面试官问如果不使用数据库呢?博主想了想,就随口说爬取一部分用户后写入到文件,然后生成MD5摘要,这样每次写入文件后判断该摘要是否已存在,存在就不写入,牺牲时间,保证最终的结果重复性最低.现在想来还是有问题,爬取是随机的,所以导致生成摘要碰撞几率太低.可能多一个字符少一个字符就导致摘要不同.没想到好办法…4.在做项目中有没有什么取巧的经历?一时间还真想不到…就没答上来.5.在项目中遇到的难点博主说了自己写的集成微信,支付宝,银联,预付费卡的一个支付模块,主要讲了遇到问题怎么解决的,然后怎么封装的.6.关于代码洁癖举个例子博主简历上写自己有代码洁癖,所以就被问了这个,我举了前公司,也就第一家面试的,使用JPA的多表查询时候返回一个Objec[]数组,导致代码没法维护,并且重复代码太多,自己使用queryDSL,对公司代码进行了大面积的修改. 本以为要挂了,最后说技术面过了,不知道是安慰我还是什么,接着是HR面,聊了聊公司现状,待遇问题等,最后也没说过还是不过等通知.因为现在时间点比较尴尬,我提出年后入职,也不知道可不可以….等消息中更新:已收到offer,年后入职,这家公司效率真不错,接下来希望自己有所提高! 第一次面试2016.7 首先简历很重要,程序员不需要太花哨的简历,尽可能的展现出自己的特点就可以了,推荐下面简历,很不错的一个模板.https://github.com/penglongli/My-Resume 第一次面试没有多紧张,可能对方是小公司吧,感觉很随意,面试就问了三个问题.1.谈一谈Java集合这种问题一般都很宽泛,博主就从List讲到Set再到Map这样的顺序来讲的,重点描述Arraylist,LinkedList,HashMap,TreeMap,最后再总结下什么样的场景用什么,算是回答好了.2.谈谈对Spring的理解.博主当时心里我哩个擦,又是这种宽泛的问题.但是还是微笑着回答Spring的核心是Ioc和AOP,其中Ioc是基于反射实现的,AOP是动态代理实现的,然后讲了从读取xml配置文件,实例化Spring容器,然后实例化Bean(这个过程挺复杂的,一会附上一张图),最后销毁Bean这一过程,结束.具体可以参考:Spring知识点提炼3.自己项目中的问题.自己在学校接到过一个微信公众号的开发,问了怎么实现的,遇到的问题之类的.这种问题回答要表现出自己不是很了解的情况下是如何快速解决一个问题的能力 拿到offer,博主是比较安逸的人,薪资还不错就不继续再找工作了,其实应该多投几家的,才能选择最适合自己的.]]></content>
    </entry>

    
  
  
</search>
